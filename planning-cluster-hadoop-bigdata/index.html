
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Planning a Cluster for Hadoop BigData - Saverio Ferrara</title>
  <meta name="author" content="Saverio Ferrara">

  
  <meta name="description" content="This post is about how to plan, for the first time, a cluster for Apache Hadoop and HBase. Hadoop, together with its friends, enable us to elaborate &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://fsferrara.github.io/planning-cluster-hadoop-bigdata/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Saverio Ferrara" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-45189328-2']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Saverio Ferrara</a></h1>
  
    <h2>...another Software Engineer blog!</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="fsferrara.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/story">Story</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Planning a Cluster for Hadoop BigData</h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-02-21T19:39:20+00:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>21</span><span class='date-suffix'>st</span>, <span class='date-year'>2014</span></span> <span class='time'>7:39 pm</span></time>
        
      </p>
    
  </header>


<div class="entry-content"><p>This post is about how to plan, for the first time, a cluster for Apache Hadoop and HBase. Hadoop, together with its friends, enable us to elaborate a large amount of data in a cheaply way: by large I mean data large about 100 gigabytes and above.</p>

<p>Hadoop implements the MapReduce framework, that is a way to take a query (or Job) over a dataset, divide it in several queries (or Tasks), and the run these queries in parallel over multiple node of a cluster. Nothing new until now, this looks like the divide-et-impera paradigm: the innovation lies in the fact that the cluster node that is in charge of executing a task has already the data on which process the query. So we are not moving data in order to elaborate them, but we&#8217;re assigning task on the right cluster node that already has the data!</p>

<!--more-->


<p>To distribute data across the cluster nodes, Hadoop has its own file system: HDFS (Hadoop Distributed File System), which can handle about 30PB (Petabyte) of data.</p>

<p>The drawback is that HDFS does not provide a way to have a random access to the data.</p>

<p>In order to have a Random access to the data, you can use HBase, a NoSQL and column-oriented database that run on top of HDFS. Unlike direct access to HDFS, HBase can handle about 1PB (Petabyte) of data, and the performances are 4-5 times slower.</p>

<p>Therefore Apache Hadoop is a software framework that supports large-scale distributed data analysis on commodity servers. It is critical to accurately predict the workloads for the tasks to be run. Hadoop and HBase workloads vary a lot based on the effective use, and for this reason it is really hard to correctly estimate the workloads and the amount of storage. In order to make these estimations correctly, a suitable technique is to start with a pilot project, measure the workloads, and then scale the pilot environment in order to fulfil other needs.</p>

<h2>Software components in an Hadoop Cluster</h2>

<p>There are several components in the Hadoop environment, some are:</p>

<ul>
<li><strong>HDFS</strong>

<ul>
<li><p><strong>NameNode</strong>: is a <em>master</em> node for HDFS file system.</p>

<p>Actually it doesn&#8217;t contains data and manage its slaves called DataNode</p></li>
<li><strong>DataNode</strong>: is a <em>slave</em> node for HDFS file system.</li>
<li><strong>Secondary NameNode</strong>: it is not required, but it is suggested to have a backup node for the main NameNode.</li>
</ul>
</li>
<li><strong>MapReduce</strong>

<ul>
<li><strong>JobTracker</strong>: is a <em>master</em> node for MapReduce framework.</li>
<li><strong>TaskTracker</strong>: is a <em>slave</em> node for MapReduce framework.</li>
</ul>
</li>
<li><strong>HBase</strong>

<ul>
<li><strong>HBase Master</strong>: is a <em>master</em> node for HBase.</li>
<li><strong>RegionServer</strong>: is a <em>slave</em> node for HBase.</li>
<li><strong>Zookeeper</strong>: is a separate component required by HBase, used to manage the cluster.</li>
</ul>
</li>
</ul>


<p>We can rearrange these components by separating masters from slaves.</p>

<ul>
<li><strong>Masters</strong>

<ul>
<li>HDFS NameNode</li>
<li>MapReduce JobTracker</li>
<li>HBase Master</li>
</ul>
</li>
<li><strong>Slaves</strong>

<ul>
<li>HDFS DataNode</li>
<li>MapReduce TaskTracker</li>
<li>HBase RegionServer</li>
</ul>
</li>
</ul>


<p>Masters should be on a reliable cluster node: they should be always available. Slaves, instead, are frequently decommissioned for maintenance. For this reason it it highly recommended to always separate masters from slaves and, additionally, task workloads executed on the slaves should not impact the master nodes.</p>

<p>It is extremely important to deploy together DataNodes, TaskTrackers, and RegionServers, in order to achieve an optimal data locality (this is the principle underlying the MapReduce framework). We will call <strong>SlaveNode</strong> a cluster node with a DataNode, a TaskTracker, and a RegionServer.</p>

<h2>A typical Apache Hadoop Cluster</h2>

<p>Typically, a medium size Hadoop cluster consists in a set of rack-servers (actually it is possible to use blade servers, but this article use rack servers as example): let&#8217;s say that we have four half-size rack cabinets each is 22U tall. The first rack cabinet should be dedicated only to accommodate nodes that are always available such as NameNode (primary and secondary), JobTracker, and HBase Master. The other two rack cabinets should contain only SlaveNodes.</p>

<p>All nodes in a rack should be interconnected with a 1 GbE (Gigabit Ethernet) switch, and these three rack-level switch should be interconnected with a cluster level switch which is typically faster (for example a 10 GbE switch).</p>

<p>This is only a starting point! The remaining hardware choices may vary a lot&#8230; I can recommend you to read the Cluster Planning Guide of <a href="http://hortonworks.com">Hortonworks</a>.</p>

<h2>Install an Apache Hadoop Distribution</h2>

<p>Apache Hadoop and all its friends can be installed manually on a Linux distribution by following the official <a href="https://hadoop.apache.org/docs/current2/index.html">guide</a>, but it is strongly suggested to instal an Hadoop distribution: At the moment the commercial <a href="http://www.cloudera.com">Cloudera CDH</a> seems to be a good choise. It is a Linux distribution based on the stable CentOS (Red Hat) and it has pre-installed all the utilities used in an Hadoop cluster.</p>

<p>Another distribution, 100% open source and freely downloadable, is <a href="http://hortonworks.com">Hortonworks Data Platform</a>: this distribution is lightweight and can be used with Microsoft Windows too.</p>

<p>There are many other Apache Hadoop distributions, for example <a href="http://www.ibm.com/big-data/us/en/">IBM Appliances</a> and <a href="http://www.windowsazure.com/en-us/services/hdinsight/">Microsoft HDInsight Service</a>: you only have to choose and try.</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">fsferrara</span></span>

      




<time class='entry-date' datetime='2014-02-21T19:39:20+00:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>21</span><span class='date-suffix'>st</span>, <span class='date-year'>2014</span></span> <span class='time'>7:39 pm</span></time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/system-administration/'>system administration</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://fsferrara.github.io/planning-cluster-hadoop-bigdata/" data-via="fsferrara" data-counturl="http://fsferrara.github.io/planning-cluster-hadoop-bigdata/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/building-web-applications-scala/" title="Previous Post: Building web applications with Scala">&laquo; Building web applications with Scala</a>
      
      
        <a class="basic-alignment right" href="/running-containers-with-docker/" title="Next Post: Running containers with Docker">Running containers with Docker &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2018/01/05/blogging-with-octopress-and-jekyll/">Blogging With Octopress and Jekyll</a>
      </li>
    
      <li class="post">
        <a href="/getting-started-with-graphql/">Getting Started With GraphQL</a>
      </li>
    
      <li class="post">
        <a href="/my-eight-rules-to-effectively-work-in-a-global-team/">My Eight Rules to Effectively Work in a Global Team</a>
      </li>
    
      <li class="post">
        <a href="/aspect-oriented-programming-with-spring-and-aspectj/">Aspect Oriented Programming With Spring and AspectJ</a>
      </li>
    
      <li class="post">
        <a href="/running-containers-with-docker/">Running Containers With Docker</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/fsferrara">@fsferrara</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'fsferrara',
            count: 5,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>



<section class="googleplus googleplus-hidden">
  <h1>
    <a href="https://plus.google.com/+SaverioFerrara?rel=author">
      <img src="http://www.google.com/images/icons/ui/gprofile_button-32.png" width="32" height="32">
      Google+
    </a>
  </h1>
</section>



  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2018 - Saverio Ferrara -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'fsferrara';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://fsferrara.github.io/planning-cluster-hadoop-bigdata/';
        var disqus_url = 'http://fsferrara.github.io/planning-cluster-hadoop-bigdata/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
