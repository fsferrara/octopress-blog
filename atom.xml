<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Saverio Ferrara]]></title>
  <link href="http://fsferrara.github.io/atom.xml" rel="self"/>
  <link href="http://fsferrara.github.io/"/>
  <updated>2018-01-07T01:45:01+01:00</updated>
  <id>http://fsferrara.github.io/</id>
  <author>
    <name><![CDATA[Saverio Ferrara]]></name>
    <email><![CDATA[me@fsferrara.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Blogging With Octopress and Jekyll]]></title>
    <link href="http://fsferrara.github.io/blog/2018/01/05/blogging-with-octopress-and-jekyll/"/>
    <updated>2018-01-05T23:01:08+01:00</updated>
    <id>http://fsferrara.github.io/blog/2018/01/05/blogging-with-octopress-and-jekyll</id>
    <content type="html"><![CDATA[<p>Nowadays, most blogs are powered by <em>Wordpress</em>. I am a Wordpress users too and I have to admit it is really a great for blogs.<br/>
As others CMS, Wordpress requires a database and PHP in order to process the <strong>dynamic</strong> pages server-side.
<em>Jekyll</em> is a static site generator. With it I can generate all my blog pages in on my computer and then publish the entire website on a static hosting server.</p>

<!--more-->


<h2>Prepare the Jekyll environment</h2>

<p>The first drawback is that you need to set-up a local dev environment in order to be able to generate a static website on your machine. For Jekyll/Octopress you need several tool: git, ruby with bundler, and a javascript runtime.</p>

<h3>git</h3>

<p>I bet you already know what git is.</p>

<h3>ruby</h3>

<p>Ruby is an open source programming language. In order to install it locally, the are convenient ways such as <a href="http://rbenv.org/">rbenv</a> or <a href="https://rvm.io/">rvm</a>.
Make sure to install at least ruby 1.9.3 in order to be compatible with <em>Octopress</em> 3.0 and check with:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; ruby --version
</span><span class='line'>ruby 2.4.3p205 (2017-12-14 revision 61247) [x86_64-darwin16]</span></code></pre></td></tr></table></div></figure>


<h3>A javascript runtime</h3>

<p>My favourite javascript runtime is <a href="https://nodejs.org/">nodejs</a>. A convenient way to install it is <a href="https://github.com/creationix/nvm">nvm</a>. After the installation you can check it with:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; node --version
</span><span class='line'>v6.11.2</span></code></pre></td></tr></table></div></figure>


<h3>Bundler</h3>

<p>Ruby libraries are, almost always, distributed in form of ruby-gems (in short <em>gems</em>).<br/>
<strong>Bundler</strong> provides a consistent environment for ruby projects by tracking and installing the exact gems and versions that are needed. All the <em>gems</em> dependencies are declared in the <strong>Gemfile</strong> and jekyll websites usually have a Gemfile for the dependencies.</p>

<p>Bundler is a gem itself and to install it (globally in your ruby environment) just type:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>gem install bundler</span></code></pre></td></tr></table></div></figure>


<p>Note: if you are using an old version of <em>rbenv</em>, then you&rsquo;ll need to run <code>rbenv rehash</code> in order to be able to start using <em>bundler</em>.</p>

<h2>Start a new website</h2>

<p>For my first experience with <em>Jekyll</em> I am going with <em>Octopress</em> (a blogging framework based on Jekyll). It is basically Jekyll with a new graphic theme and additional plugins.
To start clone the Octopress source code <code>git clone git://github.com/imathis/octopress.git octopress</code> and then:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; cd octopress/
</span><span class='line'>[git:master]&gt; bundle install</span></code></pre></td></tr></table></div></figure>


<p>With <code>bundle install</code> we are downloading all the gems needed to generate the website locally.<br/>
A very special gem is <em>rake</em>, a <em>Make-like</em> task-runner implemented in ruby. It is used in Octopress to simplify some development task that are usually performed manually when using a plain Jekyll installation.
For example, I used <code>bundle exec rake setup_github_pages</code> to publish my local website to github-pages. This task created a <em>source</em> branch for the local <em>Octopress</em> installation and setup a <em>master</em> branch in the <em>_deploy</em> subfolder.</p>

<p> pushed the local octopress installation to the <em>source</em> branch of my github repository.</p>

<h3>Setup an Octopress theme</h3>

<p>In order to use the default theme, just type:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[git:source *]&gt; bundle exec rake install
</span><span class='line'>## Copying classic theme into ./source and ./sass
</span><span class='line'>mkdir -p source
</span><span class='line'>cp -r .themes/classic/source/. source
</span><span class='line'>mkdir -p sass
</span><span class='line'>cp -r .themes/classic/sass/. sass
</span><span class='line'>mkdir -p source/_posts
</span><span class='line'>mkdir -p public</span></code></pre></td></tr></table></div></figure>


<p>The <em>classic</em> theme has been copied in the <em>source</em> and <em>sass</em> directories.
Also the <em>public</em> folder has been created: it will host my generated pages.</p>

<h3>Generate the static website</h3>

<p>Using <em>rake</em>, just issue:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[git:source *]&gt; bundle exec rake generate
</span><span class='line'>## Generating Site with Jekyll
</span><span class='line'>directory source/stylesheets
</span><span class='line'>    write source/stylesheets/screen.css
</span><span class='line'>Configuration file: /opt/home/github/fsferrara/octopress/_config.yml
</span><span class='line'>            Source: source
</span><span class='line'>       Destination: public
</span><span class='line'>      Generating...
</span><span class='line'>                    done.
</span><span class='line'> Auto-regeneration: disabled. Use --watch to enable.</span></code></pre></td></tr></table></div></figure>


<h3>Generate the static website</h3>

<p>Always using <em>rake</em>, just issue <code>bundle exec rake deploy</code>.</p>

<h3>Commit the website source</h3>

<p>This is the Jekyll feature I like most: I can version the source code of the website :-)
For the first commit:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[git:source *]&gt; git add .
</span><span class='line'>[git:source +]&gt; git commit -m "my first octopress commit"
</span><span class='line'>[git:source]&gt; git push origin source</span></code></pre></td></tr></table></div></figure>


<p>Since I am using github as hosting solution, I have a <em>source</em> branch containing the source code of the blog, and a <em>master</em> branch (linked to the <em>_deploy</em> subfolder) containing the generated website.</p>

<h3>Restoring the local website on a new computer</h3>

<p>Or at least, restoring the local website on the same computer with a new os installation.<br/>
The steps are:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; git clone https://github.com/fsferrara/fsferrara.github.io.git
</span><span class='line'>&gt; cd fsferrara.github.io
</span><span class='line'>[git:master]&gt; git checkout source
</span><span class='line'>[git:source]&gt; git clone https://github.com/fsferrara/fsferrara.github.io.git _deploy
</span><span class='line'>[git:source]&gt; bundle install
</span><span class='line'>[git:source]&gt; bundle exec rake generate
</span><span class='line'>[git:source]&gt; bundle exec rake deploy</span></code></pre></td></tr></table></div></figure>


<p>The procedure is quite the same, except the fact I had to clone the <em>master</em> branch in the <em>_deploy</em> subfolder because I am using github-pages.</p>

<h2>My first post with Octopress</h2>

<p>My first post is exactly this one you are now reading. As per Jekyll convention it is named in a format like <code>YYYY-MM-DD-post-title.markdown</code> and it is placed in the <em>source/_posts</em> directory.
Anyway, the <em>new_post</em> rake task simplify the operation of adding a new post. I could have run this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[git:source]&gt; bundler exec rake new_post["Blogging with Octopress and Jekyll"]
</span><span class='line'>mkdir -p source/_posts
</span><span class='line'>Creating new post: source/_posts/2018-01-05-blogging-with-octopress-and-jekyll.markdown</span></code></pre></td></tr></table></div></figure>


<p>to have the new post file in the <em>source/_posts</em> folder. Additionally, the post file is created with the standard <strong>Front Matter</strong>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[git:source]&gt; cat source/_posts/2018-01-05-blogging-with-octopress-and-jekyll.markdown
</span><span class='line'>---
</span><span class='line'>layout: post
</span><span class='line'>title: "Blogging with Octopress and Jekyll"
</span><span class='line'>date: 2018-01-05 23:01:08 +0100
</span><span class='line'>comments: true
</span><span class='line'>categories:
</span><span class='line'>---</span></code></pre></td></tr></table></div></figure>


<p><em>Front matter</em> is where Jekyll starts to get really cool. Any file that contains a <a href="https://jekyllrb.com/docs/frontmatter/">YAML front matter</a> block will be processed by Jekyll as a special file. This block adds meta-data to the file sush as permalink, categories, tags, and so on.</p>

<h2>The about page</h2>

<p>Similar to the post creation, the rake task <em>new_page</em> helps to create new pages.<br/>
For the usual <em>about</em> page: <code>bundle exec rake new_page["about"]</code>. Here are <a href="http://octopress.org/docs/blogging/">more information about Octopress pages</a>.</p>

<p>The <em>about</em> page usually has a link in the main menu. To add such a link, modify the file <code>source/_includes/custom/navigation.html</code> to add a new entry.</p>

<h2>Preview the changes locally before publishing</h2>

<p>Jekyll is able to generate and serve the static website locally. Octopress offers the rake task <code>bundle exec rake preview</code> that starts a web server locally listening at *<a href="http://localhost:4000/*.">http://localhost:4000/*.</a>
This task will also watch for local changes and apply them immediately to the local preview.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With GraphQL]]></title>
    <link href="http://fsferrara.github.io/getting-started-with-graphql/"/>
    <updated>2017-12-10T22:53:50+00:00</updated>
    <id>http://fsferrara.github.io/getting-started-with-graphql</id>
    <content type="html"><![CDATA[<div>
  What is GraphQL? The <a href="http://facebook.github.io/graphql/October2016/">draft RFC specification</a> (October 2016), defines it as &#8220;a query language created by Facebook in 2012 for describing the capabilities and requirements of data models for client‐server applications&#8221;. More simply, GraphQL is a language specification for API. It defines in which way the client should query the server, and in which way the server should execute those queries.
</div>




<div>
  <!--more-->
</div>




<div>
</div>




<div>
  From the definition above, it is clear that GraphQL can be adopted as an alternative to REST. Let&#8217;s now analyze its features with an example in order to understand GraphQL base concepts.<br /> Think about your favourite website for booking hotel rooms, that is obviously <a href="https://www.hotels.com/">hotels.com</a>, and let&#8217;s try to design a GraphQL service that provides the reservation list for a specific user.
</div>


<h2>Data model</h2>

<div>
  The first thing to do is defining the graph of the data provided by the service.
</div>




<div>
  The <strong>data model</strong> we are going to define follows this structure:
</div>




<div>
  <pre class="striped:false nums:false lang:default highlight:0 decode:true">+--------------------------------------+         +----------------------------+         +---------------------+
| QueryType                            |         | ReservationType            |         | HotelType           |
+--------------------------------------+         +----------------------------+         +---------------------+
|                                      |         |                            |         |                     |
| reservationList: [ReservationType!]! +-------&gt; | hotelId: ID!               |         | hotelName: String!  |
|                                      |         | checkIn: String!           |         | fullAddress: String |
+--------------------------------------+         | checkOut: String!          |         | starRating: Int!    |
                                                 | hotelDetails: HotelType!   +-------&gt; |                     |
                                                 | status: ReservationStatus! |         +---------------------+
                                                 |                            |
                                                 +----------------------------+</pre>

  <p>
    GraphQL models your data as a graph but it still needs entry points to that graph. Those entry points are the queries defined in the QueryType, that is the root of all the queries.<br /> In this example, it is defined only one query named &#8220;reservationList&#8221; that returns a list of &#8220;ReservationType&#8221;. In turn, ReservationType describes a hotel reservation and HotelType describe a hotel.
  </p>

  <h2>
    GraphQL Schema definition
  </h2>

  <p>
    Using the &#8220;<em>GraphQL schema language</em>&#8220;, explained in the <a href="http://graphql.org/learn/schema/">official GraphQL website</a>, our <strong>data model</strong> can be described in this way:
  </p>
</div>




<div>
  <pre class="lang:default highlight:0 decode:true">schema {
    query: QueryType
}
 
type QueryType {
  reservationsList(userId: ID!): [ReservationType!]!
}
 
type ReservationType {
  hotelId: ID!
  checkIn: String!
  checkOut: String!
  hotelDetails: HotelType!
  status: ReservationStatus!
}
 
type HotelType {
  hotelName: String!
  fullAddress: String
  starRating: Int!
}
 
enum ReservationStatus {
  UPCOMING
  COMPLETED
  CANCELLED
}</pre>

  <p>
    In very short, in this graphql<strong> schema definition</strong> we have:
  </p>
</div>




<div>
  <ul>
    <li>
      the keyword &#8220;schema&#8221;, that is the root of the schema;
    </li>
    <li>
      ID, String, and Int are built-in <a href="http://graphql.org/learn/schema/#scalar-types">Scalar Types</a>;
    </li>
    <li>
      ReservationStatus is an <a href="http://graphql.org/learn/schema/#enumeration-types">Enumeration Type</a>;
    </li>
    <li>
      the others are <a href="http://graphql.org/learn/schema/#object-types-and-fields">Object Types</a>.
    </li>
  </ul>
</div>




<div>
  This GraphQL schema can be parsed in order to be used for a real service. For instance, Apollo &#8220;<a href="https://github.com/apollographql/graphql-tools">graphql tools</a>&#8221; is a javascript utility for parsing such a schema.
</div>


<h2>Query example</h2>

<div>
  This is an example of a query, valid for our schema:
</div>




<div>
  <pre class="lang:default highlight:0 decode:true">{
  reservationsList(userId: 12345) {
    hotelId
    checkIn
    checkOut
    hotelDetails {
      hotelName
      fullAddress
      starRating
    }
    status
  }
}</pre>

  <p>
    This query is sent from the client to the server in order to request the list of hotel ids in which the user number 12345 has made a reservation. Once the server receives this query, it is validated against the defined schema and then it is executed.
  </p>

  <h2>
    Response example
  </h2>

  <p>
    The generated response is JSON with the exact shape of the request:
  </p>
</div>




<div>
  <pre class="lang:default decode:true">{
  "data": {
    "reservationsList": [
      {
        "hotelId": "103",
        "checkIn": "2018-11-29",
        "checkOut": "2018-11-30",
        "hotelDetails": {
          "hotelName": "Hotel Campanile Metz Nord - Talange",
          "fullAddress": "Zone Actipole, Talange, Moselle, 57525, France",
          "starRating": 5
        },
        "status": "UPCOMING"
      }
    ]
  }
}</pre>
</div>




<div>
  Please note that the client asks only for the data it needs, and with only one query. This is an advantage of using GraphQL because, in general, it <span style="text-decoration: underline;">reduces the number of roundtrips</span> and <span style="text-decoration: underline;">minimizes the amount of data transferred on the network</span>.
</div>


<h2>Query execution</h2>

<div>
  But what happened on the server when a query is executed?
</div>




<div>
  Every field has a function associated with it, and every time the server needs to produce that field then that function is executed. Those functions are named <strong>resolvers</strong>.
</div>




<div>
  In this specific example, it is defined a custom resolver for &#8220;reservationList&#8221; that provides a list of reservations and a custom resolver for &#8220;hotelDetails&#8221; that provides the necessary details for each hotel. For all the others fields, a built-in resolver is used to produce a scalar value.
</div>




<div>
  If you are interested in analyzing the entire source code for this example, with the complete resolvers definition, you can find a really nice <a href="https://github.com/fsferrara/from-rest-to-graphql-meetup">javascript implementation on github</a> :-).
</div>




<div>
</div>




<div>
  The execution aspect of a GraphQL server is described <a href="http://graphql.org/learn/execution/">here</a>. Once again, GraphQL is not an implementation: it only defines aspect for servers to execute queries. Even if GraphQL is not a ready-to-use library, there are already <a href="http://graphql.org/code/">several GraphQL implementations</a> such as graphql.js, graphql-ruby, graphql-java, and so on.
</div>


<h2>Introspection</h2>

<div>
  A really cool feature of a GraphQL service is the <a href="http://graphql.org/learn/introspection/">ability to introspect</a> itself. Every GraphQL server has a special schema field at the query root named &#8220;__schema&#8221;:
</div>




<div>
  <pre class="lang:default decode:true">{
  __schema {
    ...
  }
}</pre>

  <p>
    Using that field, the service can expose the definition of every object and every field it can provide. This leads to really nice features like:
  </p>
</div>


<ul>
<li><span style="text-decoration: underline;">Auto documentation</span>: the client knows the exact GraphQL schema.</li>
<li><span style="text-decoration: underline;">Code generation</span>: the client can use a client generated from the schema.</li>
<li><span style="text-decoration: underline;">Static validation</span>: the GraphQL client can validate the query before sending it to the server</li>
</ul>


<div>
  As a consequence, there are available very useful tools like <a href="https://github.com/graphql/graphiql">GraphiQL</a>, that is a kind of schema explorer for GraphQL. It is really useful to try and discover server features.
</div>


<h2>HTTP Caching</h2>

<div>
  We get a lot of advantages using GraphQL, but there are also drawbacks. The one I faced is HTTP caching.
</div>




<div>
  A GraphQL endpoint can receive queries in different formats and it is really hard to define a caching policy server-side. Often the solution is to use a client-side cache. There are already libraries to implement normalized cache client-side, such as <a href="https://www.apollographql.com/">Apollo</a> and <a href="http://facebook.github.io/relay/">Relay</a>.
</div>




<div>
  Even if caching on the client is a good solution in most cases, I believe this situation can be improved in the future.
</div>




<div>
  For instance, a &#8220;smart&#8221; cache system can analyze a GraphQL request and understand which part of the query can take advantage of the cache.
</div>


<h2>Conclusion</h2>

<div>
  Personally, I am quite happy in using GrapQL server-side and I tend to prefer it over REST. I think the most valuable advantage is the fact that clients already know how to query a GraphQL service and this makes integration straightforward.
</div>




<div>
  Anyway, this article covers only a few GraphQL features. There are more such as mutations, subscriptions, deferred queries, live queries, and batch operations. Please refer to the official <a href="http://graphql.org/">GraphQL website</a> for further information.
</div>




<div>
  A really useful resource is <a href="https://www.howtographql.com/">https://www.howtographql.com/</a> which contains free tutorials to learn all about GraphQL covering several GraphQL implementations.
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My Eight Rules to Effectively Work in a Global Team]]></title>
    <link href="http://fsferrara.github.io/my-eight-rules-to-effectively-work-in-a-global-team/"/>
    <updated>2016-06-16T08:24:12+00:00</updated>
    <id>http://fsferrara.github.io/my-eight-rules-to-effectively-work-in-a-global-team</id>
    <content type="html"><![CDATA[<p>I still remember when I joined Hotels.com technology team and how much excited I was to start such a new challenge. Since the very early days I realised that working in a global company is quite different from working in the same building. That is obvious, I know, but it wasn’t easy to get used to the new way of working.</p>

<p>I missed getting in touch with new teammates, and sometimes felt isolated from others and had the feeling of being a remote worker. Actually working in a global team has a lot in common with the remote work, and in this article I will list all of the good practices that allowed me to collaborate effectively with colleagues scattered across the world.</p>

<!--more-->


<ol>
<li><strong>Know Every Collaboration Tool</strong></li>
</ol>


<p>Get familiar with the standard company collaboration tools for <strong>chat</strong>, <strong>wiki</strong>, <strong>ticketing</strong> and <strong>video-conferencing</strong>.</p>

<p>They are now my best friends in the day-to-day work. As a good practice I also have backup tools for chat and video-conferencing: in the case one of them doesn&#8217;t work for some reason, don&#8217;t waste time, just move to the next one.</p>

<ol start="2">
  <li>
    <strong> Communicate Asynchronously</strong>
  </li>
</ol>


<p>A global environment is not an office. Often the most effective way to communicate is asynchronously, that means stop writing tons of email and start using issue mentions and chat tools. Tickets can be read from the entire team and for this reason it is important to properly use those tools even if people are working from the same location.</p>

<ol start="3">
  <li>
    <strong> Be Available</strong>
  </li>
</ol>


<p>Be 100% available in the chat during working hours.</p>

<p>This is the main communication channel and if I am not available then people just think I am probably out of office.</p>

<ol start="4">
  <li>
    <strong> Communicate Your Status</strong>
  </li>
</ol>


<p>Make it clear for everyone what you are working on. Also during meetings with your boss or other colleagues ask for feedback on your work, just to know if you&#8217;re on the right track.</p>

<p>For example, I do this by assigning to me the ticket in progress and by updating it in a regular way.</p>

<ol start="5">
  <li>
    <strong> Plan The Future</strong>
  </li>
</ol>


<p>Do not talk too much about the past, but use the meetings to plan the future. Sharing future plans will increase the chances to work together and allow to save time.</p>

<ol start="6">
  <li>
    <strong> Do Be Seen</strong>
  </li>
</ol>


<p>Don’t be shy and show your face during online meetings. There is no need to avoid face-to-face meetings, even if we need them only for a minute.</p>

<p>Unfortunately I never tried any sort of always-on video portals like Perch (<a href="https://perch.co/">https://perch.co/</a>), but I would like to have one of those portals in the relax area in order to enjoy a coffee break with remote colleagues.</p>

<ol start="7">
  <li>
    <strong> Bond in Real Life</strong>
  </li>
</ol>


<p>Take advantage of business trips to also spend time with others and make sure to do have fun together. Any opportunity to &#8220;team build” will improve collaboration with colleagues.</p>

<ol start="8">
  <li>
    <strong> Say Thank You</strong>
  </li>
</ol>


<p>If someone helps me in some way, then I like to use mentions in order to highlight it and give credit. It always feels good to receive a thanks and it will make future collaborations easier.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Aspect Oriented Programming With Spring and AspectJ]]></title>
    <link href="http://fsferrara.github.io/aspect-oriented-programming-with-spring-and-aspectj/"/>
    <updated>2015-12-18T23:57:23+00:00</updated>
    <id>http://fsferrara.github.io/aspect-oriented-programming-with-spring-and-aspectj</id>
    <content type="html"><![CDATA[<p><strong>Aspect-Oriented Programming</strong> (<em>AOP</em>) powerfully complements <strong>Object-Oriented Programming</strong> (<em>OOP</em>) by providing another way of thinking about program structure.</p>

<p>Drawing a comparison between AOP and OOP we can say that the key unit of modularity in OOP is the class, whereas in AOP the unit of modularity is the aspect. With aspects, you can group application behaviour that was once spread throughout your applications into reusable modules. You can then declare exactly where and how this behaviour is applied. This reduces code duplication and lets your classes focus on their main functionality.</p>

<p><!--more-->The concept of a general-purpose aspect is introduced where an aspect transparently forces crosscutting behaviour on object classes and other software entities.</p>

<p>From Wikipedia, the free encyclopedia, we can read:</p>

<blockquote><p>“In computing, Aspect-Oriented programming (AOP) is a patented (by Google) programming paradigm that aims to increase modularity by allowing the separation of cross-cutting concerns. It does so by adding additional behaviour to existing code (an advice) without modifying the code itself, instead separately specifying which code is modified via a pointcut specification”</p>

<p>“This allows behaviours that are not central to the business logic (such as logging) to be added to a program without cluttering the code core to the functionality. AOP forms a basis for aspect-oriented software development”</p></blockquote>

<p>One of the key components of Spring Framework is the AOP framework it provides.</p>

<p>This article just focuses on AOP with Spring by showing you the source code of a working example.</p>

<p>Let&#8217;s start with the pom.xml containing all the dependencies we need: the spring framework with AOP (spring-aop) and AspectJ.</p>

<p><pre class="lang:xhtml decode:true" title="pom.xml">&lt;?xml version=&ldquo;1.0&rdquo; encoding=&ldquo;UTF-8&rdquo;?&gt;
&lt;project xmlns=&ldquo;<a href="http://maven.apache.org/POM/4.0.0">http://maven.apache.org/POM/4.0.0</a>&rdquo;
         xmlns:xsi=&ldquo;<a href="http://www.w3.org/2001/XMLSchema-instance">http://www.w3.org/2001/XMLSchema-instance</a>&rdquo;
         xsi:schemaLocation=&ldquo;<a href="http://maven.apache.org/POM/4.0.0">http://maven.apache.org/POM/4.0.0</a> <a href="http://maven.apache.org/xsd/maven-4.0.0.xsd">http://maven.apache.org/xsd/maven-4.0.0.xsd</a>&rdquo;&gt;
  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</p>

<p>  &lt;groupId&gt;com.fsferrara&lt;/groupId&gt;
  &lt;artifactId&gt;spring-aop-example&lt;/artifactId&gt;
  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</p>

<p>  &lt;properties&gt;
    &lt;springframework.version&gt;4.0.6.RELEASE&lt;/springframework.version&gt;
  &lt;/properties&gt;</p>

<p>  &lt;dependencies&gt;
    &lt;!&ndash; Spring framework &ndash;&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.springframework&lt;/groupId&gt;
      &lt;artifactId&gt;spring-core&lt;/artifactId&gt;
      &lt;version&gt;${springframework.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.springframework&lt;/groupId&gt;
      &lt;artifactId&gt;spring-context&lt;/artifactId&gt;
      &lt;version&gt;${springframework.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.springframework&lt;/groupId&gt;
      &lt;artifactId&gt;spring-aop&lt;/artifactId&gt;
      &lt;version&gt;${springframework.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;!&ndash; AspectJ &ndash;&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.aspectj&lt;/groupId&gt;
      &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt;
      &lt;version&gt;1.8.7&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;!&ndash; Utilities &ndash;&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
      &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
      &lt;version&gt;1.7.6&lt;/version&gt;
      &lt;type&gt;jar&lt;/type&gt;
    &lt;/dependency&gt;
  &lt;/dependencies&gt;
&lt;/project&gt;</pre></p>

<h2>Aspect Definition</h2>

<p>As stated on Wikipedia, Aspect Oriented Programming entails breaking down program logic into distinct parts called so-called concerns. The functions that span multiple points of an application are called crosscutting concerns and these crosscutting concerns are conceptually separate from the application&#8217;s business logic. There are various common good examples of aspects like logging, auditing, declarative transactions, security, and caching etc.</p>

<p>Separating these crosscutting concerns from the business logic is where AOP goes to work.</p>

<p>An Aspect is an implementation of a crosscutting concern and it is described in terms of:</p>

<ol>
<li><strong>Advice</strong>: is the Aspect purpose definition. It defines the &#8220;<em>what</em>&#8221; and the &#8220;<em>when</em>&#8221; of an aspect.</li>
<li><strong>Pointcuts</strong>: they define the&#8221;<em>where</em>&#8220;.</li>
</ol>


<p>An Aspect is attached to one or more <strong>Join Points</strong>.</p>

<p>A <em>Join Point</em> is a point in the execution of the application where an aspect can be plugged in. This point could be a method being called, an exception being thrown, or even a field being modified. These are the points where your aspect’s code can be inserted into the normal flow of your application to add new behavior.</p>

<h3>Advice</h3>

<p>Spring aspects can work with five kinds of advice:</p>

<ul>
<li><em>Before</em>: The advice functionality takes place before the advised method is invoked.</li>
<li><em>After</em>: The advice functionality takes place after the advised method completes, regardless of the outcome.</li>
<li><em>After-returning</em>: The advice functionality takes place after the advised method successfully completes.</li>
<li><em>After-throwing</em>: The advice functionality takes place after the advised method throws an exception.</li>
<li><em>Around</em>: The advice wraps the advised method, providing some functionality before and after the advised method is invoked.</li>
</ul>


<p>In our example, we are going to define the advice in this way:</p>

<p><pre class="lang:java decode:true" title="Advice definition">package com.fsferrara.spring_aop_example;</p>

<p>import org.aspectj.lang.ProceedingJoinPoint;
import org.aspectj.lang.annotation.Around;
import org.aspectj.lang.annotation.Aspect;
import org.springframework.stereotype.Component;</p>

<p>/<em>*
 * Example of an Aspect Advice definition.
 *
 * @author fsferrara
 </em>/
@Component
@Aspect
public class AspectExample {</p>

<pre><code>/**
 * Define WHAT the aspect do and WHEN to do it.
 * - WHAT: the method source code
 * - WHEN: "around" the method
 *
 * @param pjp the join point selected by the pointcut.
 * @return any object that the proxied method might return.
 * @throws Throwable anything that the proxied object might throw.
 */
@Around(value = "@annotation(PointcutExample)")
public Object whatThisAspectDo(ProceedingJoinPoint pjp) throws Throwable {
    Object returnObject;
    System.out.println("The aspect behaviour is implemented here!");
    try {
        returnObject = pjp.proceed();
    } catch (Throwable throwable) {
        throw throwable;
    }
    return returnObject;
}
</code></pre>

<p>}</pre></p>

<p>Please note that this aspect is enabled around an annotation called <em>PointcutExample</em>. It is a custom annotation we are going to define.</p>

<h3>Pointcuts</h3>

<p>If <em>advice</em> defines the “what” and “when” of aspects, then <em>pointcut</em> define the “where”. A <em>pointcut</em> definition matches one or more join points at which advice should be woven.</p>

<p>We will annotate a join point with a custom annotation in order to make it a pointcut. This is the definition of the custom annotation</p>

<p><pre class="lang:java decode:true " title="Pointcut Annotation">package com.fsferrara.spring_aop_example;</p>

<p>import java.lang.annotation.ElementType;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;
import java.lang.annotation.Target;</p>

<p>/<em>*
 * This annotation define a pointcut on a method.
 *
 * @author fsferrara
 </em>/
@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.METHOD)
public @interface PointcutExample {</p>

<p>}</pre></p>

<p>Let&#8217;s consider a simple java &#8220;hello world&#8221; class</p>

<p><pre class="lang:java decode:true">package com.fsferrara.spring_aop_example;</p>

<p>import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.stereotype.Component;</p>

<p>/<em>*
 * Simple Hello World Bean.
 *
 * @author fsferrara
 </em>/
@Component
public class HelloWorld {
    private final Logger logger = LoggerFactory.getLogger(HelloWorld.class);</p>

<pre><code>/**
 * Prints a sentence.
 */
@PointcutExample
public void printHello() {
    logger.info("I don't know anything about the aspect!");
}
</code></pre>

<p>}</pre></p>

<p>Please note that with the annotation <em>@PointcutExample</em> we are defining a pointcut on this class!</p>

<h3>Aspect</h3>

<p>To actual apply and run the aspect source code, then the existing source code should be modified in some way.</p>

<p>We can distinguish between:</p>

<ul>
<li><strong>Introductions</strong>: an introduction allows you to add new methods or attributes to existing classes. They can be introduced to existing classes without having to change them, giving them new behavior and state.</li>
<li><strong>Weaving</strong>: is the process of applying aspects to a target object by creating a proxy object. The aspects are woven into the target object at the specified join points. The weaving can take place at several points in the target object’s lifetime:

<ul>
<li><em>Compile time</em>: Aspects are woven in when the target class is compiled. This requires a special compiler.</li>
<li><em>Class-load time</em>: Aspects are woven in when the target class is loaded into the JVM. This requires a special ClassLoader that enhances the target class’s bytecode before the class is introduced into the application.</li>
<li><em>Runtime</em>: Aspects are woven in sometime during the execution of the application. Typically, an AOP container dynamically generates a proxy object that delegates to the target object while weaving in the aspects. This is how Spring AOP aspects are woven.</li>
</ul>
</li>
</ul>


<p>Since Spring AOP is built around dynamic proxies, then AOP support is limited to method interception. So Spring AOP module provides interceptors to intercept an application, for example, when a method is executed, you can add extra functionality before or after the method execution.</p>

<h2>AspectJ</h2>

<p>AspectJ is an aspect-oriented programming (AOP) extension created at PARC for the Java programming language. There is a lot of synergy between the Spring and AspectJ projects, and the AOP support in Spring borrows a lot from the AspectJ project.</p>

<p>Definitely AspectJ can complement Spring’s AOP framework. For example wiring advice and pointcuts in Spring is much easier with the addition of @AspectJ annotation support.</p>

<p>As you noticed in our example we are using the Spring AOP with the AspectJ annotation.</p>

<p>To completely do that we should define the application context enabling AOP:</p>

<p><pre class="lang:xhtml decode:true " title="Spring Application Context Definition">&lt;?xml version=&ldquo;1.0&rdquo; encoding=&ldquo;UTF-8&rdquo;?&gt;
&lt;beans xmlns:xsi=&ldquo;<a href="http://www.w3.org/2001/XMLSchema-instance">http://www.w3.org/2001/XMLSchema-instance</a>&rdquo;
       xmlns:context=&ldquo;<a href="http://www.springframework.org/schema/context">http://www.springframework.org/schema/context</a>&rdquo;
       xmlns:aop=&ldquo;<a href="http://www.springframework.org/schema/aop">http://www.springframework.org/schema/aop</a>&rdquo;
       xmlns=&ldquo;<a href="http://www.springframework.org/schema/beans">http://www.springframework.org/schema/beans</a>&rdquo;
       xsi:schemaLocation=&ldquo;<a href="http://www.springframework.org/schema/beans">http://www.springframework.org/schema/beans</a>
    <a href="http://www.springframework.org/schema/beans/spring-beans-3.1.xsd">http://www.springframework.org/schema/beans/spring-beans-3.1.xsd</a>
    <a href="http://www.springframework.org/schema/context">http://www.springframework.org/schema/context</a>
    <a href="http://www.springframework.org/schema/context/spring-context-2.5.xsd">http://www.springframework.org/schema/context/spring-context-2.5.xsd</a>
    <a href="http://www.springframework.org/schema/aop">http://www.springframework.org/schema/aop</a>
    <a href="http://www.springframework.org/schema/aop/spring-aop-3.1.xsd">http://www.springframework.org/schema/aop/spring-aop-3.1.xsd</a>&rdquo;&gt;</p>

<p>  &lt;context:component-scan base-package=&ldquo;com.fsferrara.spring_aop_example&rdquo;/&gt;
  &lt;aop:aspectj-autoproxy/&gt;</p>

<p>  &lt;bean id=&ldquo;main&rdquo; class=&ldquo;com.fsferrara.spring_aop_example.Main&rdquo;&gt;
  &lt;/bean&gt;</p>

<p>&lt;/beans&gt;
</pre></p>

<p>The last thing is to load the application context and start the application.</p>

<p>This can be done with a simple Main class.</p>

<p><pre class="lang:java decode:true " title="Main Class">package com.fsferrara.spring_aop_example;</p>

<p>import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.ApplicationContext;
import org.springframework.context.support.ClassPathXmlApplicationContext;</p>

<p>/<em>*
 * Simple Main.
 * @author fsferrara
 </em>/
public class Main {</p>

<pre><code>private final HelloWorld helloWorld;

/**
 * Simple auto-wired constructor.
 *
 * @param helloWorld the application bean proxied by spring AOP.
 */
@Autowired
public Main(HelloWorld helloWorld) {
    this.helloWorld = helloWorld;
}

/**
 * Calls the proxied method.
 */
public void start() {
    this.helloWorld.printHello();
}

/**
 * Starts Spring application context.
 *
 * @param args if any
 */
public static void main(String[] args) {
    ApplicationContext context = new ClassPathXmlApplicationContext("spring/applicationContext.xml");
    Main main = (Main) context.getBean("main");
    main.start();
}
</code></pre>

<p>}</pre></p>

<p>Although Spring AOP is sufficient for many applications of aspects, it’s a weak AOP solution when contrasted with AspectJ. AspectJ offers many types of pointcuts that aren’t possible with Spring AOP.</p>

<p><span style="line-height: 1.5;">For instance there are times when Spring AOP isn’t enough, and you must turn to AspectJ for more powerful aspects. Constructor pointcuts, for example, are convenient when you need to apply advice on the creation of an object.</span></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running Containers With Docker]]></title>
    <link href="http://fsferrara.github.io/running-containers-with-docker/"/>
    <updated>2015-04-03T17:03:29+00:00</updated>
    <id>http://fsferrara.github.io/running-containers-with-docker</id>
    <content type="html"><![CDATA[<p><strong>Docker</strong> is an open platform for developers and sysadmins to build, ship, and run distributed applications. Consisting of <strong>Docker Engine</strong>, a portable, <em>lightweight runtime and packaging tool</em>, and <strong>Docker Hub</strong>, a <em>cloud service for sharing applications and automating workflows</em>, Docker enables apps to be quickly assembled from components and eliminates the friction between development, QA, and production environments. As a result, IT can ship faster and run the same app, unchanged, on laptops, data center VMs, and any cloud.</p>

<p>This post describes how to run Docker machines with the help of Boot2Docker.</p>

<!--more-->


<h2>Boot2Docker {#boot2docker}</h2>

<p>Boot2Docker is a lightweight Linux distribution made specifically to run Docker containers. It is currently designed and tuned <strong>for development</strong>. Using it for <em>any kind of production workloads at this time is highly discouraged</em>.</p>

<p>After boot2docker installation, we can download the boot2docker-vm by typing this command:</p>

<pre><code>saverio@mstar:boot2docker &gt; boot2docker init
</code></pre>

<p>this will download and install into <strong>VirtualBox</strong> a VM.</p>

<pre><code>saverio@mstar:boot2docker &gt; VBoxManage list vms
"boot2docker-vm" {0c34b443-1f74-44c6-88cb-f8cb5fd885c9}
</code></pre>

<p>The boot2docker-vm VM is switched off. To urn it on type the command:</p>

<pre><code>saverio@mstar:boot2docker &gt; boot2docker up
Waiting for VM and Docker daemon to start...
.........................ooooooooooooooooooooooooo
Started.
Writing /Users/saverio/.boot2docker/certs/boot2docker-vm/ca.pem
Writing /Users/saverio/.boot2docker/certs/boot2docker-vm/cert.pem
Writing /Users/saverio/.boot2docker/certs/boot2docker-vm/key.pem

To connect the Docker client to the Docker daemon, please set:
    export DOCKER_HOST=tcp://192.168.59.103:2376
    export DOCKER_CERT_PATH=/Users/fferrara/.boot2docker/certs/boot2docker-vm
    export DOCKER_TLS_VERIFY=1
</code></pre>

<p>Boot2Docker is now up and running.</p>

<p>The Next step is to set up a Docker machine. <a href="https://hub.docker.com/">Docker Hub</a> hosts a collection of docker machines.</p>

<p>Boot2Docker sets up two <strong>network adaptors</strong>, one using NAT to allow the VM to download images and files from the internet, and a host only network that Docker container’s ports will be exposed on.</p>

<p>To expose a port you should use a command like this one</p>

<pre><code>docker run --name nginx-test -d -p 80:80 nginx
</code></pre>

<p>To start practicing with <strong>Docker</strong> let’s ssh-ing into the running boot2docker vm.</p>

<pre><code>saverio@mstar:boot2docker &gt; boot2docker ssh
                        ##        .
                  ## ## ##       ==
               ## ## ## ##      ===
           /""""""""""""""""\___/ ===
      ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ /  ===- ~~~
           \______ o          __/
             \    \        __/
              \____\______/
 _                 _   ____     _            _
| |__   ___   ___ | |_|___ \ __| | ___   ___| | _____ _ __
| '_ \ / _ \ / _ \| __| __) / _` |/ _ \ / __| |/ / _ \ '__|
| |_) | (_) | (_) | |_ / __/ (_| | (_) | (__|   &lt;  __/ |
|_.__/ \___/ \___/ \__|_____\__,_|\___/ \___|_|\_\___|_|
Boot2Docker version 1.5.0, build master : a66bce5 - Tue Feb 10 23:31:27 UTC 2015
Docker version 1.5.0, build a8a31ef
docker@boot2docker:~$
</code></pre>

<h2>Docker {#docker}</h2>

<p>The Docker Engine consists of two parts: a daemon, a server process that manages all the containers, and a client, which acts as a remote control for the daemon.</p>

<p>If you’re loggeg into the boot2docker machine, you can check if the docker daemon is running.</p>

<pre><code>docker@boot2docker:~$ docker version
Client version: 1.5.0
Client API version: 1.17
Go version (client): go1.4.1
Git commit (client): a8a31ef
OS/Arch (client): linux/amd64
Server version: 1.5.0
Server API version: 1.17
Go version (server): go1.4.1
Git commit (server): a8a31ef
</code></pre>

<p>This will verify that the daemon is running and that you can connect to it. If you can see the version number you know you are all set.</p>

<p>I found very useful the [interactive tutorial(<a href="https://www.docker.com/tryit/">https://www.docker.com/tryit/</a>) because the best way to understand Docker is to try it!</p>

<h3>Searching for images {#searchingforimages}</h3>

<p>The easiest way to get started is to use a container image from someone else. Container images are available on the Docker Hub Registry, a cloud-based collection of applications. You can find them online at Docker Hub as well <em>through the Docker Engine client command line</em>.</p>

<p>To search for a container, you can use the command <em>docker search</em>. For example:</p>

<pre><code>docker@boot2docker:~$ docker search tutorial
NAME                                       DESCRIPTION   STARS     OFFICIAL   AUTOMATED
learn/tutorial                                           8
</code></pre>

<p>Searched for a “tutorial” container.</p>

<h3>Downloading container images {#downloadingcontainerimages}</h3>

<p>Container images can be downloaded easily using <em>docker pull</em>. For images in the Docker Hub Registry, the name you specify is constructed as /.</p>

<p>To download learn/tutorial container:</p>

<pre><code>docker@boot2docker:~$ docker pull learn/tutorial
Pulling repository learn/tutorial
8dbd9e392a96: Download complete
Status: Downloaded newer image for learn/tutorial:latest
</code></pre>

<p>With a container Docker can download several layers because a docker images can consists of several layers.</p>

<h3>Run a container {#runacontainer}</h3>

<p>You can think of containers as a process in a box. The box contains everything the process might need, so it has the filesystem, system libraries, shell and such, but by default none of these are running. You <em>start</em> a container by running a process in it.</p>

<p>The command docker run takes a minimum of two arguments:</p>

<ol>
<li>an image name, and</li>
<li>the command you want to execute within that image.</li>
</ol>


<p>So, for the learn/tutorial container, it is:</p>

<pre><code>docker@boot2docker:~$ docker run learn/tutorial echo "hello world"
hello world
</code></pre>

<p>With this you have just started a container and executed a program inside of it, when the program stopped, so did the container.</p>

<h3>Installing things {#installingthings}</h3>

<p>Next we are going to install a simple utility, ping, in the container. The image is based upon ubuntu, so you can run the command <em>apt-get install -y ping</em> in the container.</p>

<p>Note that even though the container stops right after a command completes, the changes are not forgotten.</p>

<pre><code>docker@boot2docker:~$ docker run learn/tutorial apt-get install -y ping
Reading package lists...
Building dependency tree...
The following NEW packages will be installed:
  iputils-ping
0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.
Need to get 56.1 kB of archives.
After this operation, 143 kB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu/ precise/main iputils-ping amd64 3:20101006-1ubuntu1 [56.1 kB]
debconf: delaying package configuration, since apt-utils is not installed
Fetched 56.1 kB in 0s (276 kB/s)
Selecting previously unselected package iputils-ping.
(Reading database ... 7545 files and directories currently installed.)
Unpacking iputils-ping (from .../iputils-ping_3%3a20101006-1ubuntu1_amd64.deb) ...
Setting up iputils-ping (3:20101006-1ubuntu1) ...
</code></pre>

<p>That worked! You have installed a program on top of a base image. Your changes to the filesystem have been kept, but are not yet saved.</p>

<h3>Save your changes {#saveyourchanges}</h3>

<p>After you make changes (by running a command inside a container), you probably want to save those changes. This will enable you to start from this point later. With Docker, the process of saving the state is called <strong>committing</strong>. Commit basically saves the difference between the old image and the new state.</p>

<p>To do that there are several steps. First use <em>docker ps -l</em> to find the ID of the container you created by installing ping.</p>

<pre><code>docker@boot2docker:~$ docker ps -l
CONTAINER ID        IMAGE                   COMMAND                CREATED             STATUS                     PORTS               NAMES
3cba51f3bedc        learn/tutorial:latest   "apt-get install -y    3 minutes ago       Exited (0) 3 minutes ago                       modest_cori
</code></pre>

<p>The id is 3cba51f3bedc.</p>

<p>The second step is to actually commit the changes:</p>

<pre><code>docker@boot2docker:~$ docker commit 3cba51f3bedc learn/ping
86d9da396ee3c8d9d00326838999050d75bf831a016e4a6f0611edd5f62a624b
</code></pre>

<p>That worked! Please take note that Docker has returned a new ID. This ID is the image ID.</p>

<h3>Run your new image {#runyournewimage}</h3>

<p>You have built a complete, self-contained image with the ‘ping’ utility installed named <strong>learn/ping</strong>. Your image can now run on any host that runs Docker.</p>

<p>Let’s try it now with a ping to the host google.com:</p>

<pre><code>docker@boot2docker:~$ docker run learn/ping ping google.com
PING google.com (216.58.210.46) 56(84) bytes of data.
64 bytes from lhr14s23-in-f14.1e100.net (216.58.210.46): icmp_req=1 ttl=61 time=37.3 ms
64 bytes from lhr14s23-in-f14.1e100.net (216.58.210.46): icmp_req=2 ttl=61 time=36.5 ms
64 bytes from lhr14s23-in-f14.1e100.net (216.58.210.46): icmp_req=3 ttl=61 time=44.2 ms
^C
--- google.com ping statistics ---
9 packets transmitted, 9 received, 0% packet loss, time 8019ms
rtt min/avg/max/mdev = 35.384/37.963/44.248/2.814 ms
</code></pre>

<p>That worked! Note that normally you can use one of Ctrl-C, Ctrl-P, or Ctrl-Q to disconnect (I don’t know why on my Mac none of those three worked). The container will keep running until it will disconnect automatically.</p>

<p>Your image is now a running container. Using <strong>docker ps</strong> we can see a list of all running containers and using <strong>docker inspect</strong>. We can see useful information about this container.</p>

<h3>Push your image to the Docker Hub Registry {#pushyourimagetothedockerhubregistry}</h3>

<p>Now that you have verified that your image works, you can share it with others. Remember that you pulled (downloaded) the learn/tutorial image from the Registry? By pushing (uploading) images that you build, you can easily retrieve them to use on other hosts as well as share them with other users.</p>

<p>To do that the command <strong>docker push</strong> is used:</p>

<pre><code>docker@boot2docker:~$ docker push learn/ping
The push refers to a repository [learn/ping] (len: 1)
Sending image list

Please login prior to push:
Username:
</code></pre>

<p>Ops… it requires to be registered to Docker Hub so that’s all for now.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Planning a Cluster for Hadoop BigData]]></title>
    <link href="http://fsferrara.github.io/planning-cluster-hadoop-bigdata/"/>
    <updated>2014-02-21T19:39:20+00:00</updated>
    <id>http://fsferrara.github.io/planning-cluster-hadoop-bigdata</id>
    <content type="html"><![CDATA[<p>This post is about how to plan, for the first time, a cluster for Apache Hadoop and HBase. Hadoop, together with its friends, enable us to elaborate a large amount of data in a cheaply way: by large I mean data large about 100 gigabytes and above.</p>

<p>Hadoop implements the MapReduce framework, that is a way to take a query (or Job) over a dataset, divide it in several queries (or Tasks), and the run these queries in parallel over multiple node of a cluster. Nothing new until now, this looks like the divide-et-impera paradigm: the innovation lies in the fact that the cluster node that is in charge of executing a task has already the data on which process the query. So we are not moving data in order to elaborate them, but we&#8217;re assigning task on the right cluster node that already has the data!</p>

<!--more-->


<p>To distribute data across the cluster nodes, Hadoop has its own file system: HDFS (Hadoop Distributed File System), which can handle about 30PB (Petabyte) of data.</p>

<p>The drawback is that HDFS does not provide a way to have a random access to the data.</p>

<p>In order to have a Random access to the data, you can use HBase, a NoSQL and column-oriented database that run on top of HDFS. Unlike direct access to HDFS, HBase can handle about 1PB (Petabyte) of data, and the performances are 4-5 times slower.</p>

<p>Therefore Apache Hadoop is a software framework that supports large-scale distributed data analysis on commodity servers. It is critical to accurately predict the workloads for the tasks to be run. Hadoop and HBase workloads vary a lot based on the effective use, and for this reason it is really hard to correctly estimate the workloads and the amount of storage. In order to make these estimations correctly, a suitable technique is to start with a pilot project, measure the workloads, and then scale the pilot environment in order to fulfil other needs.</p>

<h2>Software components in an Hadoop Cluster</h2>

<p>There are several components in the Hadoop environment, some are:</p>

<ul>
<li><strong>HDFS</strong>

<ul>
<li><p><strong>NameNode</strong>: is a <em>master</em> node for HDFS file system.</p>

<p>Actually it doesn&#8217;t contains data and manage its slaves called DataNode</p></li>
<li><strong>DataNode</strong>: is a <em>slave</em> node for HDFS file system.</li>
<li><strong>Secondary NameNode</strong>: it is not required, but it is suggested to have a backup node for the main NameNode.</li>
</ul>
</li>
<li><strong>MapReduce</strong>

<ul>
<li><strong>JobTracker</strong>: is a <em>master</em> node for MapReduce framework.</li>
<li><strong>TaskTracker</strong>: is a <em>slave</em> node for MapReduce framework.</li>
</ul>
</li>
<li><strong>HBase</strong>

<ul>
<li><strong>HBase Master</strong>: is a <em>master</em> node for HBase.</li>
<li><strong>RegionServer</strong>: is a <em>slave</em> node for HBase.</li>
<li><strong>Zookeeper</strong>: is a separate component required by HBase, used to manage the cluster.</li>
</ul>
</li>
</ul>


<p>We can rearrange these components by separating masters from slaves.</p>

<ul>
<li><strong>Masters</strong>

<ul>
<li>HDFS NameNode</li>
<li>MapReduce JobTracker</li>
<li>HBase Master</li>
</ul>
</li>
<li><strong>Slaves</strong>

<ul>
<li>HDFS DataNode</li>
<li>MapReduce TaskTracker</li>
<li>HBase RegionServer</li>
</ul>
</li>
</ul>


<p>Masters should be on a reliable cluster node: they should be always available. Slaves, instead, are frequently decommissioned for maintenance. For this reason it it highly recommended to always separate masters from slaves and, additionally, task workloads executed on the slaves should not impact the master nodes.</p>

<p>It is extremely important to deploy together DataNodes, TaskTrackers, and RegionServers, in order to achieve an optimal data locality (this is the principle underlying the MapReduce framework). We will call <strong>SlaveNode</strong> a cluster node with a DataNode, a TaskTracker, and a RegionServer.</p>

<h2>A typical Apache Hadoop Cluster</h2>

<p>Typically, a medium size Hadoop cluster consists in a set of rack-servers (actually it is possible to use blade servers, but this article use rack servers as example): let&#8217;s say that we have four half-size rack cabinets each is 22U tall. The first rack cabinet should be dedicated only to accommodate nodes that are always available such as NameNode (primary and secondary), JobTracker, and HBase Master. The other two rack cabinets should contain only SlaveNodes.</p>

<p>All nodes in a rack should be interconnected with a 1 GbE (Gigabit Ethernet) switch, and these three rack-level switch should be interconnected with a cluster level switch which is typically faster (for example a 10 GbE switch).</p>

<p>This is only a starting point! The remaining hardware choices may vary a lot&#8230; I can recommend you to read the Cluster Planning Guide of <a href="http://hortonworks.com">Hortonworks</a>.</p>

<h2>Install an Apache Hadoop Distribution</h2>

<p>Apache Hadoop and all its friends can be installed manually on a Linux distribution by following the official <a href="https://hadoop.apache.org/docs/current2/index.html">guide</a>, but it is strongly suggested to instal an Hadoop distribution: At the moment the commercial <a href="http://www.cloudera.com">Cloudera CDH</a> seems to be a good choise. It is a Linux distribution based on the stable CentOS (Red Hat) and it has pre-installed all the utilities used in an Hadoop cluster.</p>

<p>Another distribution, 100% open source and freely downloadable, is <a href="http://hortonworks.com">Hortonworks Data Platform</a>: this distribution is lightweight and can be used with Microsoft Windows too.</p>

<p>There are many other Apache Hadoop distributions, for example <a href="http://www.ibm.com/big-data/us/en/">IBM Appliances</a> and <a href="http://www.windowsazure.com/en-us/services/hdinsight/">Microsoft HDInsight Service</a>: you only have to choose and try.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building Web Applications With Scala]]></title>
    <link href="http://fsferrara.github.io/building-web-applications-scala/"/>
    <updated>2013-11-22T11:02:39+00:00</updated>
    <id>http://fsferrara.github.io/building-web-applications-scala</id>
    <content type="html"><![CDATA[<p>Scala is general purpose programming language very popular for building web application. But why? At the moment I really don&#8217;t know why :) , I&#8217;m just reading about it and sharing my thoughts with you.</p>

<p>Let&#8217;s start from Scala. It&#8217;s a programming language both object-oriented and functional: we can refer to this kind of programming language as &#8220;object-functional&#8221;. We say that is a programming language because there is a compiler for it, but also an interpreter is available.</p>

<p>It is intended to be compiled to Java bytecode, so the resulting executable runs on the JVM, and Java libraries can be used directly in Scala code and vice-versa. Maybe this is the real strength of this language&#8230; it allows to write brand-new web application while reusing legacy java libraries. That&#8217;s awesome for a company with a bunch of old java code.</p>

<!--more-->


<h2>Scala-powered Web Framework</h2>

<p>Of course there is the possibility to simply use scala with any java-enabled web framework, but let&#8217;s choose a specialized one from the several web frameworks that use scala as main language. At the moment the main frameworks are:</p>

<ul>
<li><a href="http://liftweb.net">Lift</a> seems the most mature. As the official website states, Lift is highly secure and has the best JSON handling library in Scala: this make lift a good choice to build a web service. Moreover lift is not a traditional MVC framework, but it has a View First approach: lift loads the view first and builds your page from the view. &#8220;Why?&#8221; Because complex HTML pages rarely contain a dominant piece of logic&#8230; a single controller&#8230; but contain many different components that can interact or not.</li>
<li><a href="http://www.playframework.com">Play</a> seems to have a better documentation and videos, and looks more familiar (traditional MVC pattern). At a glance it has a better support for modern web and mobile application. It has a good support to templates, and allows writing code in Scala, Java, Javascript, Coffeescript, and others languages.</li>
<li><a>Scalatra</a> is a simple, accessible and free web micro-framework. It combines the power of the JVM with the beauty and brevity of Scala. It seems very easy to set up, and it is designed exactly to create web services. As micro-framework Scalatra doesn&#8217;t offer much functionality.</li>
</ul>


<p>In my opinion Play is the best framework here for building medium-size applications: for large application I really like the &#8220;<a href="http://stackoverflow.com/questions/13290118/differences-between-mvc-and-view-first-approach-in-web-development">View First</a>&#8221; approach, so I choose lift for a first experiment.</p>

<h2>SBT</h2>

<p>At first I thought it meant &#8220;Scala Build Tool&#8221; but actually SBT stands for &#8220;Simple Build Tool&#8221; and, even if it is more popular for Scala projects, it can be also used for Java projects.</p>

<p>SBT is the de facto build tool for the Scala community, used by both the Lift web framework and Play Framework.</p>

<p>Similar to Java&#8217;s Maven, it has a native support for compiling Scala code and integrating with many Scala test frameworks (continuous compilation, testing, and deployment). Moreover it manages dependencies using Ivy (and library for apache Ant that is compatible with apache Maven repositories). Integrated with the Scala interpreter, it supports debugging and rapid programming iteration.</p>

<p>The build file is entirely written in Scala. It is placed in the root directory of the project and the default name is &#8216;build.sbt&#8217;. This is an example:</p>

<pre lang="scala">organization := "com.fsferrara"
name := "myfirstlift"
version := "0.1-SNAPSHOT"
scalaVersion := "2.10.0"

// xsbt-web-plugin configuration
seq(webSettings :_*)

libraryDependencies ++= {
  val liftVersion = "2.5.1"
  Seq(
    "net.liftweb" %% "lift-webkit" % liftVersion % "compile",
    "org.eclipse.jetty" % "jetty-webapp" % "8.1.7.v20120910"  %
      "container,test",
    "org.eclipse.jetty.orbit" % "javax.servlet" % "3.0.0.v201112011016" %
      "container,compile" artifacts Artifact("javax.servlet", "jar", "jar")
  )
}</pre>


<p>The object &#8216;webSettings&#8217; contains the standard web configuration used to launch the web container, that is, in this example, Jetty. &#8216;Seq&#8217;, with a capital S, is the interface of a Java List: it contains the list of all the dependencies to download.</p>

<p>I took the above file from a lift webapp template I&#8217;m building. A Scala application has another SBT configuration file &#8216;project/plugins.sbt&#8217; that contains the list of plugins used by the application:</p>

<pre lang="scala">addSbtPlugin("com.earldouglas" % "xsbt-web-plugin" % "0.4.2")</pre>


<p>The <a href="https://github.com/JamesEarlDouglas/xsbt-web-plugin">xsbt-web-plugin</a> plugin is used to build Scala web application.</p>

<h2>My first Hello World lift application</h2>

<p>To complete the classic &#8220;hello world&#8221; application, we need three more files. The first one is the well-known &#8216;src/main/webapp/WEB-INF/web.xml&#8217;:</p>

<pre lang="html" escaped="true">&lt;!DOCTYPE web-app SYSTEM "http://java.sun.com/dtd/web-app_2_3.dtd"&gt;
&lt;web-app&gt;
  &lt;filter&gt;
    &lt;filter-name&gt;LiftFilter&lt;/filter-name&gt;
    &lt;display-name&gt;Lift Filter&lt;/display-name&gt;
    &lt;description&gt;The Filter that intercepts Lift calls&lt;/description&gt;
    &lt;filter-class&gt;net.liftweb.http.LiftFilter&lt;/filter-class&gt;
  &lt;/filter&gt;
  &lt;filter-mapping&gt;
    &lt;filter-name&gt;LiftFilter&lt;/filter-name&gt;
    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;
  &lt;/filter-mapping&gt;
&lt;/web-app&gt;</pre>


<p>With this file a LiftFilter servlet is instantiated and all the HTTP requests are forwarded to it. This is the entry point of the Lift framework. The next file, the &#8220;View&#8221;, is &#8216;src/main/webapp/index.html&#8217;:</p>

<pre lang="html" escaped="true">&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Lift From Scratch&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello World&lt;/h1&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre>


<p>The last one is our first &#8216;.scala&#8217; file, Finally! So we create &#8216;src/main/scala/bootstrap/Boot.scala&#8217;:</p>

<pre lang="scala">package bootstrap.liftweb

import net.liftweb.http.{Html5Properties, LiftRules, Req}
import net.liftweb.sitemap.{Menu, SiteMap}

class Boot {
  def boot {
    LiftRules.addToPackages("code")

    // Build SiteMap
    def sitemap(): SiteMap = SiteMap(
      Menu.i("Home") / "index"
    )

    // Use HTML5 for rendering
    LiftRules.htmlProperties.default.set((r: Req) =&gt;
      new Html5Properties(r.userAgent))
  }
}</pre>


<p>This file defines a &#8216;Boot&#8217; class containing only one method named &#8216;boot&#8217;. This class is instantiated early and run: it allows the application to modify lift&#8217;s environment. The first instruction of the &#8216;boot&#8217; method defines the package used to search for &#8220;Snippets&#8221; (a Snippet is the component that transforms the incoming HTML to the dynamically generated HTML).</p>

<p>Next is the definition of the SiteMap: every page on the site needs a SiteMap entry.</p>

<p>What? A class with a method? Where is the functional side of Scala?</p>

<p>Scala is an object-functional programming language. In my initial opinion it seems that only the object-oriented side of Scala is used, while only few part of code are written completely functional. Maybe the most used &#8220;functional feature&#8221; is the immutability: I read it in <a href="http://blog.manub.net/2013/11/like-immutable-objects/">this interesting post</a>.</p>

<h2>Starting our application</h2>

<p>In order to start our application, open the shell and change directory to the root of our project and type in &#8216;sbt&#8217;. Obviously you should first in install the SBT tool.</p>

<p>Now the console of SBT starts, it seems quite slow, and to download all the dependencies type the command &#8220;update&#8221;. Next to start tomcat, use the command &#8220;container:start&#8221;. By default a Jetty server will start, and we can see our first project at the address _<a href="http://localhost:8080_.">http://localhost:8080_.</a></p>

<h3>Developing with a text editor</h3>

<p>SBT has plugins available used to develop Scala application with IntelliJ Idea, Eclipse, and Netbeans. I like to develop my application with a fast text editor with few unused features. My favourite text editor now is Sublime Text, you surely know it!</p>

<p>Also I like compile and refresh my application while developing: To do that we can use SBT with this instruction:</p>

<pre lang="bash">~; container:start; container:reload /</pre>


<p>An SBT command prefixed with ~ makes that command run when files change. The first semicolon introduces a sequence of commands, where if the first command succeeds, the second will run. The second semicolon means the reload command will run if the start command ran OK. The start command will recompile any Scala source files that have changed. Honestly I don&#8217;t know what the last character (/) means.</p>

<h2>Our first Snippet</h2>

<p>Like I said before Lift adopts a view-first approach, so the first thing that is loaded is the View (in this case the HTML) and then the snippets are applied to it.</p>

<p>Our first snippet is &#8216;src/main/scala/code/snippet/HelloSnippet.scala&#8217;.</p>

<pre lang="scala">package code.snippet

import net.liftweb.util.Helpers._
import net.liftweb.util.PassThru

import scala.util.Random
import xml.Text

class HelloSnippet {
  private def fiftyFifty = Random.nextBoolean

  def render =
    if (fiftyFifty) "*" #&gt; Text("Hello Saverio")
    else PassThru
}</pre>


<p>For those of you who do not know, my name is Saverio. This snippet, with a probability of fifty percent, can change the text value of the HTML object linked to it. So the next step is to modify the view in this way:</p>

<pre lang="html" escaped="true">...
&lt;div data-lift="HelloSnippet"&gt;
  Hello World
&lt;/div&gt;
...</pre>


<p>Try it! The page can render now &#8220;Hello World&#8221; or &#8220;Hello Saverio&#8221;. All works because in the Boot class we defined the folder &#8216;code&#8217; as the place where to search for snippets (remember: <code>LiftRules.addToPackages("code")</code>)</p>

<h2>A REST endpoint written with Lift</h2>

<p>Lift makes providing REST web services very simple. REST (<a href="http://en.wikipedia.org/wiki/Representational_state_transfer">Representational State Transfer</a>) is an architectural style that abstracts the architectural elements within a distributed hypermedia system. REST ignores the details of component implementation and protocol syntax in order to focus on the roles of components: it has emerged as a predominant web API design model. For those of you who already know SOAP-based web services, the main <a href="http://stackoverflow.com/questions/2131965/main-differences-between-soap-and-restful-web-services-in-java">difference</a> between the two is that REST is almost always going to be faster, whilst SOAP is provides a mechanism for services to describe themselves to clients, and to advertise their existence. REST is much more lightweight and can be implemented using almost any tool, leading to lower bandwidth and shorter learning curve. However, the clients have to know what to send and what to expect. In general, When you&#8217;re publishing an API to the outside world that is either complex or likely to change, SOAP will be more useful. Other than that, REST is usually the better option.</p>

<p>In an extremely small nutshell REST is the convention between two systems to communicate by exchanging JSON messages.</p>

<p>Let&#8217;s write a really simple PingRest service: create the file &#8216;src/main/scala/code/lib/PingRest.scala&#8217;.</p>

<pre lang="scala">package code.lib

import net.liftweb._
import net.liftweb.http._
import net.liftweb.http.rest._
import net.liftweb.json.JsonAST._
import net.liftweb.json.JsonDSL._

object PingRest extends RestHelper {

  serve {
    case JsonGet("api" :: "ping" :: "pong" :: Nil, req) =&gt; sayHello
  }

  val sayHello: JValue = {
    (
      ("ping" -&gt; "pong")
    )
  }
}</pre>


<p>The PingRest class extend RestHelper, a helper used to speed-up the build of web services. Anyway is possible to create a web service without using RestHelper.</p>

<p>To enable this endpoint, we have to modify the Boot code. We must add, at the end of the &#8216;boot&#8217; method, this line: <code>LiftRules.dispatch.append(PingRest)</code>.</p>

<p>Now each request to the url _<a href="http://localhost:8080/api/ping/pong.json_">http://localhost:8080/api/ping/pong.json_</a> produces this answer</p>

<pre lang="json">{
  "ping":"pong"
}</pre>


<p>The libraries &#8216;net.liftweb.json.JsonAST._&#8217; and &#8216;net.liftweb.json.JsonDSL._&#8217; are used to create a JSON response.</p>

<h2>Conclusion</h2>

<p>Scala is designed to concisely express solutions in an elegant, type-safe and lightweight (low ceremonial) manner. Scala has full support for functional programming, including currying, pattern matching, algebraic data types, lazy evaluation, tail recursion, immutability, and so on.</p>

<p>Scala allows the reusing of legacy java libraries, that&#8217;s true, but I really don&#8217;t like the idea to have another language server-side. I think that adding additional languages, like Scala or Coffeescript, will only increase the complexity of our project and makes it difficult to find people who know how to work on the project.</p>

<p>Furthermore many web frameworks for Scala assume that part of Scala source code should be translated into Javascript code to be executed in the user browser: this introduces another difficulty in debugging Scala application. Other web framework use instead Javascript as main language (for example <a href="http://expressjs.com">express</a> in the MEAN stack) and in that case the code you write is the same code you should debug. Additionally you write Javascript on both client side and server side.</p>

<p>You can download all the source code in this <a href="https://github.com/fsferrara/learn-scala">collection of project</a> on github.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A GIT Branching Model for Medium-size Companies]]></title>
    <link href="http://fsferrara.github.io/git-branching-model-for-medium-size-companies/"/>
    <updated>2013-11-15T00:13:57+00:00</updated>
    <id>http://fsferrara.github.io/git-branching-model-for-medium-size-companies</id>
    <content type="html"><![CDATA[<p>This article explains how a medium size company, which has several teams, can adopt GIT for the source code management. As a software configuration management, GIT serves two different functions. The first one is the management support for controlling changes to software products, and the second one is merely development support for coordinating file changes among product developers. In particular here I want to talk about the branching model.</p>

<!--more-->


<p>The following branching model is for a single product, whereas only the last product version is maintained (i.e. a web site or a mobile app). Additionally this branching model support an agile process model, where a new product version is released (hopefully) at the end of each team sprint.</p>

<p>This proposal is based on the &#8220;branch-by-purpose&#8221; model (@see <a href="http://svn.haxx.se/users/archive-2007-10/att-0101/SCMBranchingModels.pdf">The Importance of Branching Models in SCM</a>), but it also provide a branch for the next release.</p>

<p>Main actors here are:</p>

<ul>
<li><strong>Developers</strong>, one or more developer teams</li>
<li><strong>Release manager</strong>, or a release team</li>
<li><strong>System administrator</strong>, or a sysadm team</li>
</ul>


<p>This branching model is inspired by the work of <a href="http://nvie.com/about/">Vincent Driessen</a>.</p>

<h2>Branches organization</h2>

<p>A good branching model for medium-size technology department should absolutely have these characteristics:</p>

<ul>
<li>Parallel Development</li>
<li>Collaboration</li>
<li>Release Staging</li>
<li>Support for emergency fixes (hotfix)</li>
</ul>


<p>The proposed branching model has three branches, each with an infinite life. System administrators will always use the &#8216;master&#8217; branch: everything is happy and deployable in master. Developers should always use the &#8216;develop&#8217; branch, and all teams share this branch to commit their features. Also developers can&#8217;t commit anything in the master branch, the release manager is in charge of this operation. The release manager has its own branch &#8216;candidate&#8217; in order to integrate in it the team&#8217;s patches, test these patches, promote versions, and then commit stable versions in the &#8216;master&#8217; branch. The original work <a href="http://nvie.com/posts/a-successful-git-branching-model/">GitFlow</a> does not have the &#8216;candidate&#8217; branch, but uses a new branch for each release. I, instead, prefer to have the integration branch always with the same name: this can be useful in the future for the dependencies management.</p>

<h2>Creating the three branches</h2>

<p>Once created the repository with the master branch, you can create &#8216;candidate&#8217; and &#8216;develop&#8217; branches.</p>

<pre lang="bash">[~/git]$ git clone https://github.com/fsferrara/lemon.git
Cloning into 'lemon'...
remote: Counting objects: 12, done.
remote: Compressing objects: 100% (11/11), done.
remote: Total 12 (delta 2), reused 10 (delta 0)
Unpacking objects: 100% (12/12), done.
[~/git]$ cd lemon

[master][~/git/lemon]$ git branch -a
* master
  remotes/origin/HEAD -&gt; origin/master
  remotes/origin/master

[master][~/git/lemon]$ git branch candidate master
[master][~/git/lemon]$ git branch develop candidate

[master][~/git/lemon]$ git push origin candidate
Total 0 (delta 0), reused 0 (delta 0)
To https://github.com/fsferrara/lemon.git
 * [new branch]      candidate -&gt; candidate

[master][~/git/lemon]$ git push origin develop
Total 0 (delta 0), reused 0 (delta 0)
To https://github.com/fsferrara/lemon.git
 * [new branch]      develop -&gt; develop</pre>


<p>Now we have these branches:<figure id="attachment_314" style="max-width: 250px" class="wp-caption aligncenter"></p>

<p><a href="http://www.fsferrara.com/wp-content/uploads/2013/11/00_three_branches.jpg"><img class="size-medium wp-image-314" src="http://www.fsferrara.com/wp-content/uploads/2013/11/00_three_branches-250x300.jpg" alt="Three Branches" width="250" height="300" srcset="http://www.fsferrara.com/wp-content/uploads/2013/11/00_three_branches-250x300.jpg 250w, http://www.fsferrara.com/wp-content/uploads/2013/11/00_three_branches.jpg 409w" sizes="(max-width: 250px) 100vw, 250px" /></a><figcaption class="wp-caption-text">Three Branches</figcaption></figure></p>

<h2>The features</h2>

<p>Any new feature should be developed in a separate branch. So, a developer that is on &#8216;develop&#8217; branch&#8230;</p>

<pre lang="bash">[master][~/git/lemon]$ git checkout develop
Switched to branch 'develop'
[develop][~/git/lemon]$ git branch -a
  candidate
* develop
  master
  remotes/origin/HEAD -&gt; origin/master
  remotes/origin/candidate
  remotes/origin/develop
  remotes/origin/master</pre>


<p>&#8230;must start a feature branch, and share it with its team:</p>

<pre lang="bash">[develop][~/git/lemon]$ git checkout -b myteam/amazing_feature
Switched to a new branch 'myteam/amazing_feature'

[myteam/amazing_feature][~/git/lemon]$ git push origin myteam/amazing_feature
Total 0 (delta 0), reused 0 (delta 0)
To https://github.com/fsferrara/lemon.git
 * [new branch]      myteam/amazing_feature -&gt; myteam/amazing_feature</pre>


<p>Rebasing keeps our code working, merging easy, and history clean. Developer should maintain this branch always rebased with remote branches &#8216;origin/devel&#8217; and &#8216;origin/myteam/amazing_feature&#8217;, by doing these operations:</p>

<pre lang="bash">[myteam/amazing_feature][~/git/lemon]$ git fetch origin
[develop][~/git/lemon]$ git rebase origin/develop
Current branch develop is up to date.
[develop][~/git/lemon]$ git rebase origin/myteam/amazing_feature
Current branch develop is up to date.</pre>


<p>The branch &#8216;myteam/amazing_feature&#8217; contains all the feature commits. These commit should not be done directly on the &#8216;develop&#8217; branch because anything committed to this branch can be delivered on-line without any notice. Once the feature is done, the feature branch is reintegrated in the &#8216;develop&#8217; branch.<figure id="attachment_315" style="max-width: 145px" class="wp-caption aligncenter"></p>

<p><a href="http://www.fsferrara.com/wp-content/uploads/2013/11/01_feature_branch.jpg"><img class="size-medium wp-image-315" src="http://www.fsferrara.com/wp-content/uploads/2013/11/01_feature_branch-145x300.jpg" alt="Feature Branch" width="145" height="300" srcset="http://www.fsferrara.com/wp-content/uploads/2013/11/01_feature_branch-145x300.jpg 145w, http://www.fsferrara.com/wp-content/uploads/2013/11/01_feature_branch.jpg 235w" sizes="(max-width: 145px) 100vw, 145px" /></a><figcaption class="wp-caption-text">Feature Branch</figcaption></figure></p>

<p>At this point a &#8220;merge request&#8221; can be created also to manage the code review process. To finish a feature, perform these operations:</p>

<pre lang="bash">[myteam/amazing_feature][~/git/lemon]$ git fetch
[myteam/amazing_feature][~/git/lemon]$ git rebase -i origin/develop
Successfully rebased and updated refs/heads/myteam/amazing_feature.

[master][~/git/lemon]$ git checkout develop
Switched to branch 'develop'

[develop][~/git/lemon]$ git fetch
[develop][~/git/lemon]$ git merge origin/develop
Already up-to-date.

[develop][~/git/lemon]$ git merge --no-ff myteam/amazing_feature
Merge made by the 'recursive' strategy.
 hello.js | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

[develop][~/git/lemon]$ git push origin develop
Counting objects: 1, done.
Writing objects: 100% (1/1), 241 bytes, done.
Total 1 (delta 0), reused 0 (delta 0)
To https://github.com/fsferrara/lemon.git
   cd84dc7..ee499c9  develop -&gt; develop</pre>


<p>The option &#8220;&#8211;no-ff&#8221; preserves feature history and easy full-feature reverts merge. Now we can delete the feature branch:</p>

<pre lang="bash">[develop][~/git/lemon]$ git branch -d myteam/amazing_feature
Deleted branch myteam/amazing_feature (was a30b140).

[develop][~/git/lemon]$ git push --delete origin myteam/amazing_feature
To https://github.com/fsferrara/lemon.git
 - [deleted]         myteam/amazing_feature</pre>


<h2>Integration phase and release</h2>

<p>At any time the release engineer can merge the new content of &#8216;devel&#8217; and start an integration phase, as this picture show:<figure id="attachment_316" style="max-width: 260px" class="wp-caption aligncenter"></p>

<p><a href="http://www.fsferrara.com/wp-content/uploads/2013/11/02_candidate_branch.jpg"><img class="size-medium wp-image-316" src="http://www.fsferrara.com/wp-content/uploads/2013/11/02_candidate_branch-260x300.jpg" alt="Candidate Branch" width="260" height="300" srcset="http://www.fsferrara.com/wp-content/uploads/2013/11/02_candidate_branch-260x300.jpg 260w, http://www.fsferrara.com/wp-content/uploads/2013/11/02_candidate_branch.jpg 412w" sizes="(max-width: 260px) 100vw, 260px" /></a><figcaption class="wp-caption-text">Candidate Branch</figcaption></figure></p>

<p>The integration starts with the <em>code chill</em> phase, that is the phase in which only small bugfixes are allowed. Personally I hate these bugfixes, and I prefer to perform all kind of tests directly on &#8216;devel&#8217; branch: for me the integration phase should be only the final check. Once the code is ready to be deployed in production, we have the reintegration with &#8216;master&#8217;. At this point the release engineer can create the tag directly on master. Optionally the tag to be created can point before to the head of &#8216;candidate&#8217; branch and then can be updated to point to &#8216;master&#8217;.</p>

<h2>Deploying and emergency fixes</h2>

<p>Everything is happy and up-to-date in master: the system administrator can use tags created by the release engineer to deploy a specific version of the product. This support the deploy of the latest version and also the roll-back to a previous version. Once reintegrated the branch &#8216;candidate&#8217; into &#8216;master&#8217;, a new tag is created following these steps:</p>

<pre lang="bash">[master][~/git/lemon]$ git tag -a 1.2.3 -m "Promoted on `date`"
[master][~/git/lemon]$ git tag -l
1.2.3

[master][~/git/lemon]$ git push --tags
Counting objects: 1, done.
Writing objects: 100% (1/1), 182 bytes, done.
Total 1 (delta 0), reused 0 (delta 0)
To https://github.com/fsferrara/lemon.git
 * [new tag]         1.2.3 -&gt; 1.2.3

[master][~/git/lemon]$ git ls-remote --tags origin
83fd280e796bc4134c2e7b31106b9f8ed85ecf2c    refs/tags/1.2.3
cd84dc74b39607706e8f1b110411b4a508c6f3e8    refs/tags/1.2.3^{}</pre>


<p>If for testing purpose you already created the tag 1.2.3 pointing the &#8216;candidate&#8217; branch, now you can move this tag by using the option &#8220;-f&#8221;.</p>

<p>Also the emergency bug fixes (hotfix) are supported by this model, as shown in this picture:<figure id="attachment_317" style="max-width: 190px" class="wp-caption aligncenter"></p>

<p><a href="http://www.fsferrara.com/wp-content/uploads/2013/11/03_hotfix.jpg"><img class="size-medium wp-image-317" src="http://www.fsferrara.com/wp-content/uploads/2013/11/03_hotfix-190x300.jpg" alt="Hotfix Branch" width="190" height="300" srcset="http://www.fsferrara.com/wp-content/uploads/2013/11/03_hotfix-190x300.jpg 190w, http://www.fsferrara.com/wp-content/uploads/2013/11/03_hotfix.jpg 312w" sizes="(max-width: 190px) 100vw, 190px" /></a><figcaption class="wp-caption-text">Hotfix Branch</figcaption></figure></p>

<h2>Useful configuration</h2>

<p>Autosetup rebase so that pulls operations rebase by default</p>

<pre lang="bash">git config --global branch.autosetuprebase always</pre>


<h2>DOs and DON&#8217;Ts</h2>

<p>No DO or DON&#8217;T is sacred. You&#8217;ll obviously run into exceptions, and develop your own way of doing things. However, these are guidelines I&#8217;ve found useful.</p>

<h3>DOs</h3>

<ul>
<li><em>do</em> master must always be deployable.</li>
<li><em>do</em> all changes are made through feature branches</li>
<li><em>do</em> use a &#8220;merge request&#8221; (aka &#8220;pull request&#8221;) to manage code-reviews</li>
<li><em>do</em> rebase to avoid/resolve conflicts before to merge</li>
<li><em>do</em> keep master in working order</li>
<li><em>do</em> rebase your feature branches often</li>
<li><em>do</em> tag releases</li>
<li><em>do</em> learn to rebase and merge</li>
</ul>


<h3>DON&#8217;Ts</h3>

<ul>
<li><em>don&#8217;t</em> fork</li>
<li><em>don&#8217;t</em> merge broken code.</li>
<li><em>don&#8217;t</em> commit onto master directly.</li>
<li><em>don&#8217;t</em> hotfix onto master! use a specific hotfix branch.</li>
<li><em>don&#8217;t</em> rebase master.</li>
<li><em>don&#8217;t</em> merge with conflicts. Handle conflicts upon rebasing.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GIT Explained for Subversion Users]]></title>
    <link href="http://fsferrara.github.io/git-explained-subversion-users/"/>
    <updated>2013-11-03T23:31:45+00:00</updated>
    <id>http://fsferrara.github.io/git-explained-subversion-users</id>
    <content type="html"><![CDATA[<p><code>This guide shows the most common procedures usually performed by SVN users, but using GIT.&lt;br /&gt;
Why this guide should be better than the others already on-line? There isn't a particular reason ;) . I'm now a SVN user and I'm just migrating to GIT, so I'm going to find a way to perform with GIT all the operations that I usually do with Subversion: this will be useful for Subversion users who want to start using GIT quickly.</code></p>

<!--more-->


<p>Git is a distributed revision control (DVCS) and source code management (SCM) system with an emphasis on speed. As a distributed VCS, every Git working directory is a full-fledged repository with complete history and full version tracking capabilities, not dependent on network access or a central server.</p>

<p>This is the most substantial difference with SVN where there is a central repository. With subversion, the developers working in a team used continuously exchange their code. This is deeply different with GIT because there is no a main central repository; so developer should use a given remote repository, and use it as the central one.</p>

<p>No more talk, I don&#8217;t like to talk: let&#8217;s start with GIT by examples.</p>

<p>We have two developers, obviously their user-names are Alice and Bob.</p>

<h2>GIT &#8211; Create a repository</h2>

<p>Alice wants to create a new project named &#8220;lemon&#8221;. She simply creates an empty directory and then launch the command &#8216;git init&#8217;:</p>

<pre lang="bash">[~/alice]$ mkdir lemon
[~/alice]$ cd lemon
[~/alice/lemon]$ git init
Initialized empty Git repository in /Users/fferrara/alice/lemon/.git/
[master][~/alice/lemon]$
</pre>


<p>That&#8217;s all! Alice has now a brand new repository locally (note that this is more than a working copy). The main branch is called &#8220;master&#8221;. The shell prompt has the capability to detect and print the name of the current branch (this is the zsh shell default behaviour).</p>

<h2>GIT &#8211; Your first commit</h2>

<p>Let&#8217;s prepare our first file commit. Lemon has one simple file &#8216;hello.js&#8217; containing the source code.</p>

<pre lang="javascript">var prompt = require('prompt');

prompt.start();

prompt.get(['fruit'], function(err, result) {

    if (result) {
        console.log('Hey fruit ' + result.fruit);
        if ('lemon' == result.fruit) {
            console.log('I like yellow things :) ');
        };
    }
});</pre>


<p>Also we have a package.json configuration file.</p>

<pre lang="javascript">{
  "dependencies": {
    "prompt": "0.2.11"
  }
}
</pre>


<p>As many of you know, in this type of application, we have to ignore the node_modules directory. So we have to create the .gitignore file containing the ignore-list.</p>

<pre lang="bash">*[master][~/alice/lemon]$ echo "node_modules" &gt; .gitignore
</pre>


<p>To see the status of our branch, you should use the command &#8216;git status&#8217;</p>

<pre lang="bash">*[master][~/alice/lemon]$ git status
# On branch master
#
# Initial commit
#
# Untracked files:
#   (use "git add ..." to include in what will be committed)
#
#   .gitignore
#   hello.js
#   package.json
nothing added to commit but untracked files present (use "git add" to track)
</pre>


<p>The file for now are all in the &#8216;untracked&#8217; status, that is the first state. To track these files we have to add them to the repository index.</p>

<pre lang="bash">*[master][~/alice/lemon]$ git add .gitignore package.json hello.js
</pre>


<p>Check the status again</p>

<pre lang="bash">*[master][~/alice/lemon]$ git status
# On branch master
#
# Initial commit
#
# Changes to be committed:
#   (use "git rm --cached ..." to unstage)
#
#   new file:   .gitignore
#   new file:   hello.js
#   new file:   package.json
#
</pre>


<p>The added files are now ready to be committed (aka tracked-file). The commit command resembles that of SVN.</p>

<pre lang="bash">*[master][~/alice/lemon]$ git commit -m "my first git commit"
[master (root-commit) 7046414] my first git commit
 3 files changed, 19 insertions(+)
 create mode 100644 .gitignore
 create mode 100644 hello.js
 create mode 100644 package.json
</pre>


<p>Note that the number &#8216;7046414&#8217; is equivalent of the SVN revision number. Actually it is a commit hash and in this context is truncated to the first 7 characters. To see the entire commit identified we can print the commit log.</p>

<p>Use the &#8216;git log&#8217; command to see this:</p>

<pre lang="bash">commit 7046414d2c9d3407f421987449c92877718248f9
Author: alice
Date:   Fri Nov 1 16:44:31 2013 +0100
     my first git commit
(END)
</pre>


<h2>GIT &#8211; Share your commit with the team</h2>

<p>What about the remote repository? Actually GIT doesn&#8217;t need a main remote repository, but can track several distributed repositories.</p>

<p>For this example I&#8217;m borrowing to Alice this remote <a href="https://github.com/fsferrara/lemon.git">https://github.com/fsferrara/lemon.git</a> repository. She should set this uri in her local repository, and then verify with the command &#8216;git remote -v&#8217;.</p>

<pre lang="bash">[master][~/alice/lemon]$ git remote -v
[master][~/alice/lemon]$ git remote add origin https://github.com/fsferrara/lemon.git
[master][~/alice/lemon]$ git remote -v
origin  https://github.com/fsferrara/lemon.git (fetch)
origin  https://github.com/fsferrara/lemon.git (push)
</pre>


<p>Nice&#8230; a remote (by default called &#8216;origin&#8217;) to share our branch!</p>

<p>Yes, you&#8217;ve got it right. With GIT we always share branches. Alice now have to push her master branch to the origin repository.</p>

<pre lang="bash">[master][~/alice/lemon]$ git push -u origin master
Counting objects: 5, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (4/4), done.
Writing objects: 100% (5/5), 514 bytes, done.
Total 5 (delta 0), reused 0 (delta 0)
To https://github.com/fsferrara/lemon.git
 * [new branch]      master -&gt; master
Branch master set up to track remote branch master from origin.
</pre>


<p>In a team, were developer used to often share their code with SVN, this operation should be performed after every commit.</p>

<p>Only the first time we share a branch we should use the -u flag, in order to set the upstream. In a nutshell an upstream is a tracking reference, in order to set Alice&#8217;s master branch to track the remote master branch (we can refer to it as origin/master or remotes/origin/master).</p>

<p>The &#8216;git branch -a&#8217; command prints out the entire lists of branches.</p>

<pre lang="bash">[master][~/alice/lemon]$ git branch -a
* master
  remotes/origin/master
</pre>


<h2>GIT &#8211; Create a branch</h2>

<p>Now Alice want to write down a killer feature&#8230; maybe it can be a custom message not only for lemons, but also for all kinds of citrus fruit. The first thing to do is to create a branch&#8230;</p>

<pre lang="bash">[master][~/alice/lemon]$ git branch citrus
[master][~/alice/lemon]$ git branch -a
  citrus
* master
  remotes/origin/master
</pre>


<p>The branch citrus is created only locally. That means that the origin (aka remote repository) doesn&#8217;t have this branch. Alice can share this branch with others by pushing it to origin.</p>

<pre lang="bash">[master][~/alice/lemon]$ git push -u origin citrus
Total 0 (delta 0), reused 0 (delta 0)
To https://github.com/fsferrara/lemon.git
 * [new branch]      citrus -&gt; citrus
Branch citrus set up to track remote branch citrus from origin.
[master][~/alice/lemon]$ git branch -a
  citrus
* master
  remotes/origin/citrus
  remotes/origin/master
</pre>


<h2>GIT &#8211; Switch to a branch</h2>

<p>But Alice can&#8217;t start working because is still using the master branch. The &#8216;git checkout&#8217; command is launched to change the current branch.</p>

<p>Yes poor SVN users&#8230; with GIT the checkout command doesn&#8217;t means &#8216;create a brand new working copy&#8217;, but has now a new meaning: now checkout is used to switch branch or revert a modified file or directory.</p>

<p>Let&#8217;s start by simply change the current branch:</p>

<pre lang="bash">[master][~/alice/lemon]$ git checkout citrus
Switched to branch 'citrus'
[citrus][~/alice/lemon]$ git branch -a
* citrus
  master
  remotes/origin/citrus
  remotes/origin/master
</pre>


<h2>GIT &#8211; Clone an existing repository</h2>

<p>Bob, a team mate of Alice, awakens, and start working at the project lemon. The first thing is to clone an existing repository by using the given uri.</p>

<pre lang="bash">[~/bob]$ git clone https://github.com/fsferrara/lemon.git lemon
Cloning into 'lemon'...
remote: Counting objects: 5, done.
remote: Compressing objects: 100% (4/4), done.
remote: Total 5 (delta 0), reused 5 (delta 0)
Unpacking objects: 100% (5/5), done.
[~/bob]$ cd lemon
[master][~/bob/lemon]$ git branch -a
* master
  remotes/origin/HEAD -&gt; origin/master
  remotes/origin/citrus
  remotes/origin/master
</pre>


<h2>GIT &#8211; Share a commit on an existing file</h2>

<p>Ops&#8230; there is a minor bug! The &#8216;hello&#8217; string doesn&#8217;t contains the point. Bob choose to treat it as a hot bugfix, and to commit this change directly on the master branch.</p>

<p>He first edit the hello.js file, and then:</p>

<pre lang="bash">*[master][~/bob/lemon]$ git status
# On branch master
# Changes not staged for commit:
#   (use "git add ..." to update what will be committed)
#   (use "git checkout -- ..." to discard changes in working directory)
#
#   modified:   hello.js
#
no changes added to commit (use "git add" and/or "git commit -a")
*[master][~/bob/lemon]$ git add hello.js
*[master][~/bob/lemon]$ git commit -m "hot bugfix"
[master c6538cc] hot bugfix
 1 file changed, 1 insertion(+), 1 deletion(-)
[master][~/bob/lemon]$ git push origin master
Counting objects: 5, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 346 bytes, done.
Total 3 (delta 1), reused 0 (delta 0)
To https://github.com/fsferrara/lemon.git
   7046414..c6538cc  master -&gt; master
[master][~/bob/lemon]$
</pre>


<h2>GIT &#8211; Create a tag</h2>

<p>Bob want to freeze the current master version to a given tag. We&#8217;re familiar with tags since we currently are SVN users :) but in the GIT case there isn&#8217;t a folder that contains all the tag. Tags are treated like commits, and refers to a snapshot of the source code.</p>

<p>The &#8216;git tag&#8217; command is used here. After the tag is created, there is need to push it in order to share it with the team.</p>

<pre lang="bash">[master][~/bob/lemon]$ git tag -l
[master][~/bob/lemon]$ git tag -a v0.1.0 -m "Released on `date`"
[master][~/bob/lemon]$ git tag -l
v0.1.0
[master][~/bob/lemon]$ git push --tags origin master
Counting objects: 1, done.
Writing objects: 100% (1/1), 184 bytes, done.
Total 1 (delta 0), reused 0 (delta 0)
To https://github.com/fsferrara/lemon.git
 * [new tag]         v0.1.0 -&gt; v0.1.0
</pre>


<h2>GIT &#8211; Check if a branch is rebased</h2>

<p>Alice is working on branch &#8216;citrus&#8217; and in the meanwhile Bob committed a fix on the master branch. How Alice can check if the branch she is currently working on has to be rebased? The first thing to do is to &#8216;fetch&#8217; updates from origin.</p>

<pre lang="bash">[citrus][~/alice/lemon]$ git fetch
remote: Counting objects: 6, done.
remote: Compressing objects: 100% (3/3), done.
remote: Total 4 (delta 1), reused 4 (delta 1)
Unpacking objects: 100% (4/4), done.
From https://github.com/fsferrara/lemon
   7046414..c6538cc  master     -&gt; origin/master
 * [new tag]         v0.1.0     -&gt; v0.1.0
</pre>


<p>Now Alice&#8217;s repository has information about Bob&#8217;s commits and tags. In order to know if the current branch is rebased with master Alice can use the &#8216;git cherry&#8217; command. Another option are the more powerful commands:</p>

<p>gitk citrus..origin/master</p>

<p>git log citrus..origin/master</p>

<p>The range notation &#8220;citrus..master&#8221; means &#8220;show everything that is included in master but is not included in citrus&#8221;.</p>

<pre lang="bash">[citrus][~/alice/lemon]$ git cherry citrus origin/master
+ c6538cc3b3fed65bd5c9cfe708961f1f5f2e1616</pre>


<h2>GIT &#8211; Rebase a branch with master</h2>

<p>Expected surprise! There is a commit (c6538cc3b3fed65bd5c9cfe708961f1f5f2e1616) not included in the current branch. Now is very important to note all the branches present in Alice&#8217;s repository:</p>

<pre lang="bash">[citrus][~/alice/lemon]$ git branch -a
* citrus
  master
  remotes/origin/citrus
  remotes/origin/master
</pre>


<p>There are two local branches (citrus and master), and two remote tracked branches (origin/citrus and origin/master). At the moment origin/master is updated, but master isn&#8217;t updated yet. That&#8217;s because &#8216;git fetch&#8217; only download new information but doesn&#8217;t perform any merge operation.</p>

<p>The choice is to work with remote branches, or update local branches and work with locals. Alice choose to work with the remote ones.</p>

<pre lang="bash">[citrus][~/alice/lemon]$ git rebase origin/master citrus
First, rewinding head to replay your work on top of it...
Fast-forwarded citrus to origin/master.
[citrus][~/alice/lemon]$ git status
# On branch citrus
# Your branch is ahead of 'origin/citrus' by 1 commit.
#
nothing to commit (working directory clean)
[citrus][~/alice/lemon]$ git push origin citrus
Total 0 (delta 0), reused 0 (delta 0)
To https://github.com/fsferrara/lemon.git
   7046414..c6538cc  citrus -&gt; citrus
[citrus][~/alice/lemon]$ git status
# On branch citrus
nothing to commit (working directory clean)
</pre>


<p>Examining the log (with git log or gitk) we can see that now citrus and origin/citrus branches have exactly the commit c6538cc3b3fed65bd5c9cfe708961f1f5f2e1616 in their log. That means that this commit is now in common with the master branch.</p>

<h2>GIT &#8211; Reintegrate a branch</h2>

<p>Alice worked hard on her branch, and a the end commits the killer feature.</p>

<pre lang="bash">[citrus][~/alice/lemon]$ vim hello.js
*[citrus][~/alice/lemon]$ git add hello.js
*[citrus][~/alice/lemon]$ git commit -m "Add the killer feature"
[citrus b306b5c] Add the killer feature
 1 file changed, 3 insertions(+)
[citrus][~/alice/lemon]$ git push origin citrus
Counting objects: 5, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 447 bytes, done.
Total 3 (delta 1), reused 0 (delta 0)
To https://github.com/fsferrara/lemon.git
   c6538cc..b306b5c  citrus -&gt; citrus
</pre>


<p>Ops&#8230; she forgot something :( . Another commit is necessary:</p>

<pre lang="bash">[citrus][~/alice/lemon]$ vim hello.js
*[citrus][~/alice/lemon]$ git add hello.js
*[citrus][~/alice/lemon]$ git commit -m "This actually add the killer feature"
[citrus ae073c3] This actually add the killer feature
 1 file changed, 3 insertions(+)
[citrus][~/alice/lemon]$ git push origin citrus
Counting objects: 5, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 370 bytes, done.
Total 3 (delta 1), reused 0 (delta 0)
To https://github.com/fsferrara/lemon.git
   b306b5c..ae073c3  citrus -&gt; citrus
</pre>


<p>Bob wants now to integrate Alice&#8217;s commits in the master branch. So the first thing to do is to fetch the updates.</p>

<pre lang="bash">[master][~/bob/lemon]$ git fetch
remote: Counting objects: 8, done.
remote: Compressing objects: 100% (5/5), done.
remote: Total 6 (delta 2), reused 5 (delta 1)
Unpacking objects: 100% (6/6), done.
From https://github.com/fsferrara/lemon
   7046414..ae073c3  citrus     -&gt; origin/citrus
</pre>


<p>Now Bob has to merge all the Alice&#8217;s commit in the master branch. The following command &#8216;squash&#8217; these commits into one commit, and add the change-set to the GIT index:</p>

<pre lang="bash">[master][~/bob/lemon]$ git merge --squash origin/citrus
Updating c6538cc..ae073c3
Fast-forward
Squash commit -- not updating HEAD
 hello.js | 6 ++++++
 1 file changed, 6 insertions(+)
</pre>


<p>The working branch of Bob now has all the changes introduced by Alice. To see the difference Bob should use the command &#8216;git diff &#8211;staged&#8217;.</p>

<p>Finally to reintegrate the branch:</p>

<pre lang="bash">*[master][~/bob/lemon]$ git commit -m "Reintegrate branch citrus into master"
[master cd84dc7] Reintegrate branch citrus into master
 1 file changed, 6 insertions(+)
[master][~/bob/lemon]$ git push origin master
Counting objects: 5, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 538 bytes, done.
Total 3 (delta 0), reused 0 (delta 0)
To https://github.com/fsferrara/lemon.git
   c6538cc..cd84dc7  master -&gt; master
</pre>


<h2>GIT &#8211; Delete a branch</h2>

<p>At the end Bob can delete the branch he previously integrated on master. The &#8216;git branch -d&#8217; command is used.</p>

<pre lang="bash">[master][~/bob/lemon]$ git branch -d citrus
warning: deleting branch 'citrus' that has been merged to
 'refs/remotes/origin/citrus', but not yet merged to HEAD.
Deleted branch citrus (was ae073c3).
[master][~/bob/lemon]$ git push --delete origin citrus
To https://github.com/fsferrara/lemon.git
 - [deleted]         citrus
</pre>


<p>Note that the command &#8216;git branch -d&#8217; ensures that the changes in the citrus branch are already in the current branch. If not, you should use the option -D instead.</p>

<h2>What&#8217;s next&#8230;</h2>

<p>Time is over :/ . Next operation I usually perform with SVN are:</p>

<ul>
<li>GIT &#8211; Return to a revision</li>
<li>GIT &#8211; Return to a tag</li>
<li>GIT &#8211; Reverse merge</li>
<li>GIT &#8211; Undo a wrong commit (or a list&#8230; remeber the order)</li>
<li>GIT &#8211; Create a diff-file and perform a patch</li>
<li>GIT &#8211; Stash</li>
<li>GIT &#8211; Export</li>
</ul>


<p>Asap I&#8217;ll write about these operation. In the meanwhile I suggest you these manual page: &#8216;man gittutorial&#8217; and the very interesting &#8216;man gittutorial-2&#8217;</p>

<p>Goodbye and happy versioning :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Luppolo the Drinking Game]]></title>
    <link href="http://fsferrara.github.io/luppolo/"/>
    <updated>2013-10-21T22:29:38+00:00</updated>
    <id>http://fsferrara.github.io/luppolo</id>
    <content type="html"><![CDATA[<p>The Drinking Games are games in which participants are often invited to drink alcoholic beverages. These games have been played since ancient times, and now are more popular among young people, especially students.</p>

<p>Luppolo (the Italian word for hops) is a drinking game designed by me.</p>

<!--more-->


<p>It is a board game and you can play with friends, at home, or in the pub favorite.</p>

<p>In my dreams the table it will be printed directly on the tables of the pubs.</p>

<p>The rules are simple &#8230; just roll the dice hitting the gaming table, and follow the instructions of the dice :)</p>

<p>Luppolo is only in Italian, and is released under the <a href="http://creativecommons.org/licenses/by-nc-nd/2.5/legalcode">Creative Commons</a> license. Anyone wishing to contribute with suggestions, ideas, translations, and so on, is welcome.</p>

<p>You can <a href="http://fsferrara.github.io/wp-content/downloads/luppolo.pdf">download luppolo</a>, print it, build it, and then you can freely play with your friends.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Early Development of Artificial Intelligence]]></title>
    <link href="http://fsferrara.github.io/early-development-of-artificial-intelligence/"/>
    <updated>2013-10-20T01:37:43+00:00</updated>
    <id>http://fsferrara.github.io/early-development-of-artificial-intelligence</id>
    <content type="html"><![CDATA[<p>Primi sviluppi dell&#8217;Intelligenza Artificiale.</p>

<p>E&#8217; difficile dare una definizione di Intelligenza Artificiale (IA) in quando essa è vista sia dal punto di vista ingegneristico (che punta a costruire macchine intelligenti per assistere l&#8217;uomo), sia dal punto di vista psicologico (che punta a riprodurre nelle macchine le caratteristiche dell&#8217;attività cognitiva umana).</p>

<p>Seppur con idee diverse, i pionieri dell&#8217;IA (McCarthy, Minsky, Rochesterm, e Shannon) videro nel calcolatore digitale uno strumento con capacità di elaborazione ineguagliate, quindi uno strumento adatto al confronto con alcuni aspetti della mente umana.</p>

<p>Si cominciarono a sviluppare i primi programmi relativi ad ambiti ben delimitati in cui c&#8217;erano  solo regole esplicite per l&#8217;elaborazione simbolica e poca conoscenza specializzata. Motivo di questo inizio era la scarsa capacità di memoria e di calcolo dei calcolatori di quei tempi.</p>

<p>Successivamente si parte con lo sviluppo di sistemi esperti, dove la conoscenza specializzata nel campo ci porta ad avere buone prestazioni.</p>

<p>La diffusione di queste tecniche di IA ci conferma il successo dal punto di vista ingegneristico, ma cosa possiamo dire dal punto di vista psicologico?</p>

<p>Cosa implica la costruzione di macchine che riproducono caratteristiche essenziali dell&#8217;attività umana? Dove si colloca l&#8217;IA nell&#8217;ambito delle ricerche sul sistema cervello-mente che coinvolgono le neuroscienze e la psicologia?</p>

<!--more-->


<h2>Turing e la Macchina di Turing Universale</h2>

<p>Abbinando le MdT (Macchine di Turing) alle codifiche di Godel, nasce un modo di codificare le MdT. Si ha inoltre un <em>procedimento effettivo</em> per la codifica e la decodifica.</p>

<p>Dalle MdT codificate, Turing arriva alla macchina universale, che è una particolare MdT che, accettando in input la descrizione di una qualsiasi MdT, riesce a comportarsi come essa.</p>

<p>Dalla <strong>MdT Universale</strong> nasce la nozione di <strong>Macchina Programmabile</strong>.</p>

<p>Da questa considerzione ci si chiese se le macchine possano essere intelligenti. Su questo Turing scrive l&#8217;articolo &#8220;Macchine calcolatrici e intelligenza&#8221;.</p>

<h2>Macchine calcolatrici e intelligenza</h2>

<p>Turing considera la domanda: &#8220;<em>Possono pensare le macchine?</em>&#8220;. In questa domanda i termini <strong>macchina</strong> e <strong>pensare</strong> non sono di facile definizione.</p>

<p>Possiamo definire la parola <strong>macchina</strong> possiamo imporre che la macchina sia composta da tre parti: memoria, unità operativa, e governo; dove la memoria è un deposito di informazioni, l&#8217;unità operativa è la parte atta ad eseguire operazioni, ed il governo coordina l&#8217;unità operativa e la memoria.</p>

<p>Quindi scendendo più in dettaglio riusciamo a definire cos&#8217;è una macchina.</p>

<p>Cosa possiamo invece definire la parola <strong>pensare</strong>? Turing non riesce a farlo.</p>

<p>Per questo pensa di riformulare la domanda &#8220;<em>Possono pensare le macchine?</em>&#8221; con un&#8217;altra. Riformula il problema in termini di un gioco dove si trovano tre persona A (un uomo), B (una donna), e C (un&#8217;interrogante). C è isolato in una stanza, e può comunicare con A e B mediante messaggi di tipo linguistico.</p>

<p>Lo scopo di C, che parla con due individui, è di capire chi è la donna e chi è l&#8217;uomo. B (che è la donna) ha il compito di aiutare l&#8217;interrogante C, mentre lo scopo di A (l&#8217;uomo) è quello di ingannarlo.</p>

<p>La domanda riformulata è: &#8220;<em>Che cosa accadrà se una macchina prende il posto di A nel gioco? La frequenza delle risposte errate da parte di C sarà la stessa di quando il gioco si svolge tra uomini?</em>&#8220;.</p>

<p>Chiamiamo questo <strong>Test di Turing</strong>.</p>

<h3>Test di Turing e Intelligenza</h3>

<p>Superare il test di Turing, non è una condizione né necessaria, né sufficiente per stabilire se un individuo o una macchina è intelligente.</p>

<ul>
<li>Condizione Necessaria: se un essere è intelligente deve necessariamente superare il Test di Turing. Ma ci sono situazioni, come quelle delle persone nello stato locked-in (ad esempio il famoso caso di Piergiorgio Welby), in cui l&#8217;individuo non è in grado di superare il test, ma comunque non possiamo dire che tale individuo non è intelligente.</li>
<li>Condizione Sufficiente: supponiamo una macchina con un programma complicatissimo, che è fatta apposta per superare il Test di Turing. Questa macchina sa solo superare questo test e basta: possiamo definirela intelligente?</li>
</ul>


<p>Quindi il superamento del Test di Turing da parte di una macchina non è né condizione necessaria, né condizione sufficiente per affermare che la macchina stressa sia intelligente.</p>

<h3>Osservazioni all&#8217;articolo</h3>

<p><span style="text-decoration: underline;">Prima Osservazione: Funzionalismo</span></p>

<p>Notiamo che in questo gioco la macchina da risposte di tipo linguistico; infatti Turing divide nettamente le capacità fisiche di un essere umano, dalle capacità intellettuali (o mentali). Questo non è vero nell&#8217;eccezione Darwiniana in cui le capacità mentali di un essere vivente sono di fondamentale importanza per coordinare le capacità motorie, e permettono così di sopravvivere.</p>

<p>Essendo la mente umana composta da materiali diversi da quelli con i quali è costruita una macchina, Turing adotta il funzionalismo, ossia paragona il funzionamento degli oggetti anche se costruiti in modo diverso.</p>

<p><span style="text-decoration: underline;">Seconda Osservazione: La mente funziona a stati discreti</span></p>

<p>I calcolatori digitali sono indubbiamente delle macchine a <em>stati discreti</em>. Ovvero si muovono a scatti improvvisi ben distinguibili l&#8217;uno dall&#8217;altro.</p>

<p>Anche se in realtà in natura niente è discreto; se indaghiamo un calcolatore digitale funziona anch&#8217;esso in modo <em>continuo</em>. Ma consideriamolo una macchina a stati discreti.</p>

<p><em>Ci conviene discretizzare la mente paragonandola ad un calcolatore digitale</em>?</p>

<p><span style="text-decoration: underline;">Terza Osservazione: I calcolatori digitali non sono caotici</span></p>

<p>Dato un input in ingresso ad una macchina riusciamo a predire tutti i suoi stati, ed il suo output, in modo esatto. Nel mondo invece vige la teoria del caos, nella quale piccole variazioni nelle condizioni iniziali producono grandi variazioni nel comportamento a lungo termine di un sistema. Ad esempio il battito d&#8217;ali di una farfalla può essere la causa di un uragano dall&#8217;altra parte del mondo.</p>

<h3>Obiezioni Contrarie all&#8217;argomento principale dell&#8217;articolo</h3>

<p><span style="text-decoration: underline;">Obiezione Teologica:</span> &#8220;Solo Dio ha il potere di creare esseri pensanti&#8221;.</p>

<p>Questa obiezione pone serie restrizioni alla provvidenza divina: chi ci dice che Dio non ci abbia dato il potere di creare macchine pensanti?</p>

<p><span style="text-decoration: underline;">Obiezione della Testa nella Sabbia:</span> Questa è l&#8217;obiezione di chi ha paura delle macchine pensanti. A queste persone piace sentirsi superiori di ogni altra cosa, e si sentono minacciati da questo tentativo di creare macchine pensanti.</p>

<p><span style="text-decoration: underline;">Obiezione Matematica:</span> I teoremi di incompletezza di Godel, ed altri risultati ad esso annessi, dimostrano che le macchine non possono conoscere tutte le verità. Quindi esistono dei limiti, e si sostiene che la mente umana non abbia questi limiti.</p>

<p>Ma non è giusto condannare così i calcolatori; diamo risposte errate anche noi. Inoltre ci possono essere uomini più abili di una macchina, ma possono essere costruite altre macchine più abili di questi uomini. Quindi non ci possono essere uomini più abili di tutte le macchine.</p>

<p><span style="text-decoration: underline;">Obiezione dell&#8217;Autocoscienza</span>: Possiamo dividere la coscienza in &#8220;essere consapevole del proprio stato&#8221;, ed &#8220;essere consapevoli di provare&#8221;. Possiamo costruire macchine con medoti di <strong>Machine Learning</strong> che sono consapevoli del proprio stato, ma non ancora riusciamo ad immaginare macchine che sappiano provare dei sentimenti.</p>

<p><span style="text-decoration: underline;">Obiezioni basate su incapacità varie</span>: ad esempio una macchina è capace di gustare le fragole con la panna.</p>

<p>Queste obiezioni nascono dal fatto che vogliamo far assomigliare le macchine agli essere umani. Ma, non essendo le macchine degli essere umani, è difficile avere un rapporto di amicizia tra un uomo ed una macchina.</p>

<p><span style="text-decoration: underline;">Obiezione di Lady Lovelace:</span> &#8220;La macchina può eseguire solo quello che gli diciamo di fare!&#8221;. Questa obiezione è vecchia e risale ai tempi della macchina universale di Babbage.</p>

<p>Con i moderni metodi di <strong>Machine Learning</strong> possiamo avere delle macchine che riescono ad apprendere, anche se sono formate da un nucleo di base non modificabile. Quindi anche essendo una macchina <em>deterministica</em>, possiamo avere macchine che modificano il proprio comportamento man mano che apprendono nuove regole.</p>

<p><span style="text-decoration: underline;">Obiezione fondata sulla continuità del sistema nervoso:</span> Ancora una volta ci rifacciamo al concetto di funzionalismo, secondo il quale cerchiamo di ottenere solo un comportamento intelligente, e non pretendiamo che internamente le cose funzionino allo stesso modo.</p>

<h3>Possono le macchine pensare?</h3>

<p>Dopo l&#8217;articolo di Turing partono gli studi per costruire macchine in grado di competere con l&#8217;uomo in ambiti intellettuali. Ma quel&#8217;è la strada migliore per iniziare a costruire queste macchine?</p>

<p>L&#8217;<em>IA</em> comincia a sviluppare programmi per calcolatori digitali capaci di svolgere attività molto astratte, come giocare a scacchi.</p>

<p>La <em>robotica</em> invece inizia mettendo in risalto il comportamento intelligente degli esseri viventi, e comincia a costruire dispositivi meccanici che si comportano in modo intelligente.</p>

<p>Parallelamente a queste due nasce anche la branca della <strong>Machine Learning</strong>, un&#8217;intuizione geniale da parte di Turing.</p>

<h2>La cibernetica prima dei calcolatori digitali</h2>

<p>La cibernetica nasce con i sistemi a retroazione. La differenza con il punto di vista di Turing, è che questa volta <span style="text-decoration: underline;">il comportamento intelligente è visto come un comportamento flessibile-adattativo all&#8217;ambiente</span>: c&#8217;è un tentativo di collegare questi sistemi a retroazione ai sistemi biologici, con un conseguente collegamento alla scienza molto più forte.</p>

<p>Da un altro punto di vista notiamo che i cibernetici partono dal basso, costruendo prima sistemi molto semplici, mentre Turing punta a riprodurre l&#8217;attività mentale umana con un macchina&#8230; un compito arduo.</p>

<p>Un primo esempio di sistema a retroazione è la valvola di sfiato della caldaia di una locomotiva a vapore; il suo compito era quello di tenere la pressione costante all&#8217;interno della caldaia, in modo da mantenere costante la velocità del treno. Quindi quando la pressione era troppo alta, la valvola faceva uscire del vapore per farla diminuire.</p>

<p>Questo primo meccanismo di sistema a retroazione puntava a correggere l&#8217;errore, in un ciclo di questo tipo:</p>

<ol>
<li>Osservare l&#8217;output del sistema</li>
<li>Misurare l&#8217;errore</li>
<li>Apportare le modifiche atte a correggere l&#8217;errore</li>
</ol>


<p>Questi meccanismi hanno delle caratteristiche in comune con i sistemi biologici: ad esempio il corpo umano ha un meccanismo simile per controllare la temperatura corporea (la sudorazione).</p>

<p>Rosenblueth, Wiener, e Bigelow, nel loro articolo &#8220;<em>Coportamento, Scopo, e Teleologia</em>&#8221; affermano che i metodi di studio sia per gli organismi viventi, sia per le macchine, sono simili in quanto non sono state trovare delle caratteristiche qualitativamente diverse che caratterizzano un gruppo e non l&#8217;altro.</p>

<p>Possiamo dividere le cause dei mutamenti della natura in quelli provocati da:</p>

<p>&#8211; cause efficienti: è l&#8217;agente che determina operativamente il mutamento</p>

<p>&#8211; cause finali: è l&#8217;intenzione di qualche essere vivente a raggiungere un certo scopo</p>

<p>I cibernetici puntano a descrivere il comportamento intelligente usando solo le cause efficienti, in quanto le cause finali sono caratteristiche dei sistemi biologici.</p>

<p>Come esempio possiamo considerare il comportamento della falena che è stato descritto da uno studioso americano con sole cause efficienti.</p>

<h3>Comportamento, Scopo, e Teleologia</h3>

<p>Il comportamento intelligente può essere diviso in due grosse classi: il comportamento rivolto ad uno scopo (finalizzato), e il comportamento non rivolto ad uno scopo (causale).</p>

<p>Noi ci interessiamo al comportamento rivolto ad uno scopo. Ma cos&#8217;è uno scopo? Abbiamo un <strong>tentativo riduzionista</strong>, <span style="text-decoration: underline;">che riduce lo scopo ad un oggetto, e il suo raggiungimento è uno spostamento spazio/temporale dell&#8217;oggetto stesso</span>.</p>

<p>Su questa visione di vedere uno scopo si inseriscono i critici obiettando il fatto che non sempre lo scopo è un oggetto.</p>

<p>Il comportamento rivolto ad uno scopo può essere diviso a sua volta in comportamento rivolto ad uno scopo con retroazione (o teleologico) o senza retroazione (non teleologico).</p>

<p>Il comportamento rivolto ad uno scopo senza retroazione raggruppa tutti quei casi in cui il movimento è talmente veloce in cui è impensabile che ci sia del tempo utile a modificare il movimento mentre lo si sta facendo. Ad esempio, il comportamento di una rana mentre colpisce una mosca per mangiarsela, è senza retroazione.</p>

<p>Ci interesseremo al comportamento rivolto ad uno scopo con retroazione, nel quale l&#8217;azione che si sta svolgendo è modificabile mentre la si sta facendo. Questo tipo di comportamento è più efficace del comportamento senza retroazione, specialmente quando lo scopo è un oggetto fermo.</p>

<p>Il comportamento rivolto ad uno scopo con retroazione può essere ulteriormente diviso in comportamento rivolto ad uno scopo con retroazione non predittivo o non estrapolativo (la falena che cammina verso la luce) e predittivo o estrapolativo (il gatto che balza per catturare un topo nella posizione in cui il topo dovrebbe stare dopo il balzo, quindi il gatto è capace di estrapolare la posizione del topo in un istante di tempo futuro).</p>

<h3>Intelligenza e Comportamento rivolto ad uno scopo</h3>

<p>Nell&#8217;articolo &#8220;<em>Coportamento, Scopo, e Teleologia</em>&#8221; non sono state individuate le condizioni necessarie e sufficienti per affermare che un agente ha il comportamento intelligente per raggiungere uno scopo. Questo perché il tentativo riduzionista per la descrizione di cosa si intende per scopo ci vincola troppo.</p>

<ul>
<li>Condizione Necessaria: Supponiamo ci sia un cavaliere alla ricerca del Santo Graal. Se il Santo Graal non esiste, come descriviamo lo scopo di questo cavaliere se imponiamo che lo scopo sia un oggetto?</li>
<li>Condizione Sufficiente: Supponiamo una persona si sveglia all&#8217;improvviso durante la notte, e spara un colpo di pistola allo specchio. Come descriviamo lo scopo di questo signore? Il suo intento non era sparare nello specchio, ma l&#8217;ha fatto per motivi che non conosciamo.</li>
</ul>


<p>Quindi la definizione di Scopo come una relazione spazio/temporale relativa ad un oggetto è troppo restrittiva per descrivere il comportamento intelligente rivolto ad uno scopo.</p>

<h3>Il ruolo dei Modelli nella Scienza</h3>

<p>La cibernetica lavora con i <strong>modelli</strong>. Obiettivo della scienza è ottenere la <strong>comprensione</strong> ed il <strong>controllo</strong> di una qualche parte dell&#8217;universo. Ad esempio la lancetta del barometro che si abbassa ha come causa  (comprensione) l&#8217;abbassamento della pressione; ed anche, la cura per una malattia (controllo) mediante antibiotici.</p>

<p>Ma nessuna parte dell&#8217;universo si lascia afferrare senza un minimo di astrazione. I <strong>modelli</strong> ci aiutano proprio a questo: un modello formale (o intellettuale) rappresenta con astrazione un <strong>sistema studiato</strong> (cioè la parte dell&#8217;universo che stiamo studiando).</p>

<p>Possiamo dividere i modelli in:</p>

<ul>
<li><strong>Modello materiale</strong>: rappresentazione del <em>sistema studiato</em> ottenuto mediante un altro sistema, di solito più semplice, ma con proprietà simili al <em>sistema studiato</em>.</li>
<li><strong>Modello Formale</strong>: rappresenta in termini logici il <em>sistema studiato</em> in maniera semplice, con proprietà simili.</li>
</ul>


<p>I modelli materiali sono utili quando:</p>

<p>&#8211; Vogliamo studiare un sistema di un campo inconsueto (sistema studiato), in un campo più familiare (modello meccanico)</p>

<p>&#8211; Il modello materiale permette di svolgere esperimenti in condizioni più favorevoli rispetto a quelle date dal sistema studiato. Ad esempio ci conviene sperimentare nuovi farmaci prima sui topi, e poi sugli umani. Ma su quale base diciamo che un topo è un modello materiale dell&#8217;umano? Lo diciamo secondo alcuni criteri di &#8220;somiglianza&#8221; rispetto al modello originale.</p>

<p>I modelli non sono utili quando:</p>

<p>&#8211; Se il modello formale non rispecchia bene il sistema studiato, anche il modello materiale sarà poco significativo.</p>

<p>&#8211; Se il modello materiale suggerisce esperimenti predittibili dal modello formale, allora esso è superfluo.</p>

<p>Possiamo dividere i problemi in quelli a scatola chiusa e quelli a scatola aperta.</p>

<p>Nei problemi a <strong>scatola chiusa</strong> conosciamo solo alcuni input e possiamo verificare gli output, ma non sappiamo cosa avviene dentro la scatola. <em>La legge di trasformazione è quella legge che mette in relazione l&#8217;input con l&#8217;output</em>. Per scoprire cosa c&#8217;è nella scatola possiamo provare ad aprirla ed individuare altri input e/o altri output in modo da svolgere studi più approfonditi. Man mano che apriamo tutte le scatole trovate durante lo studio, abbiamo un problema a <strong>scatola aperta</strong>.</p>

<p>Nell&#8217;aprire le scatole, e quindi nell&#8217;aggiungere dettagli alla nostra descrizione, facciamo un&#8217;ipotesi di modularità, ipotizzando che gli input individuati siano debolmente accoppiati con gli altri elementi della scatola. Bisogna stare attenti quando si studiano questi problemi a scendere nel dettaglio fino ad un livello per noi soddisfacente, in modo da avere una buona descrizione del problema senza complicarlo in modo eccessivo.</p>

<h2>&#8220;Computer Simulation of Human Thinking&#8221; &#8211; Newell &amp; Simon</h2>

<p>Abbiamo discusso gli sviluppi della prima Cibernetica. Adesso ci spostiamo sul ramo della prima IA, ed esaminiamo il lavoro di Newell &amp; Simon.</p>

<p>Newell &amp; Simon, due neuroscienziati che studiavano la mente, avevano lo scopo di cercare dei <strong>modelli del mentale</strong>, ossia dei <strong>modelli</strong> che rappresentassero l&#8217;attività cognitiva umana.</p>

<p>Quindi volevano costruire dei programmi che simulassero i compiti cognitivi umani in modo psicologicamente realistico.</p>

<p>Per fare ciò si costruirono delle <strong>Microteorie</strong>. Ogni microteoria era relativa ad un particolare categoria di compiti cognitivi, ad esempio giocare a dama: essi chiedevano alla persona sotto esame di giocare a dama e pensare a voce alta, quindi riferire tutti i suoi ragionamenti selettivi ed euristici (introspezione).</p>

<p>Il programma risultante di questo studio, non solo doveva dare gli stessi risultati del ragionamento cognitivo (e quindi supera il test di Turing), ma nel calcolarli doveva elaborare le informazioni nello stesso modo di un essere umano. Quest&#8217;ultima condizione serve ad avere una simulazione psicologicamente realistica del ragionamento umano.</p>

<p>Una volta costruito un modello per un compito cognitivo, abbiamo una microteoria. Newell &amp; Simon volevano trarre un modello della mente combinando tra loro tutte le microteorie ottenute.</p>

<p>La differenza con Turing, è che Newell &amp; Simon consideravano il test di Turing &#8220;debole&#8221; in quando non riguarda i processi del pensiero, ma prende in considerazione solo la prestazione finale.</p>

<h3>Critiche al lavoro di Newell &amp; Simon</h3>

<p><strong>Critica sull&#8217;uso del protocollo verbale</strong></p>

<p>Il protocollo verbale, con il quale i soggetti studiati illustravano il proprio processo di pensiero sono <strong>incompleti</strong> perché non tutti i processi della mente sono accessibili all&#8217;introspezione.</p>

<p>Inoltre questo metodo di studio del mentale è scorretto perché pensare e descrivere cosa si sta pensando sono due compiti concorrenti che possono interferire tra loro.</p>

<p>Si sta studiando il modo di pensare, o il modo in cui un essere umano descrive il proprio pensiero?</p>

<p><strong>Critica sul dominio di applicazione</strong></p>

<p>Le microteorie sono strettamente collegate al particolare problema. Quindi applicando il modello suggerito da una microteoria ad un problema simile a quello di partenza non si hanno buoni risultati.</p>

<p><strong>Critica sul campione di persone</strong></p>

<p>Il campione scelto per eseguire i test è ristretto, e non rispecchia il modo di pensare di tutta la popolazione. Inoltre ogni persona ha un modo particolare di pensare.</p>

<p><strong>Critica sulla modularità</strong></p>

<p>Newell &amp; Simon non fanno ipotesi di modularità sulla mente e la considerano interamente in un&#8217;unica architettura unificata. Successivi studi (Chomsky, Marr, Fodor, ed altri) tentano di dividere la mente in moduli, in modo da poterli studiare indipendentemente.</p>

<h3>Conclusioni</h3>

<p>Il lavoro di Newell &amp; Simon è stato fallimentare, ma il loro contributo all&#8217;IA è stato enorme. Tutt&#8217;oggi le euristiche da loro definite sono molto utilizzate.</p>

<h2>Chomsky ed il Linguaggio Universale</h2>

<p>Un esempio di ipotesi di modularità è il <strong>Linguaggio Universale</strong> di Chomsky. Lui osserva come i bambini nei loro primi anni di vita riescono ad imparare la lingua, e nota che gli stimoli che essi ricevono sono di scarsa qualità per ottenere i risultati che si hanno.</p>

<p>Quindi l&#8217;ipotesi di modularità di Chomsky è che nella nostra mente esiste un modulo di <strong>Grammatica Universale</strong> (UG) che ci aiuta ad imparare il linguaggio parlato.</p>

<p>Quello che ha fatto Chomsky è isolare questo modulo UG dalle restanti parti della mente, e studiarlo a se stante.</p>

<p>Questo è proprio quello che manca nel lavoro fatto da Newell &amp; Simon, in quanto non avendo fatto ipotesi di modularità, non riescono a trovare delle variabili in comune a tutti gli essere umani con le quali è possibile creare un modello di tutta la mente umana.</p>

<h2>David Marr</h2>

<p>Marr, essendo allievo di Chomsky, prende da lui spunto, e nel suo articolo &#8220;Artificial Intelligence &#8211; A Personal View&#8221; espone la sua critica al lavoro di Newell &amp; Simon.</p>

<p>Secondo Marr, un risultato nel campo dell&#8217;IA doveva seguire questi passaggi:</p>

<ol>
<li>Definizione di <strong>cosa</strong> è calcolato, e <strong>perché</strong> è calcolato</li>
<li>Definire <strong>come</strong> calcolarlo, quindi definizione di un algoritmo</li>
<li>Dimostrazione di funzionamento</li>
</ol>


<p>Il &#8220;perché&#8221; non è interessante da definire in quanto è legato alla natura del problema: il mondo è fatto così. Il &#8220;cosa&#8221; invece è molto interessante, in quanto questo passaggio non è stato considerato da Newell &amp; Simon. Infatti è difficile definire &#8220;cosa&#8221; calcolare in modo preciso quando si sta tentando di costruire un modello per l&#8217;intera mente umana.</p>

<p>Marri chiama <em>teorie di tipo 1</em> quelle in cui si riesce a trovare una buona descrizione di cosa è calcolato, e chiama <em>teorie di tipo 2</em> quelle in cui non si è ancora riusciti a dare una descrizione formale.</p>

<h2>Antonio Damasio</h2>

<p>Molti hanno criticato Newell &amp; Simon per mancanza di ipotesi di modularità. In realtà un&#8217;ipotesi di modularità è stata fatta: l&#8217;attività di problem solving della mente umana è considerata indipendente dalle emozioni provate.</p>

<p>Damasio, neurologo e neuroscienziato degli anni 80, nello studiare un caso clinico si accorge che il paziente non è in grado di provare emozioni.</p>

<p>Questo paziente è perfettamente in grado di effettuare ragionamenti razionali, e risponde correttamente a domande a lui poste. Però quando è coinvolto in prima persona non riesce a prendere le decisioni giuste con i suoi ragionamenti.</p>

<p>L&#8217;ipotesi di Damasio è che <em>le emozioni hanno un ruolo importante nel ragionamento pratico</em>.</p>

<p>Test effettuati con questo paziente mostrano che non è in grado di provare emozioni. Ad esempio in una partita a poker non prova tristezza se perde una mano di gioco, oppure riesce a parlare in modo freddo della sua malattia (o di eventi brutti) con freddezza.</p>

<p>Damasio va oltre questa ipotesi e ne formula un&#8217;altra, in cui afferma che, come le emozioni, <em>le immagini mentali hanno un ruolo nel ragionamento pratico</em>.</p>

<p>Supponiamo di essere stati morsi da un cane mentre passeggiavamo nel parco. Dopo qualche giorno se ripensiamo a quel cane, riusciamo ad immaginarlo e a ricostruirci nel nostro <em>buffer visivo</em> la sua immagine. Assieme alla scena ricostruita associamo un&#8217;emozione che può essere bella o brutta a seconda se il morso del cane ci è piaciuto oppure no (ovviamente in questo caso non ci è piaciuto). Quindi in futuro cercheremo di non passare vicino a quel cane perché rischiamo di essere morsi nuovamente: così facendo nel nostro ragionamento pratico elimineremo tutti gli scenari possibili che ci portano nelle vicinanze di quel cane.</p>

<p>Damasio dice con questa ipotesi che il paziente da lui studiato è incapace associare le immagini mentali alle emozioni, e quindi nel suo ragionamento pratico può scegliere un&#8217;azione che lo riporta a commettere un errore già fatto in passato.</p>

<p>Con queste ipotesi Damasio ha cercato di spiegare l&#8217;assenza di pianificazione e di prudenza che ha il suo paziente durante i ragionamenti pratici che lo coinvolgono i prima persona.</p>

<p>Inoltre mostra come le emozioni hanno un ruolo centrale nel ragionamento, e quindi è sbagliato considerarle indipendenti dal problem solving. Quindi sarà possibile progettare macchine con prestazioni pari a quelle degli essere umani anche se non provano emozioni?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Birth of Computer Science]]></title>
    <link href="http://fsferrara.github.io/the-birth-of-computer-science/"/>
    <updated>2013-10-20T01:33:41+00:00</updated>
    <id>http://fsferrara.github.io/the-birth-of-computer-science</id>
    <content type="html"><![CDATA[<p>La nascita dell&#8217;informatica.</p>

<p>Il primo kernel Linux è stato pubblicato nel 1991, l’annuncio del primo sistema operativo della famiglia Windows risale al 1983, la nascita dell&#8217;informatica come disciplina scientifica risale al 1953, il primo calcolatore programmabile digitale al 1941 (Z3 di Zuse); in realtà tutto scaturisce da una storia molto più lunga che parte dagli studi di Leibniz quando non esistevano i calcolatori digitali, e coinvolge grandi studiosi come Frege, Gödel, e Turing.</p>

<!--more-->


<h2>Gottfried Wilhelm von Leibniz</h2>

<p>Leibniz (Lipsia, 21 giugno 1646 – Hannover, 14 novembre 1716), è stato un filosofo, matematico, e logico tedesco. Ai suoi tempi la logica era quella Aristotelica, quindi del tipo soggetto-predicato.</p>

<p>Leibniz fu il primo ad intuire l’<em style="mso-bidi-font-style: normal;">elaborazione simbolica</em> con il suo progetto della <strong>Characteristica Universalis</strong>. L’idea alla base della Cu (Characteristica Universalis) era quella di creare un linguaggio universale per migliorare le comunicazioni politiche, religiose, e commerciali; quindi la Cu doveva essere un linguaggio in grado di guidare ogni sorta di ragionamento.</p>

<p>Il progetto della Cu prevedeva:</p>

<ol>
<li><p><!-- [if !supportLists]-->Una</p>

<p><strong>Lista</strong> dei concetti primitivi e simboli corrispondenti</p></li>
<li><p><!-- [if !supportLists]--></p>

<p><!--[endif]-->Un’</p>

<p><strong>Arte Combinatoria</strong> utile a combinare i concetti primitivi:</p>

<ol>
<li><p><!-- [if !supportLists]--></p>

<p><!--[endif]--></p>

<p><span style="text-decoration: underline;">Ars Iudicandi</span>: procedura di decisione della verità</p></li>
<li><p><!--[endif]--></p>

<p><span style="text-decoration: underline;">Ars Invenendi</span>: procedura di decisione generativa</p></li>
</ol>
</li>
</ol>


<p>Notiamo che l’Ars Iudicandi e l’Ars Invenendi <em>prevedevano l’introduzione nel sistema della Cu di due procedure effettive</em>, ovvero ci doveva essere un procedimento preciso (algoritmo) sia per decidere la verità di una sentenza del linguaggio (Ars Iudicandi), sia per ottenere altre verità dalle verità che già conosciamo (Ars Invenendi).</p>

<p>I concetti di <strong>Procedura Effettiva</strong> e <strong>Calcolo Simbolico</strong> sono dunque nati da quest’idea di Leibniz.</p>

<p>Purtroppo il programma di sviluppare questo linguaggio è solo un progetto di Leibniz che non è mai stato sviluppato. Abbiamo solo dei documenti e schizzi a riguardo, che saranno poi usati da Frege.</p>

<p>Qui notiamo che l’Ars Iudicandi prevede una sorta di predicato dim(x,y), vero quando x è (il numero di) una dimostrazione della formula (di numero) y. Quindi è quasi un esempio compiuto di <strong>Sistema Formale</strong>.</p>

<h2>Immanuel Kant</h2>

<p>Kant (Königsberg, 22 aprile 1724 – Königsberg, 12 febbraio 1804) è stato un filosofo tedesco. Egli scrive un’opera alla fine del ‘700 nella quale diceva: “<em>La matematica è una cosa certa, e noi dobbiamo studiare solo come arrivare a questa certezza. Inoltre ci si può chiedere: perché la matematica è certa? Qual è il suo fondamento?</em>”.</p>

<p>Frege proverà a rispondere a questa domanda.</p>

<h2>Friedrich Ludwig Gottlob Frege</h2>

<p>Frege (Wismar, 8 novembre 1848 – Bad Kleinen, 26 luglio 1925) è stato un matematico, logico e filosofo tedesco, padre della logica matematica moderna.</p>

<p>Frege voleva rispondere alla domanda posta da Kant (<em>“Perché la matematica è certa?”</em>), usando l’intuizione che aveva avuto Leibniz nella sua Characteristica Universalis.</p>

<p>Qui è introdotta la <strong>Tesi Logicista</strong> (o <strong>Programma Logicista</strong>):</p>

<p align="center">
  “La Matematica è riconducibile alla Logica”
</p>


<p>Si afferma che la matematica è logica! Per portare avanti il Programma Logicista, Frege introduce la logica del primo e del secondo ordine come la conosciamo attualmente. Lui la chiamava <em>Ideografia</em>.</p>

<p>Nel 1879 Frege propose l’<em style="mso-bidi-font-style: normal;">Ideografia</em> un “linguaggio in formule del pensiero puro, a imitazione di quello aritmetico” in cui dice: il modo più sicuro di condurre una dimostrazione è quello puramente logico, il quale astrae dalla natura particolare delle cose e si basa soltanto sulle leggi sulle quali si fonda ogni conoscenza.</p>

<p>A supporto della Tesi Logicista, fu introdotto il primo esempio compiuto di <strong>Sistema Formale</strong>, ovvero un sistema che vincola il processo dimostrativo in modo tale che è sempre possibile riconoscere mediante un procedimento algoritmico se una qualsiasi configurazione di simboli è una dimostrazione oppure no.</p>

<p>Questo <em>sistema formale</em> prevedeva:</p>

<ol>
<li><p><!-- [if !supportLists]-->Insieme Finito di</p>

<p><strong>Assiomi Logici</strong>.</p></li>
<li><p><!-- [if !supportLists]--></p>

<p><!--[endif]-->Insieme Finito di</p>

<p><strong>Regole di Inferenza</strong> che, senza introdurre conoscenza implicita, ci permettano di dedurre gli assiomi della Matematica dall’insieme di <em>Assiomi Logici</em>.</p></li>
</ol>


<p>Inoltre ci sono due importanti <strong>Condizioni di Effettività</strong> che specificano un <em>Sistema Formale</em>:</p>

<ul>
<li><p><!-- [if !supportLists]-->L’insieme degli Assiomi Logici è</p>

<p><strong>Effettivamente Decidibile</strong></p></li>
<li>L’insieme delle Dimostrazioni Logiche è <strong>Effettivamente Decidibile</strong></li>
</ul>


<p>In quest’ultima richiesta si intravede qualcosa del teorema di Gödel; si chiede che il predicato dim(x,y) sia effettivamente decidibile!</p>

<p>Come in Leibniz, anche questa volta ci deve essere un procedimento formale (Algoritmo) che ci assicuri le condizioni di effettività. Ma questa volta le condizioni di effettività sono espressamente richieste.</p>

<p>Inoltre Leibniz e Frege hanno obiettivi diversi, il primo vuole un linguaggio universale, mentre il secondo vuole verificare la certezza della matematica (un problema più piccolo rispetto alla definizione di una lingua universale); entrambi usano la logica come strumento per raggiungere il proprio fine epistemologico.</p>

<h2>Bertrand Arthur William Russell</h2>

<p>Frege prosegue con il suo programma logicista puntando a dimostrare gli assiomi della matematica (gli assiomi di Peano) partendo solo dagli <em>assiomi logici</em>. Nel sistema formale definito da Frege si possono individuare:</p>

<ul>
<li>Il principio di <strong>Coestensione</strong>: “data una proprietà P, esiste l’insieme y di tutti gli x che godono della proprietà P”</li>
<li><p><!-- [if !supportLists]-->Il principio del</p>

<p><strong>Terzo Escluso</strong>: almeno uno tra <em>x</em> e <em>not</em> <em>x</em> deve essere vero.</p></li>
</ul>


<p>Russell (Trellech, 18 maggio 1872 – Penrhyndeudraeth, 2 febbraio 1970), è stato un filosofo, logico e matematico gallese. Si interessò al lavoro di Frege, e formulò il famoso Paradosso di Russell, causa della caduta del Programma Logicista.</p>

<p><span style="text-decoration: underline;">Paradosso di Russell</span>: Supponiamo la proprietà: <em>not__(x appartiene ad x)</em></p>

<p>Un elemento che gode di questa proprietà non appartiene a se stesso. Per il principio della coestensione c’è l’insieme di tutti gli elementi che godono di questa proprietà. Quindi diciamo y l’insieme di tutti gli elementi che non appartengono a se stessi. Adesso ci chiediamo: y appartiene a se stesso?</p>

<ul>
<li><p><!-- [if !supportLists]-->Se y appartiene a se stesso allora gode della proprietà di non appartenere a se stesso.</p></li>
<li><p><!-- [if !supportLists]-->Se y non appartiene a se stesso allora per come è definito deve appartenere a se stesso</p></li>
</ul>


<p>In entrambi i casi, grazie al principio del terzo escluso, giungiamo ad una contraddizione (questa è un’<strong>antinomia</strong>).</p>

<p>Russell nel 1901 formulò il paradosso e si rese conto delle conseguenze che avrebbe avuto per il programma logicista. Non esitò a mettersi in contatto con Frege con una lettera nell&#8217;estate del 1902 in cui illustra il paradosso.</p>

<p>Frege prese atto delle conseguenze distruttive per il sistema che aveva costruito in quegli anni e decise di scrivere un&#8217;appendice ai suoi Principî in cui confessava il fallimento della sua opera.</p>

<p>Siamo davanti ad una scelta:</p>

<p class="MsoListParagraph">
  <!-- [if !supportLists]-->&#8211;

  <em> rinunciare al principio del terzo escluso</em>: e quindi rinunciare alla logica classica
</p>


<p>oppure</p>

<p class="MsoListParagraph">
  <!-- [if !supportLists]-->&#8211;

  <em> rinunciare al principio di coestensione</em>: ma in questo caso non si riescono più a derivare gli assiomi della matematica
</p>


<p>Qui il Programma Logicista, e sorge il <span style="text-decoration: underline;">problema della certezza della matematica</span>.</p>

<p>A seguire ci saranno due programmi che puntano a risolvere il problema della certezza della matematica: Il <strong>Programma Intuizionista</strong>, ed il <strong>Programma di Hilbert</strong>.</p>

<h2>Luitzen Egbertus Jan Brouwer</h2>

<p>Brouwer (Overschie, 27 febbraio 1881 – Blaricum, 2 dicembre 1966) è stato un matematico olandese. Fondò la <strong>Scuola Intuizionista (o costruttivista)</strong>, nella quale dubitò</p>

<p>del <em>principio del terzo escluso</em>.</p>

<p>I requisiti del Programma Intuizionista erano:</p>

<ol>
<li><p><!--[endif]-->Eliminazione del Principio del Terzo Escluso su totalità infinite.</p></li>
<li><p>Interpretazione delle dimostrazioni in modo Costruttivista: cioè una dimostrazione di “esiste x tale che P(x)” deve effettivamente esibire un elemento y per il quale è vero P(y).</p></li>
</ol>


<p>Quindi gli intuizionisti puntano a limitare la matematica, eliminando l’uso di proposizioni ideali, come l’infinito in atto (o infinito attuale), che hanno permesso alla matematica di raggiungere ottimi risultati.</p>

<h2>David Hilbert</h2>

<p>Hilbert (Königsberg, 23 gennaio 1862 – Gottinga, 14 febbraio 1943) è stato un matematico tedesco. Rispose agli intuizionisti con il cosiddetto <strong>Programma di Hilbert</strong>.</p>

<p>Al contrario di Frege che voleva dimostrare gli assiomi matematici patendo dagli assiomi logici, Hilbert voleva formalizzare la matematica con degli assiomi e poi verificare la coerenza delle teorie matematiche formalizzate.</p>

<p>Quindi:</p>

<ol>
<li><p><!-- [if !supportLists]--></p>

<p><!--[endif]-->Formalizzare tutte le teorie matematiche</p>

<p><em>“T”</em> con sistemi formali T</p></li>
<li><p><!-- [if !supportLists]--></p>

<p><!--[endif]-->Dimostrare la coerenza di tali sistemi T con</p>

<p><span style="text-decoration: underline;">metodi matematici finitisti</span>.</p></li>
</ol>


<p>Si comincio con la più semplice delle teorie, ossia con l’Aritmetica Elementare. I <em>metodi matematici finitisti</em> non sono mai stati definiti da Hilbert con precisione. Di sicuro sono metodi matematici in cui vengono chiesti i requisiti intuizionisti: quindi no al terzo escluso su totalità infinite e interpretazione costruttivista delle dimostrazioni. Molti concordano che i metodi finitisti sono inclusi nell’aritmetica Primitiva Ricorsiva dove valgono gli assiomi di Peano che descrivono l’aritmetica elementare.</p>

<p>Nasce la meta-matematica, ossia la parte della matematica che consente di studiare la matematica da punti di vista generali. Stiamo cioè usando la matematica stessa per risolvere il <span style="text-decoration: underline;">problema della certezza della matematica</span>.</p>

<p>Nella metamatematica possiamo studiare varie proprietà dei sistemi formali, ad esempio:</p>

<ul>
<li><p><!-- [if !supportLists]--></p>

<p><strong>Coerenza</strong>: se T dimostra A allora non può dimostrare not A</p></li>
<li><p><!-- [if !supportLists]--></p>

<p><strong>Correttezza</strong>: se T dimostra A allora A è vero nella teoria <em style="mso-bidi-font-style: normal;">“T”</em></p></li>
<li><strong>Completezza</strong>: se A è vero nella teoria <em>“T”</em> allora T dimostra A</li>
</ul>


<p>Notiamo che la correttezza di un sistema formale T implica la sua coerenza.</p>

<p>Ricapitolando Hilbert con il suo <strong>Programma della Coerenza</strong> (che è solo una parte del <strong>Programma di Hilbert</strong>) vuole dimostrare la coerenza della matematica utilizzando la matematica stessa.</p>

<h2>Principia Mathematica (PM)</h2>

<p>I Principia Mathematica, scritti da Russell e Whitehead tra il 1910 e il 1913, rappresentano un’importante tentativo di formalizzare la matematica con la logica. Traggono origine dal lavoro di Frege.</p>

<p>Chiameremo PM il sistema formale formalizzato in questo lavoro.</p>

<h2>Kurt Gödel</h2>

<p>Gödel (Brno, 28 aprile 1906 – Princeton, 14 gennaio 1978) è stato un matematico, logico e filosofo statunitense di origine austro-ungarica, noto soprattutto per i suoi lavori sull&#8217;incompletezza delle teorie matematiche. Gödel è ritenuto uno dei più grandi logici di tutti i tempi insieme a Frege e Aristotele.</p>

<p>Gödel si interessa al Programma di Hilbert, e formula il suo <strong>primo teorema di incompletezza</strong>:</p>

<p style="margin-left: 35.4pt;">
  <em>Se PM è coerente, allora esiste una formula G nel linguaggio L(PM) tale che G è vera e non è dimostrabile in PM ne G ne not G</em>
</p>


<p>Ne segue come corollario il <strong>secondo teorema di incompletezza</strong>:</p>

<p style="margin-left: 35.4pt;">
  <em>Se PM è coerente, e dato che la coerenza di PM è esprimibile all’interno di PM stesso (consis(PM) appartiene a L(PM)) allora in PM non è dimostrabile consis(PM)</em>
</p>


<p>Il <strong>secondo teorema di incompletezza</strong> è quello che fa cadere il <strong>Programma di Hilbert</strong> poiché afferma che non possiamo dimostrare la coerenza di PM all’interno di PM stesso,</p>

<p>cioè non possiamo dimostrare la coerenza della matematica all’interno della matematica stessa.</p>

<p>Però i teoremi di incompletezza si riferiscono al <strong>Sistema Formale</strong> PM. Per far cadere definitivamente il Programma di Hilbert bisognava generalizzare i teoremi di incompletezza a qualsiasi <strong>Sistema Formale</strong> che contiene l’aritmetica elementare.</p>

<h2>Generalizzazione dei Teoremi di Incompletezza</h2>

<p>Vogliamo generalizzare i teoremi di incompletezza in questo modo:</p>

<p><em>Per ogni sistema formale S tale che:</em></p>

<ol>
<li><p><!-- [if !supportLists]--></p>

<p><em>S contiene P (Aritmetica di Peano)</em></p></li>
<li><p><!-- [if !supportLists]--></p>

<p><em>S soddisfa la <strong>condizioni di effettività</strong> di Frege</em></p>

<ul>
<li><p><!-- [if !supportLists]--></p>

<p> <em>a) L’insieme degli assiomi è effettivamente decidibile</em></p></li>
<li><p><!-- [if !supportLists]--></p>

<p><em>b) L’insieme delle dimostrazioni è effettivamente decidibile</em></p></li>
</ul>
</li>
<li><p><!-- [if !supportLists]--></p>

<p><em>S è coerente</em></p></li>
</ol>


<p><em>Allora per S valgono i teoremi di incompletezza</em></p>

<p>Le ipotesi 1 e 3 sono ben precise. L’ipotesi 2.a e 2.b invece no! Infatti esse chiedono di avere due funzioni <strong>effettivamente calcolabili</strong> f(x) e g(Y) le quali ci decidano rispettivamente le formule ben formate di S e le dimostrazioni di S.</p>

<p>Questo è il punto di snodo tra i fondamenti della matematica e la nascita dell’informatica. Infatti una funzione è effettivamente calcolabile se esiste un algoritmo per essa.</p>

<p>Ma quale’è il concetto di algoritmo? Quali sono le funzioni calcolabili mediante un procedimento di calcolo (algoritmo)?</p>

<p>Tutt’ora non esiste un concetto di algoritmo preciso. La classe di tutti gli algoritmi è delineata con la tesi di Church-Turing, la quale essendo una tesi non può essere dimostrata.</p>

<h2>Alan Mathison Turing</h2>

<p>Turing (Londra, 23 giugno 1912 – Wilmslow, 7 giugno 1954) è stato un matematico, logico e crittanalista britannico, considerato uno dei padri dell&#8217;informatica.</p>

<p>Lavorò alla generalizzazione del teorema di Gödel, tentando di rispondere alla domanda: <em>“che cos’è una funzione parzialmente calcolabile mediante un procedimento di calcolo (algoritmo)?”</em>.</p>

<p>Church a quei tempi lavorava alla stessa domanda definendo la classe delle funzioni matematiche PRF, per poi arrivare ad un procedimento di calcolo (λ-calcolo).</p>

<p>Turing invece cominciò questo lavoro cominciando a definire il procedimento di calcolo (definito dalla <strong>Macchina di Turing</strong>), per poi arrivare alla classe di tutte le funzioni calcolabili da una <strong>Macchina di Turing</strong>.</p>

<p>Per definire la sua Macchia di Turing (d’ora in poi MdT), Turing osservo il comportamento di un essere umano che calcola. Quindi individua una serie di restrizioni:</p>

<ol>
<li><p><!-- [if !supportLists]-->L’umano effettua dei calcoli aiutandosi con un foglio. Nel caso di una macchina possiamo pensare ad un nastro potenzialmente infinito fatto di caselle contigue. In ogni casella possiamo</p>

<p>scrivere un simbolo appartenente ad un alfabeto.</p></li>
<li><p><!-- [if !supportLists]-->Limiti all’uso del nastro</p>

<ul>
<li><p><!-- [if !supportLists]-->a.</p>

<p><!--[endif]-->Limite Percettivo: c’è un limite superiore B al numero di caselle contigue osservabili in un istante (questo implica che ci si può spostare sul nastro per vedere le prossime B caselle).</p></li>
<li><p><!-- [if !supportLists]-->b.</p>

<p><!--[endif]-->Limite di Memoria: l’alfabeto dei simboli scrivibili sul nastro è finito poiché l’essere umano non riesce a distinguere e ricordareinfiniti simboli.</p></li>
</ul>
</li>
<li><p><!-- [if !supportLists]-->Il comportamento dipende dallo stato mentale (stato di memoria) dell’essere umano. Questo stato mentale dipende dalle azioni fatte precedentemente. Senza indagare molto sul cervello umano, imponiamo che questi stati siano in numero finito (deciso a priori).</p></li>
<li><p><!-- [if !supportLists]-->Limitiamo il comportamento dell’essere umano che calcola, senza perdita di generalità, al compimento di un’azione per volta:</p>

<ul>
<li><p><!-- [if !supportLists]-->a.</p>

<p><!--[endif]-->Si può cambiare il contenuto solo delle caselle osservate</p></li>
<li><p><!-- [if !supportLists]-->b.</p>

<p><!--[endif]-->Ci si può spostare di un numero L di caselle per volta</p></li>
<li><p><!-- [if !supportLists]-->c.</p>

<p><!--[endif]-->Si può cambiare lo stato mentale</p></li>
</ul>
</li>
<li><p><!-- [if !supportLists]-->Il calcolo è fatto in maniera Deterministica, dato lo stesso input otteniamo sempre lo stesso output</p></li>
</ol>


<p>Ma come imponiamo la condizione di determinismo?</p>

<p>Consideriamo tutte le possibili azioni che può fare l’essere umano durante il calcolo. Diciamo C l’insieme di tutte le possibili coppie <stato mentale, configurazione dei simboli osservati>. Per ogni elemento di C si può scegliere di fare un’azione a scelta contenuta nell’insieme possibili di azioni A (scrittura di un simbolo, spostamento a destra, spostamento a sinistra, cambiamento di stato mentale). Definiamo l’insieme di tutte le possibili istruzioni I=CxA. L’insieme delle istruzioni come definito contiene delle istruzioni che definiscono un algoritmo <strong>non deterministico</strong>, poiché a parità di stato mentale e configurazioni di simboli osservati, possiamo trovare istruzioni che effettuano azioni diverse. Poniamo qui una condizione di <strong>determinismo</strong>, chiedendo di avere come insieme di istruzioni solo un sottoinsieme di I nel quale non compaiano istruzioni che possono essere applicate nello stesso stato del calcolo.</p>

<p>Questa è l’analisi dell’essere umano che calcola.</p>

<p>Adesso definiamo una macchina che simulerà il comportamento di calcolo dell’essere umano. Questa macchina avrà delle configurazioni interne q, che corrispondono agli stati mentali dell’umano. Lavora su un nastro osservando ad ogni nastro un numero B di caselle contigue, e può spostarsi di un numero L di caselle a destra o a sinistra. Può usare i simboli dell’alfabeto per scrivere sulla porzione di nastro osservata, e può cambiare la sua configurazione interna. Questa macchina riproduce il comportamento di calcolo di un essere umano.</p>

<p>Ponendo i vincoli B=1 e L=1 abbiamo proprio la definizione di <strong>Macchina di Turing</strong> (MdT). Chiamiamo classe delle funzioni Turing calcolabili (o T-calcolabili), la classe delle funzioni calcolabili con una MdT.</p>

<p>Turing arriva a formulare la seguente tesi:</p>

<p align="center">
  “Ogni funzione calcolabile da un essere umano mediante algoritmo è una funzione T-calcolabile”
</p>


<p>Notiamo che questa tesi è però ristretta alle funzioni calcolate da un essere umano, e non da un qualsiasi agente di calcolo (come un calcolatore). Proviamo ad estendere questa tesi in questo modo:</p>

<p align="center">
  “Ogni funzione calcolabile da un calcolatore mediante algoritmo è una funzione T-calcolabile”
</p>


<p>Per arrivare alla tesi di Church-Turing, osserviamo che i limiti B ed L sono soggetti ai limiti della fisica: la teoria delle relatività ci vieta di oltrepassare la velocità della luce. Inoltre in una singola cella di nastro possiamo registrarci un simbolo preso da un alfabeto finito, perché assumiamo che la materia (del nastro) abbia un vincolo di atomicità, ma su questo non è ancora stata formulata alcuna teoria scientifica.</p>

<p>Considerando i limiti della fisica possiamo riscrivere la tesi ed ottenere finalmente la <strong>Tesi di Church-Turing</strong>:</p>

<p align="center">
  “Ogni funzione calcolabile da un algoritmo è una funzione T-calcolabile”
</p>


<p>Con questa tesi sono stati generalizzati i teoremi di incompletezza di Gödel, chiedendo che le funzioni f(x) e g(Y) siano T-calcolabili. Cade definitivamente il <strong>Programma di Hilbert</strong>,</p>

<p>e il suo tentativo di verificare la certezza della matematica.</p>

<h2>Sviluppi futuri</h2>

<p>Quindi dal problema della matematica è nata la MdT, e Turing stesso definì la <strong>Macchina di Turing Universale</strong>, la quale è programmabile proprio come un moderno calcolatore digitale.</p>

<p>Da questo nasce il ramo dell’Intelligenza Artificiale (IA), e più in generale dell’Informatica.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Recursive Implementation of Heap Sort Algorithm]]></title>
    <link href="http://fsferrara.github.io/c-recursive-implementation-of-heap-sort-algorithm/"/>
    <updated>2010-07-11T00:46:14+00:00</updated>
    <id>http://fsferrara.github.io/c-recursive-implementation-of-heap-sort-algorithm</id>
    <content type="html"><![CDATA[<p>L&#8217; heapsort è un algoritmo di ordinamento iterativo ed in-place proposto da Williams nel 1964, che si basa su strutture dati ausiliarie.</p>

<blockquote><p>L&#8217; heapsort per eseguire l&#8217;ordinamento, utilizza una struttura chiamata heap (mucchio); un heap è rappresentabile con un albero binario in cui tutti i nodi seguono una data proprietà, detta priorità. Esso è completo almeno fino al penultimo livello dell&#8217;albero e ad ogni nodo corrisponde uno ed un solo elemento.</p>

<p>In uno heap decrescente (utilizzato per ordinare ad esempio un array in senso crescente) ogni nodo padre contiene un valore maggiore o uguale a quello dei suoi due figli diretti, di conseguenza risulterà maggiore anche di tutti i nodi che si trovano nel sottoalbero di cui esso è la radice; questo non implica affatto che nodi a profondità maggiore contengano valori minori di quelli a profondità minore.</p>

<p>Quindi in ogni istante, in un heap decrescente, la radice contiene il valore maggiore.</p>

<p>Questa struttura è molto usata, in particolare, per l&#8217;ordinamento di array.</p>

<p>In questo caso si considera come radice l&#8217;elemento iniziale di indice 1; inoltre i figli di un nodo con indice j, avranno indice rispettivamente 2j, quello sinistro, 2j+1 quello destro.</p>

<p><!--more-->Per comprendere meglio il funzionamento dell&#8217;algoritmo è bene capire che gli elementi che si trovano nella seconda metà dell&#8217;array rappresenteranno foglie dello heap e quindi esse saranno già al loro posto giusto; non vi è infatti alcun elemento dopo di esse.</p>

<p>&#8230;tratto da wikipedia</p></blockquote>

<h2>Implementazione Ricorsiva di Heap Sort</h2>

<p><span style="font-family: Consolas, Monaco, monospace; font-size: 12px; line-height: 18px;">#include &lt;stdio.h></span></p>

<pre lang="c">#define MAX 20

int sinistro(int i)
{
 return 2*i+1;
}

int destro(int i)
{
 return 2*i+2;
}

int padre(int i)
{
 return (int)(i-1/2);
}

stampavettore(int *vettore,int n)
{
 int i;

 for(i=0 ; i&lt;=n ; printf("%d ",vettore[i++]));
}

int riempivettore(int *vettore)
{
 int i;

 i=0;
 do {
 printf("inserire l'elemento %d dell'array('-1' per terminare): ",i+1);
 scanf("%d",vettore+i);
 } while (vettore[i++] != -1);
 return i-2;
}

void scambia(int *n1,int *n2)
{
 int temp;

 temp = *n1;
 *n1 = *n2;
 *n2 = temp;
}

void heapify(int *vettore, int i,int heapsize)
{
 int l,r,maggiore;

 l = sinistro(i);
 r = destro(i);

 if ((l &lt;= heapsize) && (vettore[l] &gt; vettore[i]))
 {
 maggiore = l;
 }
 else
 {
 maggiore = i;
 }

 if ((r &lt;= heapsize) && (vettore[r]&gt;vettore[maggiore]))
 {
 maggiore = r;
 }
 if (maggiore != i)
 {
 scambia(&vettore[i],&vettore[maggiore]);
 heapify(vettore,maggiore,heapsize);
 }
}

void buildheap(int *vettore,int heapsize,int n)
{
 int i;

 for (i=(int)(n/2) ; i&gt;=0 ; i--)
 {
 heapify(vettore,i,heapsize);
 }
}

heapsort(int *vettore,int n)
{
 int i,heapsize;

 heapsize=n;
 buildheap(vettore,heapsize,n);
 for (i=n ; i&gt;0 ; i--)
 {
 scambia(&vettore[0],&vettore[i]);
 heapsize--;
 heapify(vettore,0,heapsize);
 }
}

main()
{
 int vettore[MAX];
 int n; /*numero di elementi*/

 n=riempivettore(vettore);

 heapsort(vettore,n);

 stampavettore(vettore,n);
}</pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[C Implementation of Heap Sort Algorithm]]></title>
    <link href="http://fsferrara.github.io/c-implementation-of-heap-sort-algorithm/"/>
    <updated>2010-07-10T00:40:54+00:00</updated>
    <id>http://fsferrara.github.io/c-implementation-of-heap-sort-algorithm</id>
    <content type="html"><![CDATA[<p>L&#8217; heapsort è un algoritmo di ordinamento iterativo ed in-place proposto da Williams nel 1964, che si basa su strutture dati ausiliarie.</p>

<blockquote><p>L&#8217; heapsort per eseguire l&#8217;ordinamento, utilizza una struttura chiamata heap (mucchio); un heap è rappresentabile con un albero binario in cui tutti i nodi seguono una data proprietà, detta priorità. Esso è completo almeno fino al penultimo livello dell&#8217;albero e ad ogni nodo corrisponde uno ed un solo elemento.</p>

<p>In uno heap decrescente (utilizzato per ordinare ad esempio un array in senso crescente) ogni nodo padre contiene un valore maggiore o uguale a quello dei suoi due figli diretti, di conseguenza risulterà maggiore anche di tutti i nodi che si trovano nel sottoalbero di cui esso è la radice; questo non implica affatto che nodi a profondità maggiore contengano valori minori di quelli a profondità minore.</p>

<p>Quindi in ogni istante, in un heap decrescente, la radice contiene il valore maggiore.</p>

<p>Questa struttura è molto usata, in particolare, per l&#8217;ordinamento di array.</p>

<p>In questo caso si considera come radice l&#8217;elemento iniziale di indice 1; inoltre i figli di un nodo con indice j, avranno indice rispettivamente 2j, quello sinistro, 2j+1 quello destro.</p>

<p><!--more-->Per comprendere meglio il funzionamento dell&#8217;algoritmo è bene capire che gli elementi che si trovano nella seconda metà dell&#8217;array rappresenteranno foglie dello heap e quindi esse saranno già al loro posto giusto; non vi è infatti alcun elemento dopo di esse.</p>

<p>&#8230;tratto da wikipedia</p></blockquote>

<h2>Implementazione Iterativa di Heap Sort</h2>

<p>L&#8217;algoritmo che ordina in senso crescente inizia creando uno heap decrescente. Per ogni iterazione si copia la radice (primo elemento dell&#8217;array) in fondo all&#8217;array stesso, eseguendo uno scambio di elementi. L&#8217;algoritmo poi ricostruisce uno heap di n &#8211; 1 elementi spostando verso il basso la nuova radice, e ricomincia con un altro scambio (tra il primo elemento dell&#8217;array e quello in posizione n &#8211; 1), eseguendo un ciclo che considera array di dimensione progressivamente decrescente.</p>

<pre lang="c">#include &lt;stdio.h&gt;
#define MAX 20

int sinistro(int i)
{
 return 2*i+1;
}

int destro(int i)
{
 return 2*i+2;
}

int padre(int i)
{
 return (int)(i-1/2);
}

stampavettore(int *vettore,int n)
{
 int i;

 for(i=0 ; i&lt;=n ; printf("%d ",vettore[i++]));
}

int riempivettore(int *vettore)
{
 int i;

 i=0;
 do {
 printf("inserire l'elemento %d dell'array('-1' per terminare): ",i+1);
 scanf("%d",vettore+i);
 } while (vettore[i++] != -1);
 return i-2;
}

void scambia(int *n1,int *n2)
{
 int temp;

 temp = *n1;
 *n1 = *n2;
 *n2 = temp;
}

void heapify(int *vettore, int i,int heapsize)
{
 int l,r,maggiore,violazione=1;

 while (violazione)
 {
 l = sinistro(i);
 r = destro(i);

 if ((l &lt;= heapsize) && (vettore[l] &gt; vettore[i]))
 {
 maggiore = l;
 }
 else
 {
 maggiore = i;
 }

 if ((r &lt;= heapsize) && (vettore[r]&gt;vettore[maggiore]))
 {
 maggiore = r;
 }
 if (maggiore != i)
 {
 scambia(&vettore[i],&vettore[maggiore]);
 i=maggiore;
 }
 else
 {
 violazione = 0;
 }
 }
}

void buildheap(int *vettore,int heapsize,int n)
{
 int i;

 for (i=(int)(n/2) ; i&gt;=0 ; i--)
 {
 heapify(vettore,i,heapsize);
 }
}

heapsort(int *vettore,int n)
{
 int i,heapsize;

 heapsize=n;
 buildheap(vettore,heapsize,n);
 for (i=n ; i&gt;0 ; i--)
 {
 scambia(&vettore[0],&vettore[i]);
 heapsize--;
 heapify(vettore,0,heapsize);
 }
}

main()
{
 int vettore[MAX];
 int n; /*numero di elementi*/

 n=riempivettore(vettore);

 heapsort(vettore,n);

 stampavettore(vettore,n);
}</pre>


<p>Si può dimostrare che la complessità asintotica massima dell&#8217;heap sort è O(nlogn). Tuttavia, in generale (e soprattutto per array quasi ordinati) altri algoritmi con la medesima complessità asintotica, per esempio quick sort o merge sort, ottengono migliori prestazioni. Per array di piccole dimensioni è addirittura più veloce l&#8217;insertion sort nonostante abbia una complessità di O(n<sup>2</sup>))</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ISDN Technology]]></title>
    <link href="http://fsferrara.github.io/isdn-technology/"/>
    <updated>2010-01-09T01:28:47+00:00</updated>
    <id>http://fsferrara.github.io/isdn-technology</id>
    <content type="html"><![CDATA[<p>Integrated Services Digital Network, o ISDN, è una rete digitale che dà supporto a molti servizi di voce e dati. La definizione tecnica dell&#8217;ISDN, che investe diverse componenti delle reti, risale alle raccomandazioni ITU-T della serie I del 1984 e comprende numerose altre pubblicazioni dello stesso ITU-T e dell&#8217;ETSI (European Telecommunications Standard Institute) fatte negli anni successivi.</p>

<!--more-->


<h2>**Integrated Services Digital Network &#8211; ISDN</h2>

<p>**</p>

<p>ISDN è un servizio di <em>telefonia digitale</em> basato sul protocollo ISDN. Quindi con il termine ISDN ci riferiamo sia al protocollo, sia al servizio implementato dal protocollo stesso.</p>

<p>ISDN: protocollo che descrive come si svolgono le chiamate</p>

<p>Una rete ISDN è quindi una rete digitale anche integrata nei servizi, in cui le diverse parti, il terminale, la rete di accesso, la rete di trasporto, sono realizzate per offrire gli stessi servizi. Elementi fondamentali per il supporto di tali servizi sono il protocollo di segnalazione della rete di trasporto ISUP (ITU-T Q.767) e della rete di accesso DSS1 (ITU-T Q.931), che fanno parte della pila di protocolli del sistema di segnalazione a canale comune n°7 insieme ad altri descritti nelle Racc. ITU-T serie Q. Attraverso tali protocolli vengono trasportate le informazioni che consentono l&#8217;espletamento dei diversi servizi; un esempio per tutti l&#8217;identità del chiamante, che viene trasportata dai protocolli di segnalazione dalla rete del chiamante verso la rete e il terminale del chiamato.</p>

<p>In Europa è usata la variante ISDN-DSS1 sviluppata da ETSI (European Telecomunications Standards Institute).</p>

<p>Sull&#8217;accesso BRA ISDN sono disponibili una serie di nuovi servizi come la segnalazione del numero telefonico di chi chiama (Caller ID) e il multinumero, cioè la possibilità di avere fino ad otto numeri telefonici sullo stesso abbonamento, ciascuno assegnato ad un apparecchio diverso (es. uno per il telefono, uno per il fax, uno per il modem in ingresso&#8230;). La tecnologia digitale utilizzata da ISDN garantisce una qualità audio molto elevata, eliminando completamente la diafonia e buona parte dei disturbi presenti nella tradizionale telefonia . In Italia ISDN BRA viene fornito in modalità mononumero o multinumero: è possibile cioè richiedere fino a 7 numeri telefonici diversi oltre al numero principale. Sempre sull&#8217;accesso base (BRA), che comprende 2 canali B a 64 Kbit/sec, è possibile collegarsi ad Internet sia ad una velocità di 64 Kbit/s, pagando una semplice telefonata, sia, se il Provider utilizzato lo permette, ad una velocità di 128 Kbit/s, sostenendo però il costo di due chiamate contemporanee. Inoltre sono disponibili i servizi di avviso di chiamata, conferenza a tre, presentazione dell&#8217;identità del chiamante (Caller ID), trasferimento di chiamata e per alcuni Operatori anche il servizio di richiamata su occupato.</p>

<p>Molto diffusa in Italia un tipo particolare di NT, chiamata NT1+, che ha al suo interno anche un Terminal Adapter (TA) a/b, capace di gestire due porte analogiche, permettendo cosi&#8217; di connettere direttamente all&#8217;NT1+ apparati analogici come telefoni tradizionali o fax di gruppo 3. L&#8217;installazione della borchia ISDN deve essere richiesta al proprietario della rete.</p>

<p>Una ulteriore configurazione degli accessi è il &#8220;punto-punto&#8221; e &#8220;punto-multipunto&#8221; che in buona sostanza esprime il modo di dialogare della rete con uno o più terminali lato utente. La configurazione &#8220;punto-punto&#8221; è adottata in presenza, lato utente, di centralini (PABX)collegati sia su accesso primario che in pool di accessi base. La configurazione punto-multipunto è adottata ad esempio negli accessi base in cui sul bus isdn sono collegati dispositivi con numeri diversi (MSN) quali telefoni isdn, modem isdn, fax G4. La differenza tecnica che contraddistingue anche le due tipologie è il cosiddetto TEI, che viene utilizzato nel protocollo ISDN, per il quale una punto-punto è fisso a zero, mentre sulla punto-multipunto è variabile e deciso dalla centrale pubblica. Per capire se la tipologia e punto-punto o punto-multipunto, soprattutto nel caso di accesso base mononumero, bisogna contattare l&#8217;operatore che fornisce il servizio, non esistono veri e propri standard.</p>

<p><strong><span style="text-decoration: underline;">CALLER-ID</span>:</strong> è la funzione che ci permette di vedere il numero di chi ci chiama.</p>

<p><strong><span style="text-decoration: underline;">MULTINUMERO</span>:</strong> Possibilità di avere fino a 8 numeri su una singola linea ISDN. Ovviamente bisognerà assegnare un numero per ogni apparecchio.</p>

<p>Il collegamento ISDN più diffuso è quello base, a due canali (detto BRI):</p>

<ul>
<li>1° Canale: 64 kbit/s</li>
<li>2° Canale: 64 kbit/s</li>
<li>3° Canale aggiuntivo: 16 kbit/s (usato per le segnalazioni)</li>
</ul>


<p>La banda totale e&#8217; 144 kbit/s!!! Di questa banda, solo i canali da 64 kbit/s sono sfruttati per trasferire informazioni utili all&#8217;utente finale, quindi in effetti l&#8217;utente beneficia di 128 kbit/s (sempre teorici)</p>

<h2>Architettura ISDN</h2>

<h3>Alcuni termini</h3>

<ul>
<li><strong>NT (Network Terminator)</strong>: Traduce il segnale proveniente dalla centrale telefonica, mediante <em>U-BUS</em>, in segnale utilizzabile dai nostri dispositivi ISDN, su <em>S-BUS</em>. Inoltre il Network Terminator permette di attaccarci</li>
<li><strong>TA (Terminal Adapter)</strong> : Permette di allacciare vecchi dispositivi analogigi al Network Terminator, in moda da poterli riutilizzare. E&#8217; indicato per i vecchi FAX ;-) .</li>
</ul>


<h3>Esempio NT (Network Terminator)</h3>

<p>Un Network Terminator, che prende in ingresso un U-Bus dalla linea ISDN, e caccia in output due S-Bus per allacciarci due dispositivi ISDN (ad esempio due telefono ISDN).</p>

<p>Notiamo che in S-Bus non è che un cavo ethernet, usato per ISDN&#8230; e (forse) per U-Bus si usa il doppino telefonico, o anche in questo caso un cavo ethernet.</p>

<h2>Configurazione di ISDN</h2>

<p>Una linea ISDN può avere varie configurazioni, in modo da adattarsi all&#8217;hardware con il quale deve funzionare (esempio PBX &#8211; centralino telefonico).</p>

<h3>Canali</h3>

<p>ISDN supporta due tipi di canali:</p>

<p><strong>-> Canale B</strong> (Bearer): sono canali utilizzati per i dati ed hanno una banda prefissata di 64 kbit/s.</p>

<p><strong>-> Canale D</strong> (Delta): sono canali usati per segnalazioni e controllo; in particolari configurazioni possono essere usati anche per i dati. La banda passante assegnata ad un canale D varia al variare del tipo di <em>Accesso ISDN</em>.</p>

<h3>Accesso ISDN</h3>

<p>Esistono due tipi di accesso ISDN:</p>

<ul>
<li><strong>Accesso BRI [Basic Rate Interface &#8211; Accesso Base]</strong>:&#8211; 2 canali B&#8211; 1 canale D a 16 kbit/s==> Totale 2B+D = 144 kbit/s</li>
<li><strong>Accesso PRI T1 [Basic Rate Interface &#8211; Accesso Base]</strong>: (America, Giappone)&#8211; 23 canali B&#8211; 1 canale D a 64 kbit/s==> Totale 23B+D = 1536 kbit/s</li>
<li><strong>Accesso BRI E1 [Basic Rate Interface &#8211; Accesso Base]</strong>: (Europa, Asia, Australia)&#8211; 30 canali B&#8211; 2 canale D a 64 kbit/s==> Totale 30B+2D = 2048 kbit/s</li>
</ul>


<h3>Funzionamento Chiamate</h3>

<p>I canali D sono usati per <em>iniziare</em> le chiamate. Una volta che la chiamata è iniziata, ad essa è allocato un canale B&#8230; quindi per ogni chiamata deve essere disponibile un canale B (sempre di 64 kbit/s).</p>

<p>Notiamo come i canali B sono allocati sempre in modo dinamico!</p>

<h2>Considerazioni Tecniche</h2>

<p>L&#8217;evoluzione di ISDN l&#8217;ha portato ad essere adottato in anbito aziendale. Queste ultime scelgono spesso tra due opzioni di installazione: il <em>multinumero</em> e la <em>selezione passante</em>.</p>

<h3>Multinumero</h3>

<p>E&#8217; un servizio opzionale.  <span class="blue-pen">Permette di avere un massimo di 8 terminali, sullo steso S-BUS, ognuno raggiungibile direttamente dall&#8217;esterno con un suo proprio numero telefonico</span>.</p>

<ul>
<li>Possibile solo su ISDN accesso base (BRI)</li>
<li>Solo due terminali possono essere attivi contemporaneamente</li>
<li>Non chiede l&#8217;installazione di un PBX</li>
<li>Le chiamate interne sono a pagamento</li>
<li>NT (Network Terminator) deve essere configurato punto-multipunto</li>
</ul>


<h3>Selezione Passante</h3>

<p>E&#8217; un servizio opzionale.  <span class="blue-pen">Permette di raggiungere direttamente i terminali interni appoggiandoci su un PBX (centralino telefonico). Non si ha il limite di 8 terminali su ogni linea ISDN</span>.</p>

<ul>
<li>Possibile sia su linee BRI, sia su linee PRI</li>
<li>Non c&#8217;è limite al numero di terminali interni attivi contemporaneamente</li>
<li>Chiede l&#8217;instllazione di un PBX</li>
<li>Le chiamate interne NON sono a pagamento</li>
<li>NT (Network Terminator) deve essere configurato punto-punto</li>
</ul>


<h3>Considerazioni</h3>

<p>Il multinumero si adatta solo in pochi casi&#8230; spesso perche&#8217; sono richieste telefonate interne gratuite!</p>

<p><span class="blue-pen"><br /> Ad esempio possiamo avere cinque ingressi ISDN: ipotizziamo i numeri telefonici da 02160291<span style="text-decoration: underline;">01</span> a 02160291<span style="text-decoration: underline;">05</span> (Le ultime due cifre individuano la linea fisica, e sono 5 BRI &#8211; quindi max 10 telefonate esterne contemporaneamente).<br /> Grazie alla selezione passante riusciamo ad avere i numeri da 02160291<span style="text-decoration: underline;">00</span> a 02160291<span style="text-decoration: underline;">99</span>&#8230; un range di ben 100 numero!<br /> </span></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java Implementation of the Ackermann Function]]></title>
    <link href="http://fsferrara.github.io/java-implementation-of-the-ackermann-function/"/>
    <updated>2009-11-29T01:24:14+00:00</updated>
    <id>http://fsferrara.github.io/java-implementation-of-the-ackermann-function</id>
    <content type="html"><![CDATA[<p>Wilhelm Friedrich Ackermann (29/3/1896 – 24/12/1962) was a German mathematician best known for the Ackermann function, an important example in the theory of computation.</p>

<p>La funzione di Ackermann è una funzione f(x,y,z) che ha come dominio l&#8217;insieme delle terne di numeri naturali e come codominio i numeri naturali.</p>

<p>Essa è un esempio di funzione ricorsiva che non è primitiva ricorsiva poiché cresce più velocemente di qualsiasi funzione ricorsiva primitiva.</p>

<p><!--more--><figure id="attachment_122" style="max-width: 300px" class="wp-caption alignnone"></p>

<p><a href="http://www.fsferrara.com/wp-content/uploads/2013/10/ackermann.png"><img class="size-medium wp-image-122" src="http://www.fsferrara.com/wp-content/uploads/2013/10/ackermann-300x54.png" alt="Ackermann function description" width="300" height="54" srcset="http://www.fsferrara.com/wp-content/uploads/2013/10/ackermann-300x54.png 300w, http://www.fsferrara.com/wp-content/uploads/2013/10/ackermann.png 477w" sizes="(max-width: 300px) 100vw, 300px" /></a><figcaption class="wp-caption-text">Ackermann function description</figcaption></figure></p>

<p>Qui il codice java che implementa questa funzione:</p>

<p><span style="text-decoration: underline;">Ackermann.java</span></p>

<p><pre lang="java">public class Ackermann {</p>

<p> static long count = 0;</p>

<p> private static long h(long m, long n) {</p>

<p>  count++;</p>

<p>  if (m == 0) {
   return n + 1;
  }
  if (n == 0) {
   return h(m-1, 1);
  }</p>

<p>  return h(m-1, h(m,n-1) );
 }</p>

<p> private static long ack(long n) {
  return h(n, n);
 }</p>

<p> public static void main(String[] args) {</p>

<p>  if (args.length != 1) {
   System.out.println(&ldquo;usage: Ackermann &lt;number&gt;\n\twhere number is a positive integer&rdquo;);
   System.exit(1);
  }</p>

<p>  long n = Long.valueOf(args[0]);</p>

<p>  count = 0;
  long retValue = ack(n);  
  System.out.println(&ldquo;ack(&rdquo; + n + &ldquo;) = &rdquo; + retValue + &ldquo; [recursive calls = &rdquo;+ count +&ldquo;]&rdquo;);</p>

<p>  System.exit(0);
 }</p>

<p>}</pre></p>

<p>Il meccanismo di calcolo della funzione è estremamente semplice quanto pesante dal punto di vista computazionale. Questi sono i risultati ottenuti:</p>

<ul>
<li>ack(0) = <strong>1</strong>  [recursive calls = <strong>1</strong>]</li>
<li>ack(1) = <strong>3</strong>  [recursive calls = <strong>4</strong>]</li>
<li>ack(2) = <strong>7</strong>  [recursive calls = <strong>27</strong>]</li>
<li>ack(3) = <strong>61</strong> [recursive calls = <strong>2432</strong>]</li>
</ul>


<p>Non riesco a calcolare ack(4) causa stack overflow (Exception in thread &#8220;main&#8221; java.lang.StackOverflowError).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[XQuery Queries in Java]]></title>
    <link href="http://fsferrara.github.io/xquery-queries-in-java/"/>
    <updated>2009-10-29T00:55:37+00:00</updated>
    <id>http://fsferrara.github.io/xquery-queries-in-java</id>
    <content type="html"><![CDATA[<p style="text-align: justify;">
  XQuery, una abbrevazione per XML Query Language, è un linguaggio di programmazione specificato dal W3C e destinato ad interrogare documenti e basi di dati XML. Questo perché XML si sta proponendo come la tecnologia per rimpiazzare i vecchi DBMS relazionali :-)
</p>




<p style="text-align: justify;">
  Il w3c ha definito il linguaggio XQuery 1.0; usa la sintassi delle espressioni di XPath  2.0, con l&#8217;aggiunta delle cosiddette espressioni FLWOR per la formulazione di query complesse. Il risultato è un linguaggio di programmazione funzionale, dichiarativo, con somiglianze con il vecchio SQL.
</p>




<p style="text-align: justify;">
  Per effettuare delle query xquery su un file XML possiamo usare delle librerie come BaseX e Saxon. Purtroppo attualmente Saxon non è un prodotto del tutto gratuito, quindi scegliamo di usare BaseX, un processore Xquery-XPath open source.
</p>




<p style="text-align: justify;">
  <!--more-->In realtà BaseX, oltre ad essere utlilizzabile come libreria all&#8217;interno del linguaggio Java, ci mette a disposizione un&#8217;interfaccia grafica dalla quale possiamo effettuare query su file XML ben formati arbitrari.
</p>




<h2 style="text-align: justify;">
  Primo esempio di query
</h2>




<p style="text-align: justify;">
  La prima cosa da fare è inserire i file jar di BaseX nel build path del nostro progetto; la seconda è assicurarsi di avere java 1.6 (non funziona con java 1.5) perché BaseX utilizza il package javax.xml.stream.
</p>




<p style="text-align: justify;">
  Questo è un sempio dove si esegue la query <strong>//li </strong>sul file &#8216;<strong>input</strong>&#8216;:
</p>




<pre lang="java">import javax.xml.xquery.XQConnection;
import javax.xml.xquery.XQDataSource;
import javax.xml.xquery.XQPreparedExpression;
import javax.xml.xquery.XQResultSequence;

public final class XQueryAPIExample {
 /** Database Driver. */
 static final String DRIVER = "org.basex.api.xqj.BXQDataSource";

 public static void main(final String[] args) throws Exception {

 // Gets the XQDataSource for the specified Driver.
 XQDataSource source = (XQDataSource) Class.forName(DRIVER).newInstance();

 // Creates an XQConnection
 XQConnection conn = source.getConnection();

 // Prepares the Expressionwith the Document and the Query.
 XQPreparedExpression expr = conn.prepareExpression("doc('input')//li");

 // Executes the XQuery query.
 XQResultSequence result = expr.executeQuery();

 // Gets all results of the execution.
 while(result.next()) {
 // Prints the results to the console.
 System.out.println(result.getItemAsString(null));
 }

 }
}</pre>




<p style="text-align: justify;">
  Questo esempio funziona solo se il file XML interrogato non dichiara nessun namespace.
</p>




<h2 style="text-align: justify;">
  Query in presenza di namespace
</h2>




<p style="text-align: justify;">
  Supponiamo adesso di interrogare un file XML con namespace&#8230; ad esempio un file in formato XML Mpeg-7 che usa i seguenti namespace:<br /> xmlns=&#8221;urn:mpeg:mpeg7:schema:2001&#8243;<br /> xmlns:mpeg7=&#8221;urn:mpeg:mpeg7:schema:2001&#8243;<br /> xmlns:xsi=&#8221;http://www.w3.org/2001/XMLSchema-instance&#8221;
</p>




<p style="text-align: justify;">
  Per far riconoscere i namespace dobbiamo dichiararli nel prologo della xquery in questo modo:<br /> declare default element namespace &#8220;urn:mpeg:mpeg7:schema:2001&#8221;<br /> declare  namespace mpeg7 = &#8220;urn:mpeg:mpeg7:schema:2001&#8221;<br /> declare  namespace xsi = &#8220;http://www.w3.org/2001/XMLSchema-instance&#8221;
</p>




<p style="text-align: justify;">
  Questo è il codice che esegue la query sul file file/video/extract.xml:
</p>




<pre lang="java">String prologoQuery = "" +
 "declare default element namespace \"urn:mpeg:mpeg7:schema:2001\"; " +
 "declare  namespace mpeg7 = \"urn:mpeg:mpeg7:schema:2001\"; " +
 "declare  namespace xsi = \"http://www.w3.org/2001/XMLSchema-instance\"; ";

 // Gets the XQDataSource for the specified Driver.
 XQDataSource source = (XQDataSource) Class.forName(DRIVER).newInstance();
 // Creates an XQConnection
 XQConnection conn = source.getConnection();
 // Prepares the Expressionwith the Document and the Query.
 //XQPreparedExpression expr = conn.prepareExpression("&lt;xml&gt;1 + 2 = { 1+2 }&lt;/xml&gt;/text()");
 //XQPreparedExpression expr = conn.prepareExpression("doc('file/video/20090201_video_15213221.xml')//meta");
 XQPreparedExpression expr = conn.prepareExpression(prologoQuery + " doc('file/video/extract.xml')//Name");

 // Executes the XQuery query.
 XQResultSequence result = expr.executeQuery();
 // Gets all results of the execution.
 while(result.next()) {
 //element = (org.w3c.dom.Element) result.getObject();
 System.out.println(result.getItemAsString(null));
 }</pre>




<p style="text-align: justify;">
  Nella riga 18 è commentato un altro modo per usare gli oggetti restiuiti dalla query, che ci restituisce il risultato come elementi della struttura DOM del file XML.
</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Describing Media With XML and MPEG-7]]></title>
    <link href="http://fsferrara.github.io/describing-media-with-xml-and-mpeg-7/"/>
    <updated>2009-10-27T01:17:43+00:00</updated>
    <id>http://fsferrara.github.io/describing-media-with-xml-and-mpeg-7</id>
    <content type="html"><![CDATA[<p class="western">
  La diffusione delle connessioni a banda larga ha agevolato la diffusione di audio e video via web: un esempio eclatante è YouTube! Ma riuscire a trovare un video particolare tra la grossa quantità di dati multimediali sul web è un compito arduo: il valore del dato multimediale dipende da quanto è agevole trovarlo, gestirlo, ed accedere.
</p>




<p style="margin-bottom: 0cm;">
  Per gestire questa grossa quantità di dati multimediali, sia da parte degli utenti, sia da parte dei sistemi automatici, ci aiuta Mpeg-7: uno standard nato per codificare i contenuti multimediali attraverso la definizione di metadati sui dati multimediali.
</p>




<p style="margin-bottom: 0cm;">
  I precedenti standard Mpeg-1 (1992), Mpeg-2 (1994), e Mpeg-4 (1999) riguardano la codifica del video. Nel 2001 è stato definito Mpeg-7 che non definisce il modo di codificare un video, ma riguarda la sua metataggatura attraverso un linguaggio XML.<br /> Perché 7? Mpeg-7 permette di definire metadati sui video codificati con Mpeg 1, 2, e 4. Siccome 4+2+1=7, nasce il nome Mpeg-7.
</p>




<p style="margin-bottom: 0cm;">
  <!--more-->
</p>




<p style="margin-bottom: 0cm;">
  Notiamo come non è stato nominato Mpeg-3, lo standard per i famosissimi mp3 :) . In realtà questo standard non esiste, ma il nome Mpeg-3 è usato per riferirsi alla parte audio di Mpeg-2.
</p>


<h2>Metadati {.western}</h2>

<p style="margin-bottom: 0cm;">
  I metadati associati ad un video permettono di descrivere cosa c&#8217;è nel video. Mpeg-7 permette descrizioni sia a basso livello (caratteristiche del segnale, come il colore di un oggetto), sia ad alto livello (informazioni semantiche, come la scena di un goal in una partita di calcio).<br /> Un esempio di file XML in formato Mpeg-7 contenente la descrizione di un video di una notizia è:
</p>




<pre lang="xml">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;
 &lt;!--Metadati generati automaticamente dall'applicazione--&gt;
&lt;Mpeg7 xmlns="urn:mpeg:mpeg7:schema:2001" xmlns:mpeg7="urn:mpeg:mpeg7:schema:2001"
 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
 xsi:schemaLocation="urn:mpeg:mpeg7:schema:2001 Mpeg7-2001.xsd"&gt;
 &lt;Description xsi:type="ContentEntityType"&gt;
 &lt;MultimediaContent xsi:type="VideoType"&gt;
 &lt;Video&gt;
 &lt;MediaInformation&gt;
 &lt;MediaProfile&gt;
 &lt;MediaFormat&gt;
 &lt;Content href="MPEG7ContentCS" /&gt;
 &lt;FileFormat href="urn:mpeg:mpeg7:cs:FileFormatCS:2001:3"&gt;
 &lt;Name&gt;mpeg&lt;/Name&gt;
 &lt;/FileFormat&gt;
 &lt;FileSize&gt;17333073&lt;/FileSize&gt;
 &lt;VisualCoding&gt;
 &lt;Format colorDomain="color"
 href="urn:mpeg:mpeg7:cs:VisualCodingFormatCS:2001:1" /&gt;
 &lt;Frame height="576" rate="8000" width="720" /&gt;
 &lt;/VisualCoding&gt;
 &lt;/MediaFormat&gt;
 &lt;MediaInstance id="v20090201_video_15213221"&gt;
 &lt;InstanceIdentifier /&gt;
 &lt;MediaLocator&gt;
 &lt;MediaUri&gt;20090201_video_15213221.mov&lt;/MediaUri&gt;
 &lt;/MediaLocator&gt;
 &lt;/MediaInstance&gt;
 &lt;/MediaProfile&gt;
 &lt;/MediaInformation&gt;
 &lt;CreationInformation&gt;
 &lt;Creation&gt;
 &lt;Title&gt;Obama: presto un piano per famiglie Usa per tagliare costi
 mutui&lt;/Title&gt;
 &lt;Abstract&gt;
 &lt;FreeTextAnnotation&gt;
 Presidente cerca arginare effetti devastante crisi economica
 &lt;/FreeTextAnnotation&gt;
 &lt;StructuredAnnotation&gt;
 &lt;When&gt;
 &lt;Name&gt;1 Feb 2009&lt;/Name&gt;
 &lt;/When&gt;
 &lt;/StructuredAnnotation&gt;
 &lt;/Abstract&gt;
 &lt;Creator&gt;
 &lt;Role href="urn:mpeg:mpeg7:cs:RoleCS:2001:producer"&gt;
 &lt;Name&gt;Red&lt;/Name&gt;
 &lt;/Role&gt;
 &lt;Agent xsi:type="OrganizationType"&gt;
 &lt;Name&gt;Apcom&lt;/Name&gt;
 &lt;/Agent&gt;
 &lt;/Creator&gt;
 &lt;CreationCoordinates&gt;
 &lt;Location&gt;
 &lt;Name&gt;milano&lt;/Name&gt;
 &lt;/Location&gt;
 &lt;Date&gt;
 &lt;TimePoint&gt;2009-02-01T15:21:32&lt;/TimePoint&gt;
 &lt;/Date&gt;
 &lt;/CreationCoordinates&gt;
 &lt;CopyrightString&gt;TMNews&lt;/CopyrightString&gt;
 &lt;/Creation&gt;
 &lt;Classification&gt;
 &lt;Genre href="urn:mpeg:TVAnytime_v0.1ContentCS:3.14"&gt;
 &lt;Name&gt;est&lt;/Name&gt;
 &lt;/Genre&gt;
 &lt;MediaReview&gt;
 &lt;Rating&gt;
 &lt;RatingValue&gt;0.0&lt;/RatingValue&gt;
 &lt;RatingScheme best="5" style="higherBetter" worst="0"&gt;
 &lt;Name&gt;Overall&lt;/Name&gt;
 &lt;/RatingScheme&gt;
 &lt;/Rating&gt;
 &lt;/MediaReview&gt;
 &lt;/Classification&gt;
 &lt;RelatedMaterial&gt;
 &lt;MediaLocator&gt;
 &lt;MediaUri&gt;20090201_video_17483840.mov&lt;/MediaUri&gt;
 &lt;/MediaLocator&gt;
 &lt;/RelatedMaterial&gt;
 &lt;RelatedMaterial&gt;
 &lt;MediaLocator&gt;
 &lt;MediaUri&gt;20090201_video_18024720.mov&lt;/MediaUri&gt;
 &lt;/MediaLocator&gt;
 &lt;/RelatedMaterial&gt;
 &lt;RelatedMaterial&gt;
 &lt;MediaLocator&gt;
 &lt;MediaUri&gt;20090201_video_18094945.mov&lt;/MediaUri&gt;
 &lt;/MediaLocator&gt;
 &lt;/RelatedMaterial&gt;
 &lt;RelatedMaterial&gt;
 &lt;MediaLocator&gt;
 &lt;MediaUri&gt;20090201_video_18153193.mov&lt;/MediaUri&gt;
 &lt;/MediaLocator&gt;
 &lt;/RelatedMaterial&gt;
 &lt;RelatedMaterial&gt;
 &lt;MediaLocator&gt;
 &lt;MediaUri&gt;20090202_video_13033231.mov&lt;/MediaUri&gt;
 &lt;/MediaLocator&gt;
 &lt;/RelatedMaterial&gt;
 &lt;RelatedMaterial&gt;
 &lt;MediaLocator&gt;
 &lt;MediaUri&gt;20090202_video_13094131.mov&lt;/MediaUri&gt;
 &lt;/MediaLocator&gt;
 &lt;/RelatedMaterial&gt;
 &lt;RelatedMaterial&gt;
 &lt;MediaLocator&gt;
 &lt;MediaUri&gt;20090202_video_16491593.mov&lt;/MediaUri&gt;
 &lt;/MediaLocator&gt;
 &lt;/RelatedMaterial&gt;
 &lt;RelatedMaterial&gt;
 &lt;MediaLocator&gt;
 &lt;MediaUri&gt;20090202_video_17042673.mov&lt;/MediaUri&gt;
 &lt;/MediaLocator&gt;
 &lt;/RelatedMaterial&gt;
 &lt;/CreationInformation&gt;
 &lt;UsageInformation&gt;
 &lt;Availability id="onDemand"&gt;
 &lt;InstanceRef href="MPEG7PublicationTypeCS:4" /&gt;
 &lt;Dissemination&gt;
 &lt;Format href="MPEG7PublicationTypeCS:4"&gt;
 &lt;Name&gt;Internet&lt;/Name&gt;
 &lt;/Format&gt;
 &lt;Location&gt;
 &lt;Region&gt;it&lt;/Region&gt;
 &lt;/Location&gt;
 &lt;/Dissemination&gt;
 &lt;/Availability&gt;
 &lt;UsageRecord&gt;
 &lt;AvailabilityRef idref="onDemand" /&gt;
 &lt;Audience&gt;0&lt;/Audience&gt;
 &lt;/UsageRecord&gt;
 &lt;/UsageInformation&gt;
 &lt;MediaTime&gt;
 &lt;MediaTimePoint&gt;T00:00:00&lt;/MediaTimePoint&gt;
 &lt;MediaDuration&gt;PT0H0M29S&lt;/MediaDuration&gt;
 &lt;/MediaTime&gt;
 &lt;/Video&gt;
 &lt;/MultimediaContent&gt;
 &lt;MultimediaContent xsi:type="ImageType"&gt;
 &lt;Image&gt;
 &lt;MediaInformation&gt;
 &lt;MediaProfile&gt;
 &lt;MediaFormat&gt;
 &lt;Content href="urn:mpeg:mpeg7:cs:ContentCS:2001:2"&gt;
 &lt;Name&gt;visual&lt;/Name&gt;
 &lt;/Content&gt;
 &lt;FileFormat href="urn:mpeg:mpeg7:cs:FileFormatCS:2001:3"&gt;
 &lt;Name&gt;JPEG2000&lt;/Name&gt;
 &lt;/FileFormat&gt;
 &lt;FileSize&gt;12014&lt;/FileSize&gt;
 &lt;VisualCoding&gt;
 &lt;Format colorDomain="binary"
 href="urn:mpeg:mpeg7:cs:VisualCodingFormatCS:2001:1"&gt;
 &lt;Name&gt;JPEG2000&lt;/Name&gt;
 &lt;/Format&gt;
 &lt;Frame height="288" rate="0" width="360" /&gt;
 &lt;/VisualCoding&gt;
 &lt;/MediaFormat&gt;
 &lt;MediaInstance id="i20090201_video_15213221"&gt;
 &lt;InstanceIdentifier /&gt;
 &lt;MediaLocator&gt;
 &lt;MediaUri&gt;20090201_video_15213221.jpg&lt;/MediaUri&gt;
 &lt;/MediaLocator&gt;
 &lt;/MediaInstance&gt;
 &lt;/MediaProfile&gt;
 &lt;/MediaInformation&gt;
 &lt;CreationInformation&gt;
 &lt;Creation&gt;
 &lt;Title&gt;
 Foto
&lt;/Title&gt;
 &lt;Creator&gt;
 &lt;Role href="urn:mpeg:mpeg7:cs:RoleCS:AUTHOR"&gt;
 &lt;Name&gt;Red&lt;/Name&gt;
 &lt;/Role&gt;
 &lt;Agent xsi:type="OrganizationType"&gt;
 &lt;Name&gt;MPEG&lt;/Name&gt;
 &lt;/Agent&gt;
 &lt;/Creator&gt;
 &lt;/Creation&gt;
 &lt;/CreationInformation&gt;
 &lt;/Image&gt;
 &lt;/MultimediaContent&gt;
 &lt;/Description&gt;
&lt;/Mpeg7&gt;</pre>




<p style="margin-bottom: 0cm;">
  Mpeg-7 è un linguaggio XML, ossia usa XML per definire i metadati. In realtà un file Mpeg-7 non è altro che un file &#8216;.xml&#8217; associato ad uno o più oggetti multimediali. Quindi è possibile memorizzare i metadati indipendentemente dai video&#8230; ad esempio un possibile uso di Mpeg-7, è la costruzione di un database multimediale!
</p>


<h2>Componenti di Mpeg-7 {.western}</h2>

<p style="margin-bottom: 0cm;">
  Lo standard Mpeg-7 è composta da quattro elementi fondamentali:
</p>


<ul>
<li><p><p style="margin-bottom: 0cm;">
  Description Tools
</p></p></li>
<li><p><p style="margin-bottom: 0cm;">
  Descriptor
</p></p></li>
<li><p><p style="margin-bottom: 0cm;">
  Description Scheme
</p></p></li>
<li><p><p style="margin-bottom: 0cm;">
  DDL – Description Definition<br /> Language
</p></p></li>
<li><p><p style="margin-bottom: 0cm;">
  System Tool
</p></p></li>
</ul>


<p style="margin-bottom: 0cm;">
  I metadati di un oggetto multimediale saranno descritti usando i &#8216;Description Tools&#8217;.<br /> I &#8216;Description Tools&#8217; a loro volta fanno uso del &#8216;Description Definition Language&#8217; (DDL) che è una estensione di XML Schema proprio per Mpeg-7.<br /> I &#8216;System Tool&#8217; non riguardano la definizione di metadati, ma la loro rappresentazione e trasmissione. Quindi il file XML è prodotto utilizzando solo &#8216;Description Tools&#8217; e &#8216;DDL&#8217;, e poi questo file XML può essere diffuso utilizzando le tecniche dei &#8216;System Tools&#8217;.
</p>


<h3>Description Definition Language (DDL) {.western}</h3>

<p style="margin-bottom: 0cm;">
  Il DDL è basato su XML Schema Language e ne rappresenta una sorta di estensione orientata al multimedia. In particolare XML Schema non è stato progettato per le descrizioni di contenuti audio/video e necessita quindi di tipi di dato per array e matrici, e tipo di dato per gestire il tempo (BasicTimePoint e BasicDuration).
</p>




<p style="margin-bottom: 0cm;">
  Ad esempio la definizione di TimeType è:
</p>




<pre lang="XML">&lt;!-- Definition of Time datatype --&gt;
&lt;complexType name="TimeType"&gt;
 &lt;sequence&gt;
 &lt;choice&gt;
 &lt;element name="TimePoint" type="mpeg7:TimePointType" /&gt;
 &lt;element name="RelTimePoint" type="mpeg7:RelTimePointType" /&gt;
 &lt;element name="RelIncrTimePoint" type="mpeg7:RelIncrTimePointType" /&gt;
 &lt;/choice&gt;
 &lt;choice minOccurs="0"&gt;
 &lt;element name="Duration" type="mpeg7:durationType" /&gt;
 &lt;element name="IncrDuration" type="mpeg7:IncrDurationType" /&gt;
 &lt;/choice&gt;
 &lt;/sequence&gt;
&lt;/complexType&gt;

&lt;!-- Definition of TimePoint datatype --&gt;
&lt;simpleType name="TimePointType"&gt;
 &lt;restriction base="mpeg7:basicTimePointType"&gt;
 &lt;pattern
 value="(\-?\d+(\-\d{2}(\-\d{2})?)?)?(T\d{2}(:\d{2}(:\d{2} (:\d+)?)?)?)?(F\d+)?(\-|\+\d{2}:\d{2})?" /&gt;
 &lt;/restriction&gt;
&lt;/simpleType&gt;

&lt;!-- Definition of duration datatype --&gt;
&lt;simpleType name="durationType"&gt;
 &lt;restriction base="mpeg7:basicDurationType"&gt;
 &lt;pattern
 value="\-?P(\d+D)?(T(\d+H)?(\d+M)
 ?(\d+S)?(\d+N)?)?( \d+F)?((\-|\+)\d{2}:\d{2}Z)?" /&gt;
 &lt;/restriction&gt;
&lt;/simpleType&gt;</pre>




<p style="margin-bottom: 0cm;">
  Usando queste definizioni di tipo contenute nella DDL, siamo in grado di descrivere il fatto che un certo filmato rappresenta un evento iniziato il 16 ottobre 2002 alle ore 17:00 in un paese con GTM+1, e dura 10 giorni, con questo codice:
</p>




<pre lang="XML">&lt;Time&gt;
  &lt;TimePoint&gt;2002-10-16T17:00+01:00&lt;/TimePoint&gt;
  &lt;Duration&gt;P10D&lt;/Duration&gt;
&lt;/Time&gt;</pre>




<p style="margin-bottom: 0cm;">
  Ovviamente il DDL, oltre ai tipi qui introdotti (TimeType, TimePointType, e durationType), contiene molte altre definizioni che per brevità non tratteremo.
</p>


<h3>Description Tools {.western}</h3>

<p style="margin-bottom: 0cm;">
  I Description Tools comprendono &#8216;Descriptor&#8217; e &#8216;Descriptor Schemes&#8217; che preferisco non distinguere e trattarli insieme, raggruppandoli in base alle loro funzionalità:
</p>


<ul>
<li><p><p style="margin-bottom: 0cm;">
  <strong>Schema and Basic Elements</strong>:<br /> forniscono tutti i tipi di dato utilizzati nelle descrizioni, e la<br /> loro corrispondenza con i tag utilizzati in Mpeg-7;
</p></p></li>
<li><p><p style="margin-bottom: 0cm;">
  <strong>Content Description</strong>:<br /> rappresentazione dell&#8217;informazione audio/video sia a livello<br /> strutturale (basso livello), sia a livello semantico (alto livello);
</p></p></li>
<li><p><p style="margin-bottom: 0cm;">
  <strong>Content Management</strong>:<br /> permette di descrivere caratteristiche come creazione, formato, ed<br /> uso del materiale multimediale;
</p></p></li>
<li><p><p style="margin-bottom: 0cm;">
  <strong>Content Organization</strong>:<br /> Permette di gestire collezioni di materiale multimediale: si possono<br /> usare questi tool per implementare una base di dati XML di<br /> informazioni su materiale multimediale;
</p></p></li>
<li><p><p style="margin-bottom: 0cm;">
  <strong>Navigation and Access</strong>:<br /> aiutano l&#8217;accessibilità al file multimediale;
</p></p></li>
<li><p><p style="margin-bottom: 0cm;">
  <strong>User Interaction</strong>:<br /> permettono di memorizzare le preferenze dell&#8217;utente.
</p></p></li>
</ul>


<p>Con i Description Tools siamo in grado di produrre due tipi di descrizioni Mpeg-7 valide: le &#8220;Complete Descriptions&#8221; che descrivono interamente un materiale multimediale come un video (l&#8217;esempio di file xml Mpeg-7 di questo articolo corrisponde ad una Complete Description perchè descrive completamente il video), e le &#8220;Descriptions Units&#8221; che non sono descrizioni intere ma dei componenti che possono far parte di una Complete Description.</p>

<h2>Conclusioni {.western}</h2>

<p style="margin-bottom: 0cm;">
  Non si è trattata la parte dei System Tools, inoltre della parte dei Description Tool si è data una semplice descrizione generale. I Description Tool sono la parte più corposa dello standard Mpeg-7, e studiarli tutti può richiedere tempo. Si suggerisce a tal proposito di utilizzare i documenti ufficiali dello standard o l&#8217;utilissima guida di Chiariglione all&#8217;indirizzo http://www.chiariglione.org/mpeg/ .
</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Very Brief Introduction to XML]]></title>
    <link href="http://fsferrara.github.io/very-brief-introduction-to-xml/"/>
    <updated>2009-10-26T01:15:26+00:00</updated>
    <id>http://fsferrara.github.io/very-brief-introduction-to-xml</id>
    <content type="html"><![CDATA[<p>Il linguaggio XML è diventato uno degli elementi fondamentali per la realizzazione di sistemi informativi, indipendentemente dalla tecnologia usata.</p>

<h2>Storia</h2>

<p>Il World Wide Web Consortium (W3C), in seguito alla guerra dei browser fu costretto a seguire le individuali estensioni al linguaggio HTML. Dovette scegliere quali caratteristiche standardizzare e quali lasciare fuori dalle specifiche ufficiali dell&#8217;HTML. Fu in questo contesto che iniziò a delinearsi la necessità di un linguaggio di markup che desse maggiore libertà nella definizione dei tag, pur rimanendo in uno standard.</p>

<p>Il &#8220;progetto XML&#8221;, che ebbe inizio alla fine degli anni &#8217;80 nell&#8217;ambito della SGML Activity del W3C, suscitò un così forte interesse a tal punto che la W3C creò un gruppo di lavoro, chiamato XML Working Group, composto da esperti mondiali delle tecnologie SGML, ed una commissione, XML Editorial Review Board, deputata alla redazione delle specifiche del progetto.</p>

<p>Nel febbraio del 1998 le specifiche divennero una raccomandazione ufficiale con il nome di Extensible Mark-up Language, versione 1.0. Ben presto ci si accorse che XML non era solo limitato al contesto web, ma era qualcosa di più: uno strumento che permetteva di essere utilizzato nei più diversi contesti, dalla definizione della struttura di documenti, allo scambio delle informazioni tra sistemi diversi, dalla rappresentazione di immagini alla definizione di formati di dati.</p>

<!--more-->


<h2>Il Linguaggio</h2>

<ul>
<li><strong>Definizione XML</strong>: (acronimo di eXtensible Markup Language) è un metalinguaggio di markup, ovvero un linguaggio marcatore che definisce un meccanismo sintattico che consente di estendere o controllare il significato di altri linguaggi marcatori. Costituisce il tentativo di produrre una versione semplificata di SGML che consenta di definire in modo semplice nuovi linguaggi di markup</li>
</ul>


<p>Quindi quello che si fa con XML è definire/progettare dei propri “Linguaggi XML” (cioè un linguaggio basato su XML); ad esempio possiamo scegliere di codificare in XML i risultati di una giornata del campionato di calcio:</p>

<!--more-->




<pre lang="xml">&lt;partite giornata=”3°”&gt;
 &lt;partita numero=”1”&gt;
  &lt;squadra&gt;Napoli&lt;/squadra&gt;
  &lt;squadra&gt;Juventus&lt;/squadra&gt;
  &lt;risultato&gt;3-0&lt;/risultato&gt;
 &lt;/partita&gt;
  &lt;partita numero=”2”&gt;
  &lt;squadra&gt;Roma&lt;/squadra&gt;
  &lt;squadra&gt;Lazio&lt;/squadra&gt;
  &lt;risultato&gt;2-2&lt;/risultato&gt;
 &lt;/partita&gt;
&lt;/partite&gt;</pre>


<p>Il processo di sviluppo di un linguaggio XML è detto “XMLificazione”: ossia la scelta dei tag (partite, partita, squadra, risultato), degli attributi (giornata, numero), e della loro struttura.</p>

<p>Ci possono essere però altri linguaggi XML che usano i nostri stessi tag, e mischiare più linguaggi XML con nomi dei tag uguali può portare a confusione, per questo possiamo introdurre un namespace per i nostri nomi.</p>

<ul>
<li><strong>Namespace XML</strong>: Un namespace è una collezione di nomi di entità, definite dal programmatore, omogeneamente usate in uno o più file sorgente. Lo scopo dei namespace è quello di evitare confusione ed equivoci nel caso siano necessarie molte entità con nomi simili, fornendo il modo di raggruppare i nomi per categorie.Nel linguaggio XML i namespaces sono definiti esplicitamente.</li>
</ul>


<p>Nel nostro caso la prima riga diventerà:</p>

<p><partite giornata=”3°” xmlns=”http://www.fireteam.it”></p>

<p>In questo modo indichiamo che il tag &#8216;partite&#8217; e tutto il suo contenuto appartengono al namespace &#8216;<a href="http://www.fireteam.it&amp;#8217;">http://www.fireteam.it&amp;#8217;</a> di default.</p>

<p>Fin qui XML sembra la più banale delle tecnologie, eppure ha avuto così tanto successo&#8230; allora perché è così importante?</p>

<h2>La Tecnologia XML</h2>

<p>Il primo motivo è che tutti i file XML sono codificati in UNICODE (i famosi UTF-8 UTF-16, ed UTF-32), e sono stati eliminati in questo modo molto dei fastidi che affligevano i formati testuali.</p>

<p>Il secondo motivo è che con XML si può rappresentare l&#8217;informazione in modo semplice, mantenendo un minimo di struttura; non a caso l&#8217;informazione codificata in XML è detta semistrutturata, che è il compromesso dalla completa strutturazione (come ad esempio la struttura rigida di uno schema di un database relazionale) e l&#8217;assenza di struttura (schema-less, ossia il testo puro).</p>

<p>Il terzo motivo, che ritengo più importante, è che attorno a questo semplice linguaggio di markup sono state definite parecchie tecnologie utili a risparmiare lavoro durante il trattamento dei dati. Queste sono:</p>

<ul>
<li><p><strong>Xpath</strong>: è un linguaggio parte della famiglia XML che permette di individuare i nodi all&#8217;interno di un documento XML.</p></li>
<li><p><strong>Linguaggi Schema</strong>: un linguaggio di schema è un linguaggio formale per esprimere “schemi”. Uno schema è la definizione formale della sintassi di un linguaggio XML, ovvero una famiglia di documenti XML.</p>

<ul>
<li><strong>DTD</strong>: Il linguaggio DTD è utile a definire schemi DTD per un particolare linguaggio XML. DTD è semplice, con un potere espressivo limitato, non è autoesplicativo poiché non usa una notazione XML (è descritto da una grammatica BNF), e tra i tanti difetti non supporta i namespace in quanto il linguaggio DTD stato definito è stato definito prima dei namespace.</li>
<li><strong>Schema</strong>: è un linguaggio di schema nato per sostituire DTD. E&#8217; più espressivo, è quasi autoesplicativo (è scritto in XML e la sua sintassi è definibile con XML schema stesso, ma non si riescono a catturare tutti gli aspetti sintattici del linguaggio). Inoltre introduce i tipi di dato e permette di crearne nuovi, in modo da riuscire a fare buoni controlli sui contenuti dei file XML.</li>
</ul>
</li>
<li><p><strong>XSL</strong>: acronimo di eXtensible Stylesheet Language, è il linguaggio di descrizione dei fogli di stile per i documenti in formato XML. Com&#8217;è noto, lo standard XML prevede che i contenuti di un documento siano separati dalla formattazione della pagina in cui verranno pubblicati.</p>

<ul>
<li><strong>XSLT</strong>: XSL Transformations &#8211; il linguaggio di trasformazione dell&#8217;XML. Fa uso di XPath per accedere alle parti di un documento XML. La trasformazione è fatta da un modulo detto Processore XSLT, come ad esempio quello incluso nei browser.</li>
<li><strong>XSL-FO</strong>: XSL Formatting Objects &#8211; usato per l&#8217;applicazione degli stili e del modo di apparizione a un documento XML.</li>
</ul>
</li>
<li><p><strong>XQuery</strong>: abbrevazione per XML Query Language, è un linguaggio di programmazione specificato dal W3C e destinato ad interrogare documenti e basi di dati XML.</p></li>
</ul>


<p>Qui è d&#8217;obbligo soffermarsi per discutere sull&#8217;utilità di un linguaggio di interrogazione XML. Un&#8217;ambiziosa applicazione di XML ha come scopo la generalizzazione del tradizionale modello delle basi di dati relazionali. Da tempo si sta cercando un&#8217;alternativa ai vecchissimi database relazionali, e si è provato in svariate direzioni&#8230; database gerarchici, database multidimensionali, database ad oggetti, ecc.</p>

<p>XML è un alternativa allettane! Oggi si scrive molto in XML, specialmente sul web dove vi sono pagine XHTML (che sono XML), e l&#8217;idea di avere un database XML perfettamente integrabile con tutti gli altri nostri dati non è affatto male&#8230; il World Wide Web può così diventare una gigantesca base di dati.</p>

<p>XQuery è un linguaggio per interrogare file XML, allo stesso modo in cui SQL interroga base di dati relazionali&#8230; ed è qui che una collezione di file XML è spesso chiamata Database XML.</p>

<p>E come tutti i linguaggi di interrogazione che si rispettano anche per XQuery c&#8217;è un algebra&#8230; XML Query Algebra definita dal W3C. In realtà i lavori sono ancora in progresso e ci sono varie proposte di algebra:</p>

<ul>
<li><strong>Algebra per linguaggi di interrogazione XML</strong>: sono stati proposti svariati linguaggi di interrogazione XML, come XQuery, XML-QL, ed altri; quindi c&#8217;è un interesse crescente verso l&#8217;interrogazione di file XML. Non ancora però è stata definita un&#8217;algebra comune per questi linguaggi. Un algebra formale è un passo obbligato per avere una buona ottimizzazione delle query.

<ul>
<li><strong>TAX</strong>: E&#8217; una proposta di algebra non standard, utilizzata da un motore di database XML chiamato “Timber XML”. TAX sta per “Tree Algebra for XML”, ed è una proposta interessante perché usa un modello di dati dove i documenti XML sono effettivamente visti come alberi, quindi le varie operazioni (Selezione, Proiezione, Prodotto, Set, Raggruppamento, Aggregazione, Renaming, Reordering, Copy-and-Paste, Cancellazione, Inserimento) risultano definite in modo naturale.</li>
<li><strong>XML Query Algebra</strong>: anche chiamata “The Algebra” è la proposta di standardizzazione da parte del W3C. Questa algebra, che sembra assomigliare ad un linguaggio di programmazione dichiarativo, non definisce le operazioni con operatori ad HOC, ma riesce a ricavare le consuete operazioni mediante l&#8217;uso di cicli for, assegnazioni di variabili, costrutti condizionali, ed altro. Inoltre i tipi di dato sono molto importanti, e sono definiti per ogni espressione. Una volta tradotta una query, la sua ottimizzazione sfrutta delle regole di inferenza logica; un metodo del tutto innovativo.</li>
</ul>
</li>
</ul>


<p>E quando queste tecnologie non riescono a soddisfare le nostre richieste, entra in gioco la solita programmazione:</p>

<ul>
<li><p><strong>Programmazione XML</strong>: Benchè gli strumenti XML (Schema, XSLT, XQuery, XPath, ecc&#8230;) ci permettono di fare molti tipi di elaborazione, spesso c&#8217;è la necessita di manipolare file XML da linguaggi di programmazione di uso generale come ad esempio Java.</p>

<ul>
<li><strong>DOM</strong>: Il Document Object Model (DOM) è una forma di rappresentazione dei documenti strutturati come modello orientato agli oggetti. DOM definisce un API per accedere e manipolare file XML comune a diversi linguaggi.</li>
<li><strong>SAX</strong>: (Simple API for XML) è un&#8217;API per numerosi linguaggi di programmazione che permette di leggere ed elaborare dei documenti XML. Contrariarmente al DOM, il SAX processa i documenti linea per linea. Il flusso di dati XML è unidirezionale, così che dati a cui si è acceduto in precedenza non possono essere riletti senza la rielaborazione dell&#8217;intero documento.</li>
<li><strong>JDOM</strong>: JDom è un API per accedere ed elaborare documenti XMl specifica per il linguaggio di programmaziopne Java, che (rispettando il principio del 80/20) permette di sviluppare con semplicità l&#8217;80% delle applicazione, mentre richiede una soluzione ad HOC per il restante 20%&#8230; cioè JDom sacrifica parte della generalità per dar miglior supporto alle applicazioni più comuni.</li>
</ul>
</li>
<li><p><strong>XML Retrieval</strong>: L&#8217;information retrieval (IR) è la disciplina che studia le tecniche utilizzate per il recupero mirato dell’informazione in formato elettronico.</p></li>
</ul>


<h2>Le Applicazioni XML</h2>

<p>XML è oggi una tecnologia matura ed utilizzata negli ambiti più disparati&#8230; basta provare a salvare un documento di testo scritto con il famosissimo word processor OpenOffice, rinominare questo file .zip, e provare ad estrarre il contenuto: dentro troveremo il nostro documento descritto in XML!!!</p>

<p>Un altro esempio è SVG, lo standard aperto per la grafica vettoriale che punta a sostituire la tecnologia &#8216;flash&#8217; sul web. Un file .svg è interamente scritto in XML, tant&#8217;è vero che si può aprire senza problemi con un qualsiasi editor di testo.</p>

<p>Alcuni linguaggi XML hanno avuto particolare successo come XHTML, CML (Chemical Markup Language), WML (usato nella tecnologia WAP dei cellulari), RSS ed altri&#8230; in particolare Mpeg7:</p>

<ul>
<li><strong>Mpeg-7</strong>: MPEG-7 è uno standard nato per codificare i contenuti multimediali; non è uno standard nato per codificare flussi audio o video come, ad esempio, MPEG-1 MPEG-2 o MPEG-4 ma per definire metadati sui dati multimediali.La codifica utilizza l&#8217;XML per memorizzare dei metadati che utilizzano a loro volta il timecode del filmato permettendo di sincronizzare i flussi multimediali con particolari eventi. Per esempio, permette di sincronizzare un filmato con i suoi sottotitoli o un video con il testo della canzone.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Very Brief Introduction to Regular Expressions]]></title>
    <link href="http://fsferrara.github.io/very-brief-introduction-to-regular-expressions/"/>
    <updated>2009-10-25T01:13:16+00:00</updated>
    <id>http://fsferrara.github.io/very-brief-introduction-to-regular-expressions</id>
    <content type="html"><![CDATA[<p>Le espressioni regolari sono utili per descrivere la validità di valori, come ad esempio valori di attributi, dati caratteri, e qualsiasi tipo di valore esprimibile con un certo alfabeto.</p>

<p>Il concetto di espressione regolare è un formalismo importante utilizzato, in varie forme, in svariate applicazioni&#8230; ad esempio nei linguaggi di schema (come DTD di XML) per descrivere sequenze di elementi o caratteri. I linguaggi regolari sono utilizzati in molte altre aree dell&#8217;informatica oltre a XML, dall&#8217;elaborazione del testo e del linguaggio naturale alla verifica formale dei componenti hardware.</p>

<p>Potrebbe essere necessario, ad esempio, vincolare un valore &#8216;data&#8217; in modo tale da rispettare il formato dd-mm-yyyy, ovvero sia composto da due cifre per il giorno, seguite da due per il mese e quattro per l&#8217;anno, tutto separato da un segno meno “-”. Alternativamente possiamo specificare che un certo valore deve essere un numero intero.</p>

<p>Chiamiamo Σ un alfabeto consistente in un insieme di atomi, che tipicamente sono caratteri Unicode o nomi di elementi. Un&#8217;espressione regolare su Σ è costruita in base alle seguenti regole:</p>

<!--more-->


<ul>
<li>ogni atomo in Σ, preso da solo, è un espressione regolare;</li>
<li>se a e b sono espressioni regolari, allora lo sono anche le seguenti:

<ul>
<li><p><pre>a?</pre></p></li>
<li><p><pre>a*</pre></p></li>
<li><p><pre>a+</pre></p></li>
<li><p><pre>a b</pre></p></li>
<li><p><pre>a|b</pre></p></li>
<li><p><pre>(a)</pre></p></li>
</ul>
</li>
</ul>


<p>Gli operatori ?, , e + hanno una precedenza superiore alla concatenazione (l&#8217;operatore vuoto o “giustapposizione”), che a sua volta ha una precedenza superiore a |. E&#8217; sempre possibile usare le parentesi per raggruppare sotto-espressioni, superando così le precedenze di default. L&#8217;espressione ab*|c, in cui l&#8217;alfabeto Σ contiene a, b, e c, è interpretata come (a(b*))|c e non a(b*|c).</p>

<p>Una stringa finita di atomi di Σ può corrispondere o meno a una data espressione regolare a:</p>

<ul>
<li>un atomo r appartenente a Σ corrisponde unicamente al singolo atomo r;</li>
<li>a? corrisponde ad a opzionalmente, ovvero a qualsiasi stringa corrisponda ad a più la stringa vuota;</li>
<li>a* corrisponde a zero o più ripetizioni delle stringhe che corrispondono ad a;</li>
<li>a+ corrisponde ad una o più ripetizioni delle stringhe che corrispondono ad a;</li>
<li>a b corrisponde a ciò a cui corrisponde &#8216;a&#8217; seguito da ciò a cui corrisponde b;</li>
<li>a|b corrisponde all&#8217;unione delle corrispondenze di a e b;</li>
<li>(a) ha le stesse corrispondente di a.</li>
</ul>


<p>L&#8217;espressione regolare (a(b*))|c corrisponde così a tutte le stringhe composte da una a seguite da zero o più b, oppure una singola c da sola.</p>

<p>Un linguaggio regolare è un insieme di stringhe che corrispondono a una qualche espressione regolare.</p>

<p>E&#8217; possibile definire un&#8217;espressione regolare d (che sta per digit, cifra) scrivendo:</p>

<pre>0|1|2|3|4|5|6|7|8|9</pre>


<p>laddove l&#8217;alfabeto è composto ad esempio da tutti caratteri Unicode. Possiamo partire da questa definizione per definire un&#8217;altra espressione regolare &#8216;data&#8217; scrivendo dd-dd-dddd. Naturalmente quest&#8217;espressione corrisponde anche a stringhe come 88-26-9995, che non denotano date reali, ma con un po&#8217; più di sforzo è possibile catturare precisamente l&#8217;insieme di stringhe desiderato: in effetti su può usare un linguaggio regolare per gestire correttamente anche gli anni bisestili, ma allora le cose si fanno parecchie complicate!</p>

<p>La seguente espressione regolare descrive gli interi con un alfabeto composto dalle dieci cifre e dal segno meno:</p>

<pre>0|-?(|1|2|3|4|5|6|7|8|9)(0|1|2|3|4|5|6|7|8|9)*</pre>


<p>Secondo questa definizione, -42, 0, 117 sono accettabili, mentre 000, -0 e 3.14 non lo sono.</p>

<p>Adesso facciamo l&#8217;ultimo esempio, più complicato! In XHTML il contenuto di un elemento table dev&#8217;essere una sequenza che consiste in un elemento opzionale &#8216;caption&#8217; seguito da un certo numero di elementi &#8216;col&#8217; o alternativamente &#8216;colgroup&#8217;, i quali a loro volta sono opzionalmente seguiti da un elemento &#8216;thead&#8217; e uno &#8216;tfoot&#8217;, per concludere almeno un elemento &#8216;tbody&#8217; (o alternativamente &#8216;tr&#8217;). Possiamo scrivere con un&#8217;espressione regolare:</p>

<pre>caption? ( col* | colgroup* ) thead? tfoot? ( tbody+ | tr+ )</pre>


<p>Esistono molte varianti delle espressioni regolari&#8230; ad esempio le regular expression del linguaggio perl: tuttavia la maggior parte di queste varianti si limita ad aggiungere zucchero sintattico alla notazione base che abbiamo appena presentato.</p>

<p>Un&#8217;estensione tipica sono gli intervalli di caratteri: [0-9], ad esempio, è una comoda abbreviazione per indicare le cifre al posto di 0|1|2|3|4|5|6|7|8|9. In modo analogo a{n,m} con n e m numeri interi non negativi, denota da n ad m ripetizioni di a.</p>

<p>Questa è l&#8217;introduzione alle espressioni regolari; per lavorare efficientemente con un vero implementazione di queste espressioni richiede ulteriore studio.</p>
]]></content>
  </entry>
  
</feed>
